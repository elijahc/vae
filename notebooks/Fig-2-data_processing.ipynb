{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm as tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV\n",
    "\n",
    "import brainscore\n",
    "from brainscore.assemblies import walk_coords,split_assembly\n",
    "from brainscore.assemblies import split_assembly\n",
    "from brainscore.metrics import Score\n",
    "\n",
    "from brainio_base.assemblies import DataAssembly\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from src.results.experiments import _DateExperimentLoader\n",
    "\n",
    "def set_style():\n",
    "    # This sets reasonable defaults for font size for\n",
    "    # a figure that will go in a paper\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    # Set the font to be serif, rather than sans\n",
    "    sns.set(font='serif')\n",
    "    \n",
    "    # Make the background white, and specify the\n",
    "    # specific font family\n",
    "    sns.set_style(\"white\", {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"Palatino\", \"serif\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = _DateExperimentLoader('2019-06-04')\n",
    "lg.load_configs()\n",
    "configs = pd.DataFrame.from_records(lg.configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>bg_noise</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dec_blocks</th>\n",
       "      <th>ecc_max</th>\n",
       "      <th>enc_arch</th>\n",
       "      <th>enc_blocks</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>epochs</th>\n",
       "      <th>label_corruption</th>\n",
       "      <th>...</th>\n",
       "      <th>project</th>\n",
       "      <th>recon</th>\n",
       "      <th>rot_max</th>\n",
       "      <th>run_dir</th>\n",
       "      <th>seed</th>\n",
       "      <th>uploaded_by</th>\n",
       "      <th>xcov</th>\n",
       "      <th>xent</th>\n",
       "      <th>y_dim</th>\n",
       "      <th>z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>fashion_mnist</td>\n",
       "      <td>[4, 2, 1]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>feedforward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3000, 2000, 500]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>vae</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/elijahc/projects/vae/logs/0701_145223_fa...</td>\n",
       "      <td>7</td>\n",
       "      <td>elijahc</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>fashion_mnist</td>\n",
       "      <td>[4, 2, 1]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>feedforward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3000, 2000, 500]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>vae</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/elijahc/projects/vae/logs/0701_152033_fa...</td>\n",
       "      <td>7</td>\n",
       "      <td>elijahc</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size  bg_noise        dataset dec_blocks  ecc_max     enc_arch  \\\n",
       "2          512      0.05  fashion_mnist  [4, 2, 1]      0.6  feedforward   \n",
       "12         512      0.05  fashion_mnist  [4, 2, 1]      0.6  feedforward   \n",
       "\n",
       "   enc_blocks         enc_layers  epochs  label_corruption  ... project recon  \\\n",
       "2         NaN  [3000, 2000, 500]      90               0.0  ...     vae     0   \n",
       "12        NaN  [3000, 2000, 500]      10               0.0  ...     vae    25   \n",
       "\n",
       "   rot_max                                            run_dir seed  \\\n",
       "2        0  /home/elijahc/projects/vae/logs/0701_145223_fa...    7   \n",
       "12       0  /home/elijahc/projects/vae/logs/0701_152033_fa...    7   \n",
       "\n",
       "   uploaded_by  xcov  xent y_dim  z_dim  \n",
       "2      elijahc     0    15    35     35  \n",
       "12     elijahc     0    15    35     35  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.query('bg_noise == 0.05 & enc_arch == \"feedforward\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijahc/.pyenv/versions/fastai/lib/python3.6/site-packages/brainio_base/assemblies.py:213: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<xarray.DataAssembly (presentation: 10000, neuroid: 8706)>\n",
       " array([[ 2.918898,  1.481666, -6.121837, ...,  0.      ,  0.      ,  0.      ],\n",
       "        [-1.232504, -0.251372,  0.99593 , ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 7.400597,  7.941635, 10.374889, ...,  0.      ,  0.      ,  0.      ],\n",
       "        ...,\n",
       "        [ 3.823743, -6.502236,  3.107507, ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 5.338862,  5.564245,  5.631349, ...,  0.      ,  0.      ,  0.      ],\n",
       "        [-0.750803,  0.913194, -2.584277, ...,  0.      ,  0.      ,  0.      ]],\n",
       "       dtype=float32)\n",
       " Coordinates:\n",
       "   * presentation   (presentation) MultiIndex\n",
       "   - image_id       (presentation) object '6faf23dc748fc2fa6999ca4f16b90358' ... '691246995f7c97c4af84eb20fffe2128'\n",
       "   - object_name    (presentation) object 'Ankle boot' 'Pullover' ... 'Dress'\n",
       "   - dx             (presentation) float64 2.0 -6.0 -7.0 4.0 ... 7.0 0.0 -4.0 6.0\n",
       "   - dy             (presentation) float64 -8.0 -2.0 4.0 -7.0 ... -2.0 -2.0 -1.0\n",
       "   - rxy            (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "   - numeric_label  (presentation) int64 9 2 1 1 6 1 4 6 5 ... 5 7 9 1 4 6 0 9 3\n",
       "   - tx             (presentation) float64 0.07143 -0.2143 ... -0.1429 0.2143\n",
       "   - ty             (presentation) float64 -0.2857 -0.07143 ... -0.07143 -0.03571\n",
       "   - s              (presentation) float64 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0\n",
       "   * neuroid        (neuroid) MultiIndex\n",
       "   - neuroid_id     (neuroid) object 'y_lat_0' 'y_lat_1' ... 'y_lat_29'\n",
       "   - region         (neuroid) object 'y_lat' 'y_lat' 'y_lat' ... 'y_lat' 'y_lat'\n",
       "   - layer          (neuroid) int64 4 4 4 4 4 4 4 4 4 4 4 ... 4 4 4 4 4 4 4 4 4 4\n",
       " Attributes:\n",
       "     stimulus_set:                                image_id  object_name   dx  ...\n",
       "     xent:          15\n",
       "     recon:         0,\n",
       " <xarray.DataAssembly (presentation: 10000, neuroid: 8706)>\n",
       " array([[  0.      ,   0.559497,   0.      , ...,  -1.928891,  -6.929965,\n",
       "           6.187957],\n",
       "        [  0.      ,   0.      ,   0.      , ...,   5.213934,  13.492253,\n",
       "          10.716563],\n",
       "        [  0.      ,   0.      ,   0.      , ...,  13.85531 ,  20.418108,\n",
       "         -14.439281],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      , ...,   8.557281,  -2.779448,\n",
       "           4.95125 ],\n",
       "        [  0.      ,   0.      ,   0.      , ...,   5.257342,   6.776066,\n",
       "         -12.262635],\n",
       "        [  0.      ,   0.      ,   0.      , ...,   4.247205,  -3.493007,\n",
       "          -1.046876]], dtype=float32)\n",
       " Coordinates:\n",
       "   * presentation   (presentation) MultiIndex\n",
       "   - image_id       (presentation) object 'c48a8cc51a9cabeadbba098ce36363f5' ... 'ee11d0b691735096993dc2b7e96e6bbd'\n",
       "   - object_name    (presentation) object 'Ankle boot' 'Pullover' ... 'Dress'\n",
       "   - dx             (presentation) float64 2.0 -6.0 -7.0 4.0 ... 7.0 0.0 -4.0 6.0\n",
       "   - dy             (presentation) float64 -8.0 -2.0 4.0 -7.0 ... -2.0 -2.0 -1.0\n",
       "   - rxy            (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "   - numeric_label  (presentation) int64 9 2 1 1 6 1 4 6 5 ... 5 7 9 1 4 6 0 9 3\n",
       "   - tx             (presentation) float64 0.07143 -0.2143 ... -0.1429 0.2143\n",
       "   - ty             (presentation) float64 -0.2857 -0.07143 ... -0.07143 -0.03571\n",
       "   - s              (presentation) float64 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0\n",
       "   * neuroid        (neuroid) MultiIndex\n",
       "   - neuroid_id     (neuroid) object 'pixel_0' 'pixel_1' ... 'pixel_29'\n",
       "   - region         (neuroid) object 'pixel' 'pixel' 'pixel' ... 'pixel' 'pixel'\n",
       "   - layer          (neuroid) int64 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
       " Attributes:\n",
       "     stimulus_set:                                image_id  object_name   dx  ...\n",
       "     xent:          15\n",
       "     recon:         25]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = configs.query('bg_noise == 0.05 & enc_arch == \"feedforward\"').index.values\n",
    "lg.load_assemblies(subset=list(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both_df = pd.read_parquet(os.path.join(lg.experiment_root,'su_both_processed.df'))\n",
    "su_xent_df = pd.read_parquet(os.path.join(lg.experiment_root,'su_xent_processed.df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_xent = lg.assemblies[0]\n",
    "lg_both = lg.assemblies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijahc/.pyenv/versions/fastai/lib/python3.6/site-packages/brainio_base/assemblies.py:213: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    }
   ],
   "source": [
    "neural_data = brainscore.get_assembly(name=\"dicarlo.Majaj2015\")\n",
    "neural_data.load()\n",
    "stimulus_set = neural_data.attrs['stimulus_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dicarlo(assembly,avg_repetition=True,variation=3,tasks=['ty','tz','rxy']):\n",
    "    stimulus_set = assembly.attrs['stimulus_set']\n",
    "    stimulus_set['dy_deg'] = stimulus_set.tz*stimulus_set.degrees\n",
    "    stimulus_set['dx_deg'] = stimulus_set.ty*stimulus_set.degrees\n",
    "    stimulus_set['dy_px'] = stimulus_set.dy_deg*32\n",
    "    stimulus_set['dx_px'] = stimulus_set.dx_deg*32\n",
    "    \n",
    "    assembly.attrs['stimulus_set'] = stimulus_set\n",
    "    \n",
    "    data = assembly.sel(variation=variation)\n",
    "    groups = ['category_name', 'object_name', 'image_id']+tasks\n",
    "    if not avg_repetition:\n",
    "        groups.append('repetition')\n",
    "        \n",
    "    data = data.multi_groupby(groups)     # (2)\n",
    "    data = data.mean(dim='presentation')\n",
    "    data = data.squeeze('time_bin')    #   (3)\n",
    "    data.attrs['stimulus_set'] = stimulus_set.query('variation == {}'.format(variation))\n",
    "    data = data.T\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.NeuronRecordingAssembly 'dicarlo.Majaj2015' (neuroid: 296, presentation: 268800, time_bin: 1)>\n",
       "array([[[ 0.060929],\n",
       "        [-0.686162],\n",
       "        ...,\n",
       "        [-0.968256],\n",
       "        [ 0.183887]],\n",
       "\n",
       "       [[-0.725592],\n",
       "        [ 0.292777],\n",
       "        ...,\n",
       "        [ 2.449372],\n",
       "        [ 0.401197]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.121319],\n",
       "        [ 1.719423],\n",
       "        ...,\n",
       "        [ 0.800551],\n",
       "        [-0.019874]],\n",
       "\n",
       "       [[-0.518903],\n",
       "        [ 0.696196],\n",
       "        ...,\n",
       "        [-0.603347],\n",
       "        [-0.175979]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * neuroid          (neuroid) MultiIndex\n",
       "  - neuroid_id       (neuroid) object 'Chabo_L_M_5_9' ... 'Chabo_L_P_7_6'\n",
       "  - arr              (neuroid) object 'M' 'M' 'M' 'M' 'M' ... 'P' 'P' 'P' 'P'\n",
       "  - col              (neuroid) int64 9 9 8 9 8 8 7 7 5 6 ... 8 7 8 6 7 5 7 7 6 6\n",
       "  - hemisphere       (neuroid) object 'L' 'L' 'L' 'L' 'L' ... 'L' 'L' 'L' 'L'\n",
       "  - subregion        (neuroid) object 'cIT' 'cIT' 'cIT' 'cIT' ... 'V4' 'V4' 'V4'\n",
       "  - animal           (neuroid) object 'Chabo' 'Chabo' ... 'Chabo' 'Chabo'\n",
       "  - y                (neuroid) float64 0.2 0.6 0.2 1.0 0.6 ... 1.8 1.0 1.8 1.0\n",
       "  - x                (neuroid) float64 1.8 1.8 1.4 1.8 1.4 ... 1.0 1.0 0.6 0.6\n",
       "  - region           (neuroid) object 'IT' 'IT' 'IT' 'IT' ... 'V4' 'V4' 'V4'\n",
       "  - row              (neuroid) int64 5 6 5 7 6 7 9 7 9 8 ... 8 5 9 6 8 7 9 7 9 7\n",
       "  * presentation     (presentation) MultiIndex\n",
       "  - image_id         (presentation) object '8a72e2bfdb8c267b57232bf96f069374d5b21832' ... 'a533e519b553cdf360ae134f7c9f161134ddaf00'\n",
       "  - repetition       (presentation) int64 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0\n",
       "  - stimulus         (presentation) int64 0 1 2 3 4 5 6 ... 23 24 25 26 27 28 29\n",
       "  - id               (presentation) int64 1 2 3 4 5 6 7 ... 24 25 26 27 28 29 30\n",
       "  - image_file_name  (presentation) object 'astra_rx+00.000_ry+00.000_rz+00.000_tx+00.000_ty+00.000_s+01.000_ecd40f3f6d7a4d6d88134d648884e0b9b364efc9_256x256.png' ... 'face0001_rx+00.000_ry+00.000_rz+00.000_tx+00.000_ty+00.000_s+00.800_840b0badda8be10e1e3d5eff5cedce384f8021bc_256x256.png'\n",
       "  - object_name      (presentation) object 'car_astra' 'table3' ... 'face0'\n",
       "  - category_name    (presentation) object 'Cars' 'Tables' ... 'Fruits' 'Faces'\n",
       "  - background_id    (presentation) object 'ecd40f3f6d7a4d6d88134d648884e0b9b364efc9' ... '840b0badda8be10e1e3d5eff5cedce384f8021bc'\n",
       "  - variation        (presentation) int64 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0\n",
       "  - ty               (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  - tz               (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  - rxy              (presentation) float64 -0.0 -0.0 -0.0 ... -0.0 -0.0 -0.0\n",
       "  - rxz              (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  - ryz              (presentation) float64 -0.0 -0.0 -0.0 ... -0.0 -0.0 -0.0\n",
       "  - rxy_semantic     (presentation) float64 90.0 -0.0 -0.0 ... -0.0 -0.0 -0.0\n",
       "  - rxz_semantic     (presentation) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  - ryz_semantic     (presentation) float64 -0.0 -0.0 -0.0 ... -0.0 -0.0 -0.0\n",
       "  - size             (presentation) float64 256.0 256.0 256.0 ... 256.0 256.0\n",
       "  - s                (presentation) float64 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0\n",
       "  * time_bin         (time_bin) MultiIndex\n",
       "  - time_bin_start   (time_bin) int64 70\n",
       "  - time_bin_end     (time_bin) int64 170\n",
       "Attributes:\n",
       "    stimulus_set_name:  dicarlo.hvm\n",
       "    stimulus_set:               id                                  image_id ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DPRIME_MODE = 'binary'\n",
    "\n",
    "def dprime(A, B=None, mode=DEFAULT_DPRIME_MODE,\\\n",
    "        max_value=np.inf, min_value=-np.inf,\\\n",
    "        max_ppf_value=np.inf, min_ppf_value=-np.inf,\\\n",
    "        **kwargs):\n",
    "    \"\"\"Computes the d-prime sensitivity index of predictions\n",
    "    from various data formats.  Depending on the choice of\n",
    "    `mode`, this function can take one of the following format:\n",
    "    * Binary classification outputs (`mode='binary'`; default)\n",
    "    * Positive and negative samples (`mode='sample'`)\n",
    "    * True positive and false positive rate (`mode='rate'`)\n",
    "    * Confusion matrix (`mode='confusionmat'`)\n",
    "    Parameters\n",
    "    ----------\n",
    "    A, B:\n",
    "        If `mode` is 'binary' (default):\n",
    "            A: array, shape = [n_samples],\n",
    "                True values, interpreted as strictly positive or not\n",
    "                (i.e. converted to binary).\n",
    "                Could be in {-1, +1} or {0, 1} or {False, True}.\n",
    "            B: array, shape = [n_samples],\n",
    "                Predicted values (real).\n",
    "        If `mode` is 'sample':\n",
    "            A: array-like,\n",
    "                Positive sample values (e.g., raw projection values\n",
    "                of the positive classifier).\n",
    "            B: array-like,\n",
    "                Negative sample values.\n",
    "        If `mode` is 'rate':\n",
    "            A: array-like, shape = [n_groupings]\n",
    "                True positive rates\n",
    "            B: array-like, shape = [n_groupings]\n",
    "                False positive rates\n",
    "        if `mode` is 'confusionmat':\n",
    "            A: array-like, shape = [n_classes (true), n_classes (pred)]\n",
    "                Confusion matrix, where the element M_{rc} means\n",
    "                the number of times when the classifier or subject\n",
    "                guesses that a test sample in the r-th class\n",
    "                belongs to the c-th class.\n",
    "            B: ignored\n",
    "    mode: {'binary', 'sample', 'rate'}, optional, (default='binary')\n",
    "        Directs the interpretation of A and B.\n",
    "    max_value: float, optional (default=np.inf)\n",
    "        Maximum possible d-prime value.\n",
    "    min_value: float, optional (default=-np.inf)\n",
    "        Minimum possible d-prime value.\n",
    "    max_ppf_value: float, optional (default=np.inf)\n",
    "        Maximum possible ppf value.\n",
    "        Used only when mode is 'rate' or 'confusionmat'.\n",
    "    min_ppf_value: float, optional (default=-np.inf).\n",
    "        Minimum possible ppf value.\n",
    "        Used only when mode is 'rate' or 'confusionmat'.\n",
    "    kwargs: named arguments, optional\n",
    "        Passed to ``confusion_matrix_stats()`` and used only when `mode`\n",
    "        is 'confusionmat'.  By assigning ``collation``,\n",
    "        ``fudge_mode``, ``fudge_factor``, etc. one can\n",
    "        change the behavior of d-prime computation\n",
    "        (see ``confusion_matrix_stats()`` for details).\n",
    "    Returns\n",
    "    -------\n",
    "    dp: float or array of shape = [n_groupings]\n",
    "        A d-prime value or array of d-primes, where each element\n",
    "        corresponds to each grouping of positives and negatives\n",
    "        (when `mode` is 'rate' or 'confusionmat')\n",
    "    References\n",
    "    ----------\n",
    "    http://en.wikipedia.org/wiki/D'\n",
    "    http://en.wikipedia.org/wiki/Confusion_matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # -- basic checks and conversion\n",
    "    if mode == 'sample':\n",
    "        pos, neg = np.array(A), np.array(B)\n",
    "\n",
    "    elif mode == 'binary':\n",
    "        y_true, y_pred = A, B\n",
    "\n",
    "        assert len(y_true) == len(y_pred)\n",
    "        assert np.isfinite(y_true).all()\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        assert y_true.ndim == 1\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "        assert y_pred.ndim == 1\n",
    "\n",
    "        i_pos = y_true > 0\n",
    "        i_neg = ~i_pos\n",
    "\n",
    "        pos = y_pred[i_pos]\n",
    "        neg = y_pred[i_neg]\n",
    "\n",
    "    elif mode == 'rate':\n",
    "        TPR, FPR = np.array(A), np.array(B)\n",
    "        assert TPR.shape == FPR.shape\n",
    "\n",
    "    elif mode == 'confusionmat':\n",
    "        # A: confusion mat\n",
    "        # row means true classes, col means predicted classes\n",
    "        P, N, TP, _, FP, _ = confusion_matrix_stats(A, **kwargs)\n",
    "\n",
    "        TPR = TP / P\n",
    "        FPR = FP / N\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid mode')\n",
    "\n",
    "    # -- compute d'\n",
    "    if mode in ['sample', 'binary']:\n",
    "        assert np.isfinite(pos).all()\n",
    "        assert np.isfinite(neg).all()\n",
    "\n",
    "        if pos.size <= 1:\n",
    "            raise ValueError('Not enough positive samples'\\\n",
    "                    'to estimate the variance')\n",
    "        if neg.size <= 1:\n",
    "            raise ValueError('Not enough negative samples'\\\n",
    "                    'to estimate the variance')\n",
    "\n",
    "        pos_mean = pos.mean()\n",
    "        neg_mean = neg.mean()\n",
    "        pos_var = pos.var(ddof=1)\n",
    "        neg_var = neg.var(ddof=1)\n",
    "\n",
    "        num = pos_mean - neg_mean\n",
    "        div = np.sqrt((pos_var + neg_var) / 2.)\n",
    "\n",
    "        dp = num / div\n",
    "\n",
    "    else:   # mode is rate or confusionmat\n",
    "        ppfTPR = norm.ppf(TPR)\n",
    "        ppfFPR = norm.ppf(FPR)\n",
    "        ppfTPR = np.clip(ppfTPR, min_ppf_value, max_ppf_value)\n",
    "        ppfFPR = np.clip(ppfFPR, min_ppf_value, max_ppf_value)\n",
    "        dp = ppfTPR - ppfFPR\n",
    "\n",
    "    # from Dan's suggestion about clipping d' values...\n",
    "    dp = np.clip(dp, min_value, max_value)\n",
    "\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_samples = .where(lg_both.numeric_label==1,drop=True).values[:,250]\n",
    "# neg_samples = lg_both.where(lg_both.numeric_label!=1, drop=True).values[:,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_exclude_zero_dim(da,neuroid_coord):\n",
    "    nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "    return da[:,nz_neuroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUCorrelation(da,neuroid_coord,correlation_vars,exclude_zeros=True):\n",
    "    if exclude_zeros:\n",
    "        nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "        da = da[:,nz_neuroids]\n",
    "    \n",
    "    correlations = np.empty((len(da[neuroid_coord]),len(correlation_vars)))\n",
    "    for i,nid in tqdm(enumerate(da[neuroid_coord].values),total=len(da[neuroid_coord])):\n",
    "        for j,prop in enumerate(correlation_vars):\n",
    "            n_act = da.sel(**{neuroid_coord:nid}).squeeze()\n",
    "            r,p = pearsonr(n_act,prop)\n",
    "            correlations[i,j] = np.abs(r)\n",
    "\n",
    "    neuroid_dim = da[neuroid_coord].dims\n",
    "    c = {coord: (dims, values) for coord, dims, values in walk_coords(da) if dims == neuroid_dim}\n",
    "    c['task']=('task',[v.name for v in correlation_vars])\n",
    "#     print(neuroid_dim)\n",
    "    result = Score(correlations,\n",
    "                       coords=c,\n",
    "                       dims=('neuroid','task'))\n",
    "    return result\n",
    "\n",
    "def SUDprime(da,neuroid_coord='neuroid_id',class_coord='numeric_label',exclude_zeros=True):    \n",
    "    if exclude_zeros:\n",
    "            nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "            da = da[:,nz_neuroids]\n",
    "    \n",
    "    def cat_parts(da,class_coord):\n",
    "        out = [np.concatenate([da[(da[class_coord]==c).values].values,da[(da[class_coord]!=c).values]],axis=0) for c in class_vals]\n",
    "        return np.array(out)\n",
    "\n",
    "    def dprime_1d(vec,cut=1000):\n",
    "        return dprime(A=vec[:cut],B=vec[cut:],mode='sample',max_value=1,min_value=-1)\n",
    "    \n",
    "#     class_vals = np.unique(da[class_coord].values)\n",
    "#     parts = [((da[class_coord]==c).values,(da[class_coord]!=c).values) for c in class_vals]\n",
    "    class_vals = np.unique(da[class_coord].values)\n",
    "\n",
    "    c_parts = cat_parts(da,class_coord)\n",
    "    \n",
    "    dprimes = np.empty((len(da[neuroid_coord]),len(class_vals)))\n",
    "    for i,nid in tqdm(enumerate(da[neuroid_coord].values),total=dprimes.shape[0]):\n",
    "#         da_n = da.sel(**{neuroid_coord:nid})\n",
    "        dpn = np.apply_along_axis(dprime_1d,1,c_parts[:,:,i])\n",
    "        dprimes[i] = dpn\n",
    "#         for j,pos_neg in enumerate(parts):\n",
    "#             pos,neg = pos_neg\n",
    "#             pos_samples = da_n[pos].values\n",
    "#             neg_samples = da_n[neg].values\n",
    "#             dp = dprime(A=pos_samples,B=neg_samples,mode='sample',max_value=1,min_value=-1)\n",
    "#             dprimes[i,j]=dp\n",
    "\n",
    "    neuroid_dim = da[neuroid_coord].dims\n",
    "    c = {coord: (dims, values) for coord, dims, values in walk_coords(da) if dims == neuroid_dim}\n",
    "    c['task']=('task',['category'])\n",
    "#     print(neuroid_dim)\n",
    "    result = Score(dprimes.max(axis=1).reshape(-1,1),\n",
    "                       coords=c,\n",
    "                       dims=('neuroid','task'))\n",
    "    return result\n",
    "\n",
    "def result_to_df(SUC,corr_var_labels):\n",
    "    df = SUC.neuroid.to_dataframe().reset_index()\n",
    "    for label in corr_var_labels:\n",
    "        df[label]=SUC.sel(task=label).values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_parts(da,class_coord):\n",
    "    class_vals = np.unique(da[class_coord].values)\n",
    "    out = [np.concatenate([da[(da[class_coord]==c).values].values,da[(da[class_coord]!=c).values]],axis=0) for c in class_vals]\n",
    "    return out\n",
    "\n",
    "def dprime_1d(vec,cut=1000):\n",
    "    return dprime(A=vec[:cut],B=vec[cut:],mode='sample',max_value=1,min_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gu_SUD(da_sets,neuroid_coord):\n",
    "    pool = mp.Pool(6)\n",
    "    results = [pool.apply(SUDprime,args=(da,neuroid_coord)) for da in da_sets]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_sets = [xr_exclude_zero_dim(lg_both.sel(region=r),'neuroid_id') for r in np.unique(lg_both.region.values)]\n",
    "both_cat_results = gu_SUD(region_sets,'neuroid_id')\n",
    "# both_SUdp_score = [SUDprime(rsets,neuroid_coord='neuroid_id',) for rsets in region_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_SUdp_score = SUDprime(lg_xent,neuroid_coord='neuroid_id',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_both = [pd.Series(lg_both[v].values,name=v) for v in ['tx','ty']]\n",
    "corr_both = SUCorrelation(lg_both,neuroid_coord='neuroid_id',correlation_vars=corr_vars_both)\n",
    "su_both_df = result_to_df(corr_both,['tx','ty'])\n",
    "su_both_df['norm_ty'] = su_both_df.ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df_dp = pd.concat([result_to_df(res,['category']) for res in both_cat_results]).reset_index().drop(columns=['index'])\n",
    "# su_both_df['category'] = both_df_dp.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df_dp = both_df_dp.sort_values(by='neuroid_id').reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both_df = su_both_df.sort_values(by='neuroid_id').reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both_df = pd.concat([su_both_df,both_df_dp[['neuroid_id','category']]],axis=1)\n",
    "su_both_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_xent = [pd.Series(lg_xent[v].values,name=v) for v in ['tx','ty']]\n",
    "corr_xent = SUCorrelation(lg_xent,neuroid_coord='neuroid_id',correlation_vars=corr_vars_xent)\n",
    "su_xent_df = result_to_df(corr_xent,['tx','ty'])\n",
    "su_xent_df['norm_ty'] = su_xent_df.ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_df_dp = result_to_df(xent_SUdp_score,['category'])\n",
    "su_xent_df['category'] = xent_df_dp.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_data = process_dicarlo(neural_data,variation=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_corr_vars = [\n",
    "    pd.Series(hi_data['ty'],name='tx'),\n",
    "    pd.Series(hi_data['tz'],name='ty'),\n",
    "    pd.Series(hi_data['rxy'],name='rxy'),\n",
    "\n",
    "]\n",
    "\n",
    "# corr_dicarlo_med = SUCorrelation(med_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_med_corr_vars,exclude_zeros=True)\n",
    "# dicarlo_med_df = result_to_df(corr_dicarlo_med,['tx','ty','rxy'])\n",
    "# dicarlo_med_df['variation']=3\n",
    "\n",
    "corr_dicarlo_hi = SUCorrelation(hi_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_corr_vars,exclude_zeros=True)\n",
    "dicarlo_df = result_to_df(corr_dicarlo_hi, ['tx','ty','rxy'])\n",
    "layer_map = {\n",
    "    'V4':3,\n",
    "    'IT':4\n",
    "}\n",
    "\n",
    "for reg,layer in zip(['V4','IT'],[3,4]):\n",
    "    dicarlo_df['layer'] = [layer_map[r] for r in dicarlo_df.region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_SUdp_score = SUDprime(hi_data,neuroid_coord='neuroid_id',class_coord='category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_SUdp_df = result_to_df(dicarlo_SUdp_score,['category'])\n",
    "dicarlo_df['category']=dicarlo_SUdp_df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.experiment_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both_df['unit_id'] = su_both_df.neuroid_id.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_xent_df.drop(columns=['neuroid']).to_parquet(os.path.join(lg.experiment_root,'su_xent_processed'))\n",
    "su_both_df.drop(columns=['neuroid','neuroid_id']).to_parquet(os.path.join(lg.experiment_root,'su_both_processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_df.drop(columns='neuroid').to_parquet(os.path.join(lg.experiment_root,'dicarlo.Majaj_processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(y,df,by='region',order=None):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets),plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "#                                'xlim':(0.0,0.8),\n",
    "#                                'ylim':(0.0,0.8)\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.barplot(x=by,y=y,ax=ax)\n",
    "\n",
    "def plot_kde(x,y,df,by='region',order=None,xlim=(0.0,0.8),ylim=(0.0,0.8)):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets)*0.8,plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "                               'xlim':xlim,\n",
    "                               'ylim':ylim,\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.kdeplot(sub_df[x],sub_df[y],ax=ax)\n",
    "        ax.set_title(\"{}: {}\".format(by,sub))\n",
    "    \n",
    "    return fig,axs\n",
    "#         sns.despine(ax)\n",
    "# plot_bars(y='tx',df=both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(8,6),sharex=True,sharey=True,subplot_kw={'ylim':(0,0.35)})\n",
    "\n",
    "mod_order=np.arange(5)\n",
    "# mod_order = ['pixel','dense_1','dense_2','dense_3','z_lat','y_lat']\n",
    "\n",
    "sns.set_context('talk')\n",
    "properties = ['tx','ty']\n",
    "for ax_row,df,order in zip(axs,[su_xent_df,su_both_df,],[mod_order,mod_order]): \n",
    "    for ax,prop in zip(ax_row,properties):\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df,ax=ax,palette='magma')\n",
    "        sns.despine(ax=ax)\n",
    "    \n",
    "    ax_row[1].set_ylabel('')\n",
    "    ax_row[0].set_ylabel('pearson')\n",
    "    \n",
    "\n",
    "for ax in axs[1]:\n",
    "    ax.set_xticklabels(['pixel','1','2','3','4'])\n",
    "for ax,prop in zip(axs[0],properties):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(prop)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['category','tx']\n",
    "fig,axs = plt.subplots(2,len(properties),figsize=(len(properties)*4,6),sharex=True,sharey=True)\n",
    "\n",
    "mod_order=np.arange(5)\n",
    "# mod_order = ['pixel','dense_1','dense_2','dense_3','z_lat','y_lat']\n",
    "\n",
    "sns.set_context('talk')\n",
    "for ax_row,df,order in zip(axs,[su_xent_df,su_both_df,],[mod_order,mod_order]): \n",
    "    for ax,prop in zip(ax_row,properties):\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df,ax=ax,palette='magma')\n",
    "        sns.despine(ax=ax)\n",
    "    \n",
    "    ax_row[1].set_ylabel('')\n",
    "    ax_row[0].set_ylabel('d\\'')\n",
    "    \n",
    "\n",
    "for ax in axs[1]:\n",
    "    ax.set_xticklabels(['pixel','1','2','3','4'])\n",
    "\n",
    "for ax,prop in zip(axs[0],properties):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(prop)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=[0,1,2,3,4,5]\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,4.5))\n",
    "sns.set_context('talk')\n",
    "sns.boxplot(x='layer',y='tx',order=order,data=dicarlo_df,ax=ax,palette='magma')\n",
    "ax.set_xticklabels(['pixel','V1','?','V4','IT',''])\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [['tx','ty','rxy','layer','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topn_su_decode(df,n,props,**kwargs):\n",
    "    order=[0,1,2,3,4]\n",
    "    fig,axs = plt.subplots(1,len(props),figsize=(len(props)*4,3),sharey=True,**kwargs)\n",
    "    sns.set_context('talk')\n",
    "    for ax,prop in zip(axs,props):\n",
    "        df_topn = pd.concat([df.query('layer == {}'.format(l)).nlargest(n,prop) for l in [3,4]])\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df_topn,ax=ax,palette='magma')\n",
    "        ax.set_xticklabels(['pixel','V1','?','V4','IT'])\n",
    "        ax.set_ylabel('d\\'')\n",
    "        sns.despine(ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "topn_su_decode(dicarlo_df,n=15,props=['tx','ty'],subplot_kw={'ylim':(0,0.4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_su_decode(dicarlo_df,n=15,props=['category','tx'],subplot_kw={'ylim':(0,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True,sharex=True)\n",
    "\n",
    "mod_order=np.arange(5)\n",
    "\n",
    "sns.set_context('talk')\n",
    "for ax,df,order in zip(axs,[su_xent_df,su_both_df,],[mod_order,mod_order]): \n",
    "    sns.barplot(x='layer',y='tx',order=order,data=df,ax=ax)\n",
    "axs[0].set_xticklabels(['pixel','1','2','3','4'])\n",
    "axs[1].get_yaxis().set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "fig,axs = plot_kde('tx','ty',su_xent_df,by='layer',order=np.arange(5),)\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',su_xent_df,by='layer',order=np.arange(5),xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',su_both_df,by='layer',order=np.arange(5),xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('ty','category',su_both_df,by='layer',order=np.arange(5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',dicarlo_df,by='region',order=['V4','IT'],xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','category',dicarlo_df,by='region',order=['V4','IT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='tx',y='ty',data=dicarlo_df.query('region == \"IT\"'))\n",
    "plt.ylim(0,0.5)\n",
    "plt.xlim(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURegressor(object):\n",
    "    def __init__(self,da,train_frac=0.8,n_splits=5,n_units=None,estimator=Ridge):\n",
    "        if n_units is not None:\n",
    "            self.neuroid_idxs = [np.array([random.randrange(len(da.neuroid_id)) for _ in range(n_units)]) for _ in range(n_splits)]\n",
    "        \n",
    "        self.original_data = da\n",
    "        self.train_frac = train_frac\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        splits = [split_assembly(self.original_data[:,n_idxs]) for n_idxs in tqdm(self.neuroid_idxs,total=n_splits,desc='CV-splitting')]\n",
    "        self.train = [tr for tr,te in splits]\n",
    "        self.test = [te for tr,te in splits]\n",
    "        \n",
    "        \n",
    "        self.estimators = [estimator() for _ in range(n_splits)]\n",
    "        \n",
    "    def fit(self,y_coord):\n",
    "        # Get Training data\n",
    "        for mod,train in tqdm(zip(self.estimators,self.train),total=len(self.train),desc='fitting'):\n",
    "#             print(train)\n",
    "            mod.fit(X=train.values,y=train[y_coord])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X=None):\n",
    "        if X is not None:\n",
    "            return [e.predict(X) for e in self.estimators]\n",
    "        else:\n",
    "            return [e.predict(te.values) for e,te in zip(self.estimators,self.test)]\n",
    "        \n",
    "    def score(self,y_coord):\n",
    "        return [e.score(te.values,te[y_coord].values) for e,te in zip(self.estimators,self.test)]\n",
    "    \n",
    "def stratified_regressors(data, filt='region',n_units=126,y_coords=['ty','tz'],task_names=None,estimator=Ridge):\n",
    "    subsets = np.unique(data[filt].values)\n",
    "    if task_names is None:\n",
    "        task_names = y_coords\n",
    "    dfs = []\n",
    "    for y,task in zip(y_coords,task_names):\n",
    "        print('regressing {}...'.format(y))\n",
    "        regressors = {k:MURegressor(data.sel(**{filt:k}),n_units=n_units,estimator=Ridge).fit(y_coord=y) for k in subsets}\n",
    "        df = pd.DataFrame.from_records({k:v.score(y_coord=y) for k,v in regressors.items()})\n",
    "        df = df.melt(var_name='region',value_name='performance')\n",
    "        df['task']=task\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['tx','ty']\n",
    "mu_both_df = stratified_regressors(lg_both,filt='layer',y_coords=properties,n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',data=mu_both_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_xent_df = stratified_regressors(lg_xent,filt='layer',y_coords=properties,n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',data=mu_xent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(x='tx',y='ty',df=both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(x='tx',y='ty',df=xent_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-fastai (Python3.6.1)",
   "language": "python",
   "name": "py3-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
