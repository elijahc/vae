{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "import neptune\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm as tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV\n",
    "\n",
    "import brainscore\n",
    "from brainscore.assemblies import walk_coords,split_assembly\n",
    "from brainscore.assemblies import split_assembly\n",
    "from brainscore.metrics import Score\n",
    "\n",
    "from brainio_base.assemblies import DataAssembly\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from src.results.experiments import _DateExperimentLoader\n",
    "from src.results.utils import raw_to_xr, dprime\n",
    "from src.results.neptune import get_model_files, load_models, load_assemblies, load_params, load_properties,create_assemblies\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.data_generator import ShiftedDataBatcher\n",
    "\n",
    "def set_style():\n",
    "    # This sets reasonable defaults for font size for\n",
    "    # a figure that will go in a paper\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    # Set the font to be serif, rather than sans\n",
    "    sns.set(font='serif')\n",
    "    \n",
    "    # Make the background white, and specify the\n",
    "    # specific font family\n",
    "    sns.set_style(\"white\", {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"Palatino\", \"serif\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(elijahc/DuplexAE)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5tbCIsImFwaV9rZXkiOiI3ZWExMTlmYS02ZTE2LTQ4ZTktOGMxMi0wMDJiZTljOWYyNDUifQ==\"\n",
    "neptune.init('elijahc/DuplexAE')\n",
    "neptune.set_project('elijahc/DuplexAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root = '/home/elijahc/projects/vae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = neptune.project.get_experiments(id=['DPX-10','DPX-16'])\n",
    "# mod = next(load_models(proj_root,exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(proj_root,e.get_properties()['dir'])\n",
    "PARAMS = e.get_parameters()\n",
    "PROPS = e.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = ShiftedDataBatcher(PROPS['dataset'],translation=PARAMS['im_translation'],bg=PARAMS['bg'],\n",
    "                        blend=None,\n",
    "#                         blend='difference',\n",
    "                        batch_size=PARAMS['batch_sz'],\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = Shifted_Data_Loader('fashion_mnist',rotation=None,translation=0.75,bg='natural',flatten=False)\n",
    "sx_test = DL.sx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sx_test[250].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug = [(dx,dy,float(lab),float(rxy)) for dx,dy,rxy,lab in zip(DL.dx[1]-14,DL.dy[1]-14,DL.dtheta[1],DL.y_test)]\n",
    "# stim_set = pd.DataFrame({'dx':DL.dx[1]-14,'dy':DL.dy[1]-14,'numeric_label':DL.y_test,'rxy':DL.dtheta[1],'image_id':image_id})\n",
    "\n",
    "ca = create_assemblies(proj_root,exps,test_data=sx_test,slug=slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg_both = xrs[0]\n",
    "# lg_xent = xrs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exps[0].get_properties()['dir']\n",
    "# mod_dir = os.path.join(proj_root,exps[0].get_properties()['dir'])\n",
    "# save_assembly(out,run_dir=mod_dir,fname='dataset.nc',\n",
    "#     format='NETCDF3_64BIT',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das = load_assemblies(proj_root,exps)\n",
    "# lg_both = next(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg_xent = lg.assemblies[0]\n",
    "# lg_both = lg.assemblies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data = brainscore.get_assembly(name=\"dicarlo.Majaj2015\")\n",
    "neural_data.load()\n",
    "stimulus_set = neural_data.attrs['stimulus_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dicarlo(assembly,avg_repetition=True,variation=3,tasks=['ty','tz','rxy']):\n",
    "    stimulus_set = assembly.attrs['stimulus_set']\n",
    "    stimulus_set['dy_deg'] = stimulus_set.tz*stimulus_set.degrees\n",
    "    stimulus_set['dx_deg'] = stimulus_set.ty*stimulus_set.degrees\n",
    "    stimulus_set['dy_px'] = stimulus_set.dy_deg*32\n",
    "    stimulus_set['dx_px'] = stimulus_set.dx_deg*32\n",
    "    \n",
    "    assembly.attrs['stimulus_set'] = stimulus_set\n",
    "    \n",
    "    data = assembly.sel(variation=variation)\n",
    "    groups = ['category_name', 'object_name', 'image_id']+tasks\n",
    "    if not avg_repetition:\n",
    "        groups.append('repetition')\n",
    "        \n",
    "    data = data.multi_groupby(groups)     # (2)\n",
    "    data = data.mean(dim='presentation')\n",
    "    data = data.squeeze('time_bin')    #   (3)\n",
    "    data.attrs['stimulus_set'] = stimulus_set.query('variation == {}'.format(variation))\n",
    "    data = data.T\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_samples = .where(lg_both.numeric_label==1,drop=True).values[:,250]\n",
    "# neg_samples = lg_both.where(lg_both.numeric_label!=1, drop=True).values[:,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_exclude_zero_dim(da,neuroid_coord):\n",
    "    nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "    return da[:,nz_neuroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUCorrelation(da,neuroid_coord,correlation_vars,exclude_zeros=True):\n",
    "    if exclude_zeros:\n",
    "        nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "        da = da[:,nz_neuroids]\n",
    "    \n",
    "    correlations = np.empty((len(da[neuroid_coord]),len(correlation_vars)))\n",
    "    for i,nid in tqdm(enumerate(da[neuroid_coord].values),total=len(da[neuroid_coord])):\n",
    "        for j,prop in enumerate(correlation_vars):\n",
    "            n_act = da.sel(**{neuroid_coord:nid}).squeeze()\n",
    "            r,p = pearsonr(n_act,prop)\n",
    "            correlations[i,j] = np.abs(r)\n",
    "\n",
    "    neuroid_dim = da[neuroid_coord].dims\n",
    "    c = {coord: (dims, values) for coord, dims, values in walk_coords(da) if dims == neuroid_dim}\n",
    "    c['task']=('task',[v.name for v in correlation_vars])\n",
    "#     print(neuroid_dim)\n",
    "    result = Score(correlations,\n",
    "                       coords=c,\n",
    "                       dims=('neuroid','task'))\n",
    "    return result\n",
    "\n",
    "def SUDprime(da,neuroid_coord='neuroid_id',class_coord='numeric_label',exclude_zeros=True):    \n",
    "    if exclude_zeros:\n",
    "            nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "            da = da[:,nz_neuroids]\n",
    "    \n",
    "    def cat_parts(da,class_coord):\n",
    "        out = [np.concatenate([da[(da[class_coord]==c).values].values,da[(da[class_coord]!=c).values]],axis=0) for c in class_vals]\n",
    "        return np.array(out)\n",
    "\n",
    "    def dprime_1d(vec,cut=1000):\n",
    "        return dprime(A=vec[:cut],B=vec[cut:],mode='sample',max_value=1,min_value=-1)\n",
    "    \n",
    "#     class_vals = np.unique(da[class_coord].values)\n",
    "#     parts = [((da[class_coord]==c).values,(da[class_coord]!=c).values) for c in class_vals]\n",
    "    class_vals = np.unique(da[class_coord].values)\n",
    "\n",
    "    c_parts = cat_parts(da,class_coord)\n",
    "    \n",
    "    dprimes = np.empty((len(da[neuroid_coord]),len(class_vals)))\n",
    "    for i,nid in tqdm(enumerate(da[neuroid_coord].values),total=dprimes.shape[0]):\n",
    "#         da_n = da.sel(**{neuroid_coord:nid})\n",
    "        dpn = np.apply_along_axis(dprime_1d,1,c_parts[:,:,i])\n",
    "        dprimes[i] = dpn\n",
    "\n",
    "    neuroid_dim = da[neuroid_coord].dims\n",
    "    c = {coord: (dims, values) for coord, dims, values in walk_coords(da) if dims == neuroid_dim}\n",
    "    c['task']=('task',['category'])\n",
    "#     print(neuroid_dim)\n",
    "    result = Score(dprimes.max(axis=1).reshape(-1,1),\n",
    "                       coords=c,\n",
    "                       dims=('neuroid','task'))\n",
    "    return result\n",
    "\n",
    "def result_to_df(SUC,corr_var_labels):\n",
    "    df = SUC.neuroid.to_dataframe().reset_index()\n",
    "    for label in corr_var_labels:\n",
    "        df[label]=SUC.sel(task=label).values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_parts(da,class_coord):\n",
    "    class_vals = np.unique(da[class_coord].values)\n",
    "    out = [np.concatenate([da[(da[class_coord]==c).values].values,da[(da[class_coord]!=c).values]],axis=0) for c in class_vals]\n",
    "    return out\n",
    "\n",
    "def dprime_1d(vec,cut=1000):\n",
    "    return dprime(A=vec[:cut],B=vec[cut:],mode='sample',max_value=1,min_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gu_SUD(da_sets,neuroid_coord):\n",
    "    pool = mp.Pool(6)\n",
    "    results = [pool.apply(SUDprime,args=(da,neuroid_coord)) for da in da_sets]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_assembly(da):\n",
    "    # Calculate dprime for single units\n",
    "    print('Calculating dprime of all units...')\n",
    "    SUdp_score = SUDprime(da,neuroid_coord='neuroid_id',)\n",
    "    df_dp = result_to_df(SUdp_score,['category'])\n",
    "    \n",
    "    corr_vars = [pd.Series(da[v].values,name=v) for v in ['tx','ty']]\n",
    "    corr = SUCorrelation(da,neuroid_coord='neuroid_id',correlation_vars=corr_vars)\n",
    "    su_df = result_to_df(corr,['tx','ty'])\n",
    "    df_dp = df_dp.sort_values(by='neuroid_id').reset_index().drop(columns='index')\n",
    "    su_df = su_df.sort_values(by='neuroid_id').reset_index().drop(columns='index')\n",
    "    su_df['category'] = df_dp.category\n",
    "\n",
    "    return su_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_sets = [xr_exclude_zero_dim(lg_both.sel(region=r),'neuroid_id') for r in np.unique(lg_both.region.values)]\n",
    "# both_cat_results = gu_SUD(region_sets,'neuroid_id')\n",
    "# both_SUdp_score = [SUDprime(rsets,neuroid_coord='neuroid_id',) for rsets in region_sets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_xent = process_assembly(next(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_xent = su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both = process_assembly(next(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_SUdp_score = SUDprime(lg_xent,neuroid_coord='neuroid_id',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df_dp = both_df_dp.sort_values(by='neuroid_id').reset_index().drop(columns='index')\n",
    "su_both_df = su_both_df.sort_values(by='neuroid_id').reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_both_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_xent = [pd.Series(lg_xent[v].values,name=v) for v in ['tx','ty']]\n",
    "corr_xent = SUCorrelation(lg_xent,neuroid_coord='neuroid_id',correlation_vars=corr_vars_xent)\n",
    "su_xent_df = result_to_df(corr_xent,['tx','ty'])\n",
    "su_xent_df['norm_ty'] = su_xent_df.ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_df_dp = result_to_df(xent_SUdp_score,['category'])\n",
    "su_xent_df['category'] = xent_df_dp.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_data = process_dicarlo(neural_data,variation=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_corr_vars = [\n",
    "    pd.Series(hi_data['ty'],name='tx'),\n",
    "    pd.Series(hi_data['tz'],name='ty'),\n",
    "    pd.Series(hi_data['rxy'],name='rxy'),\n",
    "\n",
    "]\n",
    "\n",
    "# corr_dicarlo_med = SUCorrelation(med_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_med_corr_vars,exclude_zeros=True)\n",
    "# dicarlo_med_df = result_to_df(corr_dicarlo_med,['tx','ty','rxy'])\n",
    "# dicarlo_med_df['variation']=3\n",
    "\n",
    "corr_dicarlo_hi = SUCorrelation(hi_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_corr_vars,exclude_zeros=True)\n",
    "dicarlo_df = result_to_df(corr_dicarlo_hi, ['tx','ty','rxy'])\n",
    "layer_map = {\n",
    "    'V4':3,\n",
    "    'IT':4\n",
    "}\n",
    "\n",
    "for reg,layer in zip(['V4','IT'],[3,4]):\n",
    "    dicarlo_df['layer'] = [layer_map[r] for r in dicarlo_df.region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_SUdp_score = SUDprime(hi_data,neuroid_coord='neuroid_id',class_coord='category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_SUdp_df = result_to_df(dicarlo_SUdp_score,['category'])\n",
    "dicarlo_df['category']=dicarlo_SUdp_df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dirs = [os.path.join(proj_root,e.get_properties()['dir']) for e in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.get_parameters()['recon_weight'] for e in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dr,df in zip(mod_dirs,[su_xent,su_both]):\n",
    "    fp = os.path.join(dr,'su_selectivity.pqt')\n",
    "    print(fp)\n",
    "    df.drop(columns=['neuroid','neuroid_id']).to_parquet(fp)\n",
    "#     su_both_df.drop(columns=['neuroid','neuroid_id']).to_parquet(os.path.join(mod_dirs[0],'su_w_recon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_df.drop(columns='neuroid').to_parquet(os.path.join(proj_root,'data','dicarlo.Majaj_processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(y,df,by='region',order=None):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets),plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "#                                'xlim':(0.0,0.8),\n",
    "#                                'ylim':(0.0,0.8)\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.barplot(x=by,y=y,ax=ax)\n",
    "\n",
    "def plot_kde(x,y,df,by='region',order=None,xlim=(0.0,0.8),ylim=(0.0,0.8)):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets)*0.8,plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "                               'xlim':xlim,\n",
    "                               'ylim':ylim,\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.kdeplot(sub_df[x],sub_df[y],ax=ax)\n",
    "        ax.set_title(\"{}: {}\".format(by,sub))\n",
    "    \n",
    "    return fig,axs\n",
    "#         sns.despine(ax)\n",
    "# plot_bars(y='tx',df=both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topn_su_decode(df,n,props,**kwargs):\n",
    "    order=[0,1,2,3,4]\n",
    "    fig,axs = plt.subplots(1,len(props),figsize=(len(props)*4,3),sharey=True,**kwargs)\n",
    "    sns.set_context('talk')\n",
    "    for ax,prop in zip(axs,props):\n",
    "        df_topn = pd.concat([df.query('layer == {}'.format(l)).nlargest(n,prop) for l in [3,4]])\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df_topn,ax=ax,palette='magma')\n",
    "        ax.set_xticklabels(['pixel','V1','?','V4','IT'])\n",
    "#         ax.set_ylabel('d\\'')\n",
    "        ax.set_ylabel('perf')\n",
    "        ax.set_title(prop)\n",
    "        sns.despine(ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "topn_su_decode(dicarlo_df,n=50,props=['category','ty'],\n",
    "#                subplot_kw={'ylim':(0,0.5)},\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(8,6),sharex=True,sharey=True)\n",
    "\n",
    "mod_order=np.arange(5)\n",
    "# mod_order = ['pixel','dense_2','dense_3','y_lat','z_lat']\n",
    "\n",
    "sns.set_context('talk')\n",
    "properties = ['tx','ty']\n",
    "for ax_row,df,order in zip(axs,[su_xent,su_both,],[mod_order,mod_order]): \n",
    "    for ax,prop in zip(ax_row,properties):\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df,ax=ax,palette='magma')\n",
    "        sns.despine(ax=ax)\n",
    "    \n",
    "    ax_row[1].set_ylabel('')\n",
    "    ax_row[0].set_ylabel('pearson')\n",
    "    \n",
    "\n",
    "for ax in axs[1]:\n",
    "    ax.set_xticklabels(['pixel','1','2','3','4'])\n",
    "#     ax.set_xticklabels(['pixel','L2','L3','y_lat','z_lat'])\n",
    "\n",
    "for ax,prop in zip(axs[0],properties):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(prop)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['category','tx','ty']\n",
    "fig,axs = plt.subplots(2,len(properties),figsize=(len(properties)*4,6),sharex=True,sharey=True)\n",
    "\n",
    "# mod_order=np.arange(5)\n",
    "mod_order = [0,2,3]\n",
    "# mod_order = ['pixel','dense_2','dense_3','y_lat']\n",
    "\n",
    "sns.set_context('talk')\n",
    "for ax_row,df,order in zip(axs,[su_xent,su_both,],[mod_order,mod_order]): \n",
    "    for ax,prop in zip(ax_row,properties):\n",
    "        sns.barplot(x='layer',y=prop,order=order,data=df,ax=ax,palette='magma')\n",
    "        sns.despine(ax=ax)\n",
    "    \n",
    "    ax_row[1].set_ylabel('')\n",
    "    ax_row[2].set_ylabel('')\n",
    "    ax_row[0].set_ylabel('d\\'')\n",
    "    \n",
    "\n",
    "for ax in axs[1]:\n",
    "    ax.set_xticklabels(['pixel','2','3'])\n",
    "\n",
    "#     ax.set_xticklabels(mod_order)\n",
    "\n",
    "for ax,prop in zip(axs[0],properties):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(prop)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=[0,1,2,3,4,5]\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,4.5))\n",
    "sns.set_context('talk')\n",
    "sns.boxplot(x='layer',y='category',order=order,data=dicarlo_df,ax=ax,palette='magma')\n",
    "ax.set_xticklabels(['pixel','V1','?','V4','IT',''])\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [['tx','ty','rxy','layer','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_su_decode(dicarlo_df,n=100,props=['category','tx','ty'],\n",
    "#                subplot_kw={'ylim':(0,0.8)},\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True,sharex=True)\n",
    "\n",
    "mod_order=np.arange(5)\n",
    "\n",
    "sns.set_context('talk')\n",
    "for ax,df,order in zip(axs,[su_xent_df,su_both_df,],[mod_order,mod_order]): \n",
    "    sns.barplot(x='layer',y='tx',order=order,data=df,ax=ax)\n",
    "axs[0].set_xticklabels(['pixel','1','2','3','4'])\n",
    "axs[1].get_yaxis().set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "fig,axs = plot_kde('tx','ty',su_xent_df,by='layer',order=np.arange(5),)\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',su_xent_df,by='layer',order=np.arange(5),xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',su_both_df,by='layer',order=np.arange(5),xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('ty','category',su_both_df,by='layer',order=np.arange(5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(font_scale=2)\n",
    "fig,axs = plot_kde('ty','category',dicarlo_df,by='region',order=['V4','IT'],xlim=(0,1.1),ylim=(0,1.1))\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "for i,ax in enumerate(axs):\n",
    "    pass\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','category',dicarlo_df,by='region',order=['V4','IT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='tx',y='ty',data=dicarlo_df.query('region == \"IT\"'))\n",
    "plt.ylim(0,0.5)\n",
    "plt.xlim(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURegressor(object):\n",
    "    def __init__(self,da,train_frac=0.8,n_splits=5,n_units=None,estimator=Ridge):\n",
    "        if n_units is not None:\n",
    "            self.neuroid_idxs = [np.array([random.randrange(len(da.neuroid_id)) for _ in range(n_units)]) for _ in range(n_splits)]\n",
    "        \n",
    "        self.original_data = da\n",
    "        self.train_frac = train_frac\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        splits = [split_assembly(self.original_data[:,n_idxs]) for n_idxs in tqdm(self.neuroid_idxs,total=n_splits,desc='CV-splitting')]\n",
    "        self.train = [tr for tr,te in splits]\n",
    "        self.test = [te for tr,te in splits]\n",
    "        \n",
    "        \n",
    "        self.estimators = [estimator() for _ in range(n_splits)]\n",
    "        \n",
    "    def fit(self,y_coord):\n",
    "        # Get Training data\n",
    "        for mod,train in tqdm(zip(self.estimators,self.train),total=len(self.train),desc='fitting'):\n",
    "#             print(train)\n",
    "            mod.fit(X=train.values,y=train[y_coord])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X=None):\n",
    "        if X is not None:\n",
    "            return [e.predict(X) for e in self.estimators]\n",
    "        else:\n",
    "            return [e.predict(te.values) for e,te in zip(self.estimators,self.test)]\n",
    "        \n",
    "    def score(self,y_coord):\n",
    "        return [e.score(te.values,te[y_coord].values) for e,te in zip(self.estimators,self.test)]\n",
    "    \n",
    "def stratified_regressors(data, filt='region',n_units=126,y_coords=['ty','tz'],task_names=None,estimator=Ridge):\n",
    "    subsets = np.unique(data[filt].values)\n",
    "    if task_names is None:\n",
    "        task_names = y_coords\n",
    "    dfs = []\n",
    "    for y,task in zip(y_coords,task_names):\n",
    "        print('regressing {}...'.format(y))\n",
    "        regressors = {k:MURegressor(data.sel(**{filt:k}),n_units=n_units,estimator=Ridge).fit(y_coord=y) for k in subsets}\n",
    "        df = pd.DataFrame.from_records({k:v.score(y_coord=y) for k,v in regressors.items()})\n",
    "        df = df.melt(var_name='region',value_name='performance')\n",
    "        df['task']=task\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['tx','ty']\n",
    "mu_both_df = stratified_regressors(lg_both,filt='layer',y_coords=properties,n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',data=mu_both_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_xent_df = stratified_regressors(lg_xent,filt='layer',y_coords=properties,n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',data=mu_xent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(x='tx',y='ty',df=both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(x='tx',y='ty',df=xent_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-fastai (Python3.6.1)",
   "language": "python",
   "name": "py3-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "neptune": {
   "notebookId": "d87092c5-9710-423a-9466-ab57e41556f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
