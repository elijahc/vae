{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer,ContrastiveTrainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from src.losses import *\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Dense,Input,Concatenate,Lambda,Add,Multiply\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 500,\n",
       " 'data_dir': 'data',\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'dev_mode': True,\n",
       " 'enc_layers': [3000, 2000],\n",
       " 'epochs': 100,\n",
       " 'log_dir': '../logs',\n",
       " 'log_level': 'INFO',\n",
       " 'min_delta': 0.5,\n",
       " 'monitor': 'val_G_loss',\n",
       " 'optimizer': 'adam',\n",
       " 'recon': 5,\n",
       " 'xcov': 1000,\n",
       " 'xent': 10,\n",
       " 'y_dim': 10,\n",
       " 'z_dim': 5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config,_ = get_config()\n",
    "setattr(config, 'batch_size', 500)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs', 100)\n",
    "setattr(config, 'enc_layers', [3000,2000])\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 5)\n",
    "setattr(config, 'y_dim', 10)\n",
    "setattr(config, 'xcov', 1000)\n",
    "setattr(config, 'recon', 5)\n",
    "setattr(config, 'log_dir', '../logs')\n",
    "setattr(config, 'dev_mode',True)\n",
    "setattr(config, 'monitor', 'val_G_loss')\n",
    "setattr(config, 'min_delta', 0.5)\n",
    "# setattr(config, 'xcov', None)\n",
    "setattr(config, 'optimizer', 'adam')\n",
    "\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.dev_mode:\n",
    "    print('setting up...')\n",
    "    prepare_dirs_and_logger(config)\n",
    "    \n",
    "    with open(os.path.join(config.model_dir,'params.json'), 'w') as fp:\n",
    "        json.dump(vars(config), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.9\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n"
     ]
    }
   ],
   "source": [
    "DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "#                          rotation=0.20,\n",
    "                         translation=0.75,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building encoder...\n"
     ]
    }
   ],
   "source": [
    "G_builder = GResNet(y_dim=config.y_dim,z_dim=config.z_dim,dec_blocks=config.dec_blocks)\n",
    "E_builder = EDense(enc_layers=config.enc_layers,z_dim=config.z_dim,)\n",
    "trainer = ContrastiveTrainer(config,DL,Ebuilder=E_builder,Gbuilder=G_builder)\n",
    "trainer.build_encoder(DL.input_shape)\n",
    "# inp = Input(shape=(3136,),name='image')\n",
    "# l1 = Dense(3000,activation='relu')(inp)\n",
    "# l1 = Dense(2000,activation='relu')(l1)\n",
    "# # l1 = Dense(300,activation='relu')(l1)\n",
    "# y_lat = Dense(config.y_dim,name='y_lat')(l1)\n",
    "# z_lat = Dense(config.z_dim,name='z_lat')(l1)\n",
    "\n",
    "base_model = trainer.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building encoder...\n"
     ]
    }
   ],
   "source": [
    "trainer.build_encoder(input_shape=DL.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3000)         9411000     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2000)         6002000     dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 10)           20010       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_lat (Dense)                   (None, 5)            10005       dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,443,015\n",
      "Trainable params: 15,443,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer.E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Input(shape=(3136,),name='A')\n",
    "im2 = Input(shape=(3136,),name='B')\n",
    "# Y_in = Input(batch_shape=(None,1),name='Y')\n",
    "\n",
    "# enc_y1 = base_model(im1)\n",
    "# enc_y2 = base_model(im2)\n",
    "class_a= trainer.E(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building encoder...\n",
      "building decoder/generator...\n"
     ]
    }
   ],
   "source": [
    "trainer.build_model(DL.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3000)         9411000     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2000)         6002000     dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 10)           20010       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_lat (Dense)                   (None, 5)            10005       dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,443,015\n",
      "Trainable params: 15,443,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer.E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "A (InputLayer)                  (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "B (InputLayer)                  (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 10), (None,  15443015    A[0][0]                          \n",
      "                                                                 B[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15)           0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 15)           0           encoder[2][0]                    \n",
      "                                                                 encoder[2][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "G (Model)                       (None, 3136)         65137       concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "euclidean_distance (Lambda)     (None, 1)            0           encoder[1][0]                    \n",
      "                                                                 encoder[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,508,152\n",
      "Trainable params: 15,507,832\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.randint(0,10000,size=100)\n",
    "combos = np.array(np.meshgrid(idxs,idxs)).T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = zip(combos[:,0].tolist(),combos[:,1].tolist())\n",
    "combo_y = np.array([0 if DL.y_train[a]==DL.y_train[b] else 1 for a,b in pairs])\n",
    "pairs = zip(combos[:,0].tolist(),combos[:,1].tolist())\n",
    "combo_x = [(DL.sx_train[a],DL.sx_train[b]) for a,b in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2 = zip(*combo_x)\n",
    "x1 = np.array([x.tolist() for x in list(x1)])\n",
    "x2 = np.array([x.tolist() for x in list(x2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000, 3136)\n",
      "(10000, 3136)\n"
     ]
    }
   ],
   "source": [
    "print(combo_y.shape)\n",
    "print(x1.shape)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idxs = np.random.randint(0,10000,size=128)\n",
    "rand_x = {'X1':x1[rand_idxs],'X2':x2[rand_idxs],'Y':combo_y[rand_idxs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'G_target:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'G_target_1:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'euclidean_distance_target:0' shape=(?, ?) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = trainer.model\n",
    "mod.targets\n",
    "# K.gradients(mod.loss(mod.targets[0],mod.output),[mod.targets[0],mod.output,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3000)         9411000     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2000)         6002000     dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 10)           20010       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_lat (Dense)                   (None, 5)            10005       dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,443,015\n",
      "Trainable params: 15,443,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer.E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'G/G_image_flat/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'G_1/G_image_flat/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'euclidean_distance/Sqrt:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist_gen(u,v_arr,method='euclidean'):\n",
    "    distances = {\n",
    "        'euclidean':euclidean,\n",
    "        'seuclidean':seuclidean\n",
    "    }\n",
    "    for v in tqdm(v_arr):\n",
    "        yield distances[method](u,v)\n",
    "\n",
    "def find_knn(u,dataset,k=5):\n",
    "    dists = list(euclidean_dist_gen(x_tr_ex,DL.x_train))\n",
    "    sorted_dists = sorted(zip(dists,range(60000)),key=lambda tup:tup[0])\n",
    "    return sorted_dists[1:1+k]\n",
    "\n",
    "def batch_gen(knn=5,num_shifts=4,):\n",
    "    batch_size=knn*num_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_idx = np.random.randint(0,60000)\n",
    "x_tr_ex = DL.x_train[x_tr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:01<00:00, 39022.44it/s]\n"
     ]
    }
   ],
   "source": [
    "knn = find_knn(x_tr_ex,DL.x_train,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist,idxs = zip(*knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3192fe4208>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_tr_ex.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs = plt.subplots(1,5)\n",
    "for ax,idx in zip(axs,list(idxs)):\n",
    "    ax.imshow(DL.x_train[idx].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 27638),\n",
       " (5.450146675109863, 20361),\n",
       " (5.567053318023682, 10187),\n",
       " (5.638850212097168, 55616),\n",
       " (5.7054338455200195, 11693),\n",
       " (5.714379787445068, 10414),\n",
       " (5.794131755828857, 55056),\n",
       " (5.818718433380127, 5625),\n",
       " (5.873557090759277, 59157),\n",
       " (6.003226280212402, 22125),\n",
       " (6.012707233428955, 3768),\n",
       " (6.074528694152832, 49524),\n",
       " (6.101979732513428, 36374),\n",
       " (6.110721588134766, 50880),\n",
       " (6.127228736877441, 20473),\n",
       " (6.13072395324707, 26840),\n",
       " (6.143731594085693, 59011),\n",
       " (6.1619439125061035, 14733),\n",
       " (6.166145324707031, 2873),\n",
       " (6.174595355987549, 38706),\n",
       " (6.206881999969482, 26696),\n",
       " (6.249919891357422, 19303),\n",
       " (6.276442050933838, 35358),\n",
       " (6.27659273147583, 53468),\n",
       " (6.278343200683594, 35769),\n",
       " (6.290780544281006, 40010),\n",
       " (6.319338798522949, 16305),\n",
       " (6.322803020477295, 31620),\n",
       " (6.324387550354004, 24909),\n",
       " (6.3491058349609375, 53449),\n",
       " (6.359380722045898, 21176),\n",
       " (6.361831188201904, 13037),\n",
       " (6.373907566070557, 46577),\n",
       " (6.397336006164551, 2622),\n",
       " (6.399506092071533, 16678),\n",
       " (6.401216983795166, 18488),\n",
       " (6.402596950531006, 42175),\n",
       " (6.403446197509766, 19146),\n",
       " (6.411090850830078, 45897),\n",
       " (6.414572715759277, 48074),\n",
       " (6.421127796173096, 794),\n",
       " (6.435402870178223, 45089),\n",
       " (6.435676574707031, 43729),\n",
       " (6.454034805297852, 13936),\n",
       " (6.485691547393799, 51572),\n",
       " (6.487224102020264, 54871),\n",
       " (6.500123023986816, 2777),\n",
       " (6.5001983642578125, 27745),\n",
       " (6.509642124176025, 5117),\n",
       " (6.520903587341309, 53481),\n",
       " (6.521142959594727, 37348),\n",
       " (6.531856060028076, 16901),\n",
       " (6.5366597175598145, 57426),\n",
       " (6.541111946105957, 38652),\n",
       " (6.546901226043701, 51687),\n",
       " (6.562743663787842, 44161),\n",
       " (6.572932720184326, 59239),\n",
       " (6.597460746765137, 48858),\n",
       " (6.622739791870117, 38599),\n",
       " (6.629496097564697, 15379),\n",
       " (6.630514621734619, 1612),\n",
       " (6.6308274269104, 35904),\n",
       " (6.633067607879639, 37956),\n",
       " (6.640298366546631, 57498),\n",
       " (6.651473045349121, 34685),\n",
       " (6.653428554534912, 30710),\n",
       " (6.653473854064941, 30293),\n",
       " (6.661211013793945, 1829),\n",
       " (6.67182731628418, 56112),\n",
       " (6.673266887664795, 39513),\n",
       " (6.675253868103027, 45754),\n",
       " (6.677048683166504, 37869),\n",
       " (6.67746639251709, 22707),\n",
       " (6.681971073150635, 16957),\n",
       " (6.684703350067139, 20326),\n",
       " (6.686299800872803, 4838),\n",
       " (6.691649913787842, 35957),\n",
       " (6.692242622375488, 21846),\n",
       " (6.693340301513672, 23480),\n",
       " (6.701811790466309, 51428),\n",
       " (6.709003925323486, 18228),\n",
       " (6.711050510406494, 15057),\n",
       " (6.712714195251465, 12871),\n",
       " (6.7133684158325195, 35170),\n",
       " (6.714478015899658, 16036),\n",
       " (6.718499660491943, 43099),\n",
       " (6.721934795379639, 58290),\n",
       " (6.722169399261475, 47412),\n",
       " (6.723929405212402, 22446),\n",
       " (6.724952697753906, 6489),\n",
       " (6.72583532333374, 34666),\n",
       " (6.732104778289795, 57503),\n",
       " (6.735551834106445, 23399),\n",
       " (6.7424845695495605, 46435),\n",
       " (6.746939182281494, 29229),\n",
       " (6.752475738525391, 33021),\n",
       " (6.753097057342529, 15621),\n",
       " (6.753947734832764, 51341),\n",
       " (6.753994464874268, 17214),\n",
       " (6.760810375213623, 30523),\n",
       " (6.761120796203613, 3740),\n",
       " (6.764321804046631, 27137),\n",
       " (6.772852420806885, 2679),\n",
       " (6.7798638343811035, 59491),\n",
       " (6.795331954956055, 49013),\n",
       " (6.796774387359619, 58548),\n",
       " (6.7995758056640625, 6432),\n",
       " (6.8057169914245605, 53755),\n",
       " (6.806736469268799, 42780),\n",
       " (6.81757116317749, 22266),\n",
       " (6.8183088302612305, 50382),\n",
       " (6.82132625579834, 1628),\n",
       " (6.829990386962891, 59127),\n",
       " (6.833059787750244, 31253),\n",
       " (6.833279132843018, 7895),\n",
       " (6.8333330154418945, 49133),\n",
       " (6.8352437019348145, 12807),\n",
       " (6.845306873321533, 58431),\n",
       " (6.846024513244629, 58985),\n",
       " (6.847309112548828, 24033),\n",
       " (6.858721733093262, 24480),\n",
       " (6.859644412994385, 5487),\n",
       " (6.863123893737793, 25081),\n",
       " (6.864322662353516, 29472),\n",
       " (6.872081279754639, 22271),\n",
       " (6.872849941253662, 13759),\n",
       " (6.882931709289551, 45197),\n",
       " (6.889060974121094, 49669),\n",
       " (6.8979644775390625, 48874),\n",
       " (6.902687072753906, 30003),\n",
       " (6.906501293182373, 43353),\n",
       " (6.910039901733398, 9109),\n",
       " (6.918196201324463, 45895),\n",
       " (6.928457736968994, 40097),\n",
       " (6.930905342102051, 32163),\n",
       " (6.931990146636963, 52853),\n",
       " (6.939313888549805, 48484),\n",
       " (6.940661430358887, 23376),\n",
       " (6.944746017456055, 22898),\n",
       " (6.946242809295654, 18893),\n",
       " (6.950001239776611, 30816),\n",
       " (6.953548431396484, 5750),\n",
       " (6.957097053527832, 32405),\n",
       " (6.957385540008545, 21883),\n",
       " (6.957596778869629, 36549),\n",
       " (6.957865238189697, 7834),\n",
       " (6.958546161651611, 56833),\n",
       " (6.961424827575684, 59967),\n",
       " (6.963960647583008, 50112),\n",
       " (6.966320037841797, 46876),\n",
       " (6.966524124145508, 15186),\n",
       " (6.970498561859131, 7605),\n",
       " (6.975829124450684, 27927),\n",
       " (6.985316753387451, 51515),\n",
       " (6.9909868240356445, 55140),\n",
       " (6.9913530349731445, 4816),\n",
       " (6.993020057678223, 56739),\n",
       " (6.993606090545654, 22810),\n",
       " (6.9956841468811035, 37156),\n",
       " (7.000568866729736, 48187),\n",
       " (7.004158973693848, 48246),\n",
       " (7.004863262176514, 37479),\n",
       " (7.009620666503906, 7685),\n",
       " (7.00980806350708, 36278),\n",
       " (7.013590335845947, 22535),\n",
       " (7.0165300369262695, 16244),\n",
       " (7.02081823348999, 42472),\n",
       " (7.023909091949463, 11606),\n",
       " (7.027272701263428, 38728),\n",
       " (7.030063629150391, 36927),\n",
       " (7.031617641448975, 31825),\n",
       " (7.032042980194092, 29275),\n",
       " (7.032104015350342, 41322),\n",
       " (7.034664630889893, 41727),\n",
       " (7.035250663757324, 7702),\n",
       " (7.03581428527832, 36063),\n",
       " (7.036753177642822, 38117),\n",
       " (7.03886079788208, 29878),\n",
       " (7.042389392852783, 14556),\n",
       " (7.0468525886535645, 11766),\n",
       " (7.049765586853027, 5191),\n",
       " (7.050339221954346, 30516),\n",
       " (7.0542893409729, 32268),\n",
       " (7.057349681854248, 25369),\n",
       " (7.057586193084717, 44217),\n",
       " (7.05781364440918, 57579),\n",
       " (7.058299541473389, 11421),\n",
       " (7.058831214904785, 41304),\n",
       " (7.063399314880371, 54467),\n",
       " (7.06845235824585, 21982),\n",
       " (7.069546222686768, 28015),\n",
       " (7.08419942855835, 31229),\n",
       " (7.085463047027588, 25328),\n",
       " (7.0856614112854, 40830),\n",
       " (7.088204860687256, 11096),\n",
       " (7.0904035568237305, 27670),\n",
       " (7.099740028381348, 39157),\n",
       " (7.100299835205078, 49923),\n",
       " (7.102619171142578, 20764),\n",
       " (7.103083610534668, 3435),\n",
       " (7.105827331542969, 41861),\n",
       " (7.106917858123779, 43608),\n",
       " (7.115074634552002, 12889),\n",
       " (7.115116596221924, 49446),\n",
       " (7.119735240936279, 59075),\n",
       " (7.119953155517578, 4354),\n",
       " (7.122372150421143, 15191),\n",
       " (7.124090671539307, 21853),\n",
       " (7.124477863311768, 23273),\n",
       " (7.125626087188721, 55770),\n",
       " (7.1301655769348145, 22581),\n",
       " (7.131575107574463, 42582),\n",
       " (7.131895542144775, 14223),\n",
       " (7.133734226226807, 39191),\n",
       " (7.139023780822754, 25334),\n",
       " (7.142836570739746, 33791),\n",
       " (7.146267890930176, 52125),\n",
       " (7.148075103759766, 27682),\n",
       " (7.148763656616211, 15518),\n",
       " (7.150340557098389, 18565),\n",
       " (7.150857448577881, 15500),\n",
       " (7.151645660400391, 55954),\n",
       " (7.153152942657471, 59807),\n",
       " (7.1575517654418945, 33656),\n",
       " (7.162328243255615, 26422),\n",
       " (7.164515972137451, 58227),\n",
       " (7.1661696434021, 34839),\n",
       " (7.173437595367432, 21109),\n",
       " (7.180913925170898, 47457),\n",
       " (7.1815690994262695, 24180),\n",
       " (7.1876020431518555, 51267),\n",
       " (7.187730312347412, 23727),\n",
       " (7.189168930053711, 41135),\n",
       " (7.196697235107422, 5527),\n",
       " (7.206639766693115, 811),\n",
       " (7.208779811859131, 6682),\n",
       " (7.209789752960205, 28944),\n",
       " (7.211458683013916, 44838),\n",
       " (7.21264123916626, 9689),\n",
       " (7.213656902313232, 6142),\n",
       " (7.214038848876953, 1135),\n",
       " (7.215223789215088, 52542),\n",
       " (7.215831279754639, 32098),\n",
       " (7.217507362365723, 57760),\n",
       " (7.221173286437988, 48139),\n",
       " (7.224714279174805, 39383),\n",
       " (7.225693225860596, 48747),\n",
       " (7.227137088775635, 24688),\n",
       " (7.229909420013428, 6919),\n",
       " (7.230001926422119, 20406),\n",
       " (7.231995582580566, 20051),\n",
       " (7.233539581298828, 8066),\n",
       " (7.234473705291748, 17417),\n",
       " (7.237813472747803, 23918),\n",
       " (7.237943172454834, 40041),\n",
       " (7.238550662994385, 34798),\n",
       " (7.240141868591309, 10548),\n",
       " (7.240577220916748, 40045),\n",
       " (7.242295265197754, 12367),\n",
       " (7.249505043029785, 57984),\n",
       " (7.249977111816406, 25348),\n",
       " (7.251649856567383, 15014),\n",
       " (7.253401279449463, 20260),\n",
       " (7.254200458526611, 59523),\n",
       " (7.257742881774902, 40817),\n",
       " (7.257909297943115, 46388),\n",
       " (7.260632514953613, 15308),\n",
       " (7.265715599060059, 7237),\n",
       " (7.269181728363037, 39530),\n",
       " (7.2694525718688965, 26393),\n",
       " (7.270769119262695, 16882),\n",
       " (7.2715020179748535, 54435),\n",
       " (7.272892475128174, 26166),\n",
       " (7.273978233337402, 43370),\n",
       " (7.2746968269348145, 31828),\n",
       " (7.279284954071045, 11785),\n",
       " (7.280320167541504, 32426),\n",
       " (7.282313823699951, 5540),\n",
       " (7.283492088317871, 34214),\n",
       " (7.290966033935547, 57907),\n",
       " (7.296211242675781, 49621),\n",
       " (7.3027167320251465, 45395),\n",
       " (7.302830696105957, 2412),\n",
       " (7.304625511169434, 7970),\n",
       " (7.307550430297852, 43081),\n",
       " (7.309227466583252, 14217),\n",
       " (7.309869289398193, 58214),\n",
       " (7.310225009918213, 3315),\n",
       " (7.310724258422852, 11141),\n",
       " (7.310970306396484, 50975),\n",
       " (7.315254211425781, 23137),\n",
       " (7.316163063049316, 50227),\n",
       " (7.318713665008545, 28545),\n",
       " (7.320288181304932, 10884),\n",
       " (7.323060035705566, 35232),\n",
       " (7.324991703033447, 40368),\n",
       " (7.325409412384033, 35220),\n",
       " (7.3264641761779785, 20467),\n",
       " (7.328998565673828, 25983),\n",
       " (7.33333158493042, 32371),\n",
       " (7.333451747894287, 8059),\n",
       " (7.33513069152832, 59103),\n",
       " (7.335773944854736, 38798),\n",
       " (7.340864658355713, 45697),\n",
       " (7.340982913970947, 7195),\n",
       " (7.341160774230957, 14197),\n",
       " (7.344672203063965, 31483),\n",
       " (7.347827911376953, 25242),\n",
       " (7.348283290863037, 8274),\n",
       " (7.349935054779053, 29781),\n",
       " (7.351020812988281, 46958),\n",
       " (7.352768898010254, 31961),\n",
       " (7.353813171386719, 35197),\n",
       " (7.355231285095215, 43731),\n",
       " (7.357312202453613, 4335),\n",
       " (7.357387542724609, 40797),\n",
       " (7.357482433319092, 3633),\n",
       " (7.359618663787842, 57271),\n",
       " (7.359811782836914, 32355),\n",
       " (7.363979339599609, 44461),\n",
       " (7.364369869232178, 461),\n",
       " (7.366716384887695, 6065),\n",
       " (7.3682475090026855, 39176),\n",
       " (7.369229793548584, 22684),\n",
       " (7.3725972175598145, 27006),\n",
       " (7.372736930847168, 21100),\n",
       " (7.378318786621094, 59677),\n",
       " (7.382893085479736, 31937),\n",
       " (7.3834638595581055, 6616),\n",
       " (7.384506702423096, 4622),\n",
       " (7.385280132293701, 45077),\n",
       " (7.386170387268066, 55592),\n",
       " (7.387609004974365, 48236),\n",
       " (7.388848304748535, 23035),\n",
       " (7.394274711608887, 46615),\n",
       " (7.398882865905762, 37249),\n",
       " (7.39896297454834, 47863),\n",
       " (7.399560451507568, 16187),\n",
       " (7.399718761444092, 32653),\n",
       " (7.4006452560424805, 11254),\n",
       " (7.401177406311035, 1159),\n",
       " (7.4026007652282715, 41288),\n",
       " (7.40752649307251, 55510),\n",
       " (7.408751487731934, 12398),\n",
       " (7.409491539001465, 22598),\n",
       " (7.411175727844238, 45761),\n",
       " (7.411406993865967, 15362),\n",
       " (7.411500453948975, 20091),\n",
       " (7.417757987976074, 43721),\n",
       " (7.4182305335998535, 14722),\n",
       " (7.421108722686768, 27886),\n",
       " (7.421987056732178, 18871),\n",
       " (7.425454616546631, 30555),\n",
       " (7.42755126953125, 57862),\n",
       " (7.4288225173950195, 37326),\n",
       " (7.429748058319092, 19051),\n",
       " (7.431729793548584, 2274),\n",
       " (7.432666778564453, 34614),\n",
       " (7.433152198791504, 29810),\n",
       " (7.43364953994751, 40458),\n",
       " (7.433967113494873, 57490),\n",
       " (7.435276508331299, 37777),\n",
       " (7.439497947692871, 19198),\n",
       " (7.440424919128418, 34543),\n",
       " (7.44168758392334, 48335),\n",
       " (7.442314147949219, 49450),\n",
       " (7.444526672363281, 24104),\n",
       " (7.446600437164307, 30474),\n",
       " (7.447352409362793, 23381),\n",
       " (7.447396755218506, 6467),\n",
       " (7.448690891265869, 36593),\n",
       " (7.449362277984619, 1927),\n",
       " (7.453581809997559, 27877),\n",
       " (7.453867435455322, 5098),\n",
       " (7.454108715057373, 45499),\n",
       " (7.456860542297363, 10318),\n",
       " (7.459746360778809, 47971),\n",
       " (7.460159778594971, 58893),\n",
       " (7.461642742156982, 50598),\n",
       " (7.465484619140625, 29834),\n",
       " (7.465994358062744, 27634),\n",
       " (7.467934608459473, 47397),\n",
       " (7.469622611999512, 11636),\n",
       " (7.477116107940674, 13285),\n",
       " (7.479499816894531, 30776),\n",
       " (7.48070764541626, 7153),\n",
       " (7.481624603271484, 45827),\n",
       " (7.483288288116455, 16078),\n",
       " (7.484847545623779, 3894),\n",
       " (7.488629341125488, 24585),\n",
       " (7.48938512802124, 3962),\n",
       " (7.497468948364258, 8117),\n",
       " (7.498524188995361, 41763),\n",
       " (7.500182628631592, 13164),\n",
       " (7.504039287567139, 13241),\n",
       " (7.506404876708984, 20985),\n",
       " (7.50899600982666, 9537),\n",
       " (7.509572505950928, 35537),\n",
       " (7.510592460632324, 19099),\n",
       " (7.513870716094971, 27018),\n",
       " (7.514492988586426, 5645),\n",
       " (7.5163798332214355, 58146),\n",
       " (7.5173444747924805, 49499),\n",
       " (7.518487930297852, 27002),\n",
       " (7.519574165344238, 14229),\n",
       " (7.523541450500488, 41013),\n",
       " (7.523962497711182, 27594),\n",
       " (7.525042533874512, 32519),\n",
       " (7.525946140289307, 633),\n",
       " (7.526290416717529, 11793),\n",
       " (7.527371406555176, 9167),\n",
       " (7.5282158851623535, 16134),\n",
       " (7.528264999389648, 50937),\n",
       " (7.5298686027526855, 47339),\n",
       " (7.532677173614502, 58968),\n",
       " (7.533706188201904, 26891),\n",
       " (7.539091110229492, 37902),\n",
       " (7.541478157043457, 31465),\n",
       " (7.545470237731934, 52929),\n",
       " (7.545692443847656, 34541),\n",
       " (7.546966075897217, 25368),\n",
       " (7.547675132751465, 178),\n",
       " (7.552101135253906, 38385),\n",
       " (7.553330898284912, 8054),\n",
       " (7.553779125213623, 28717),\n",
       " (7.5557861328125, 26341),\n",
       " (7.556185245513916, 42206),\n",
       " (7.556717395782471, 35977),\n",
       " (7.5572333335876465, 55502),\n",
       " (7.558192729949951, 13255),\n",
       " (7.56122350692749, 37077),\n",
       " (7.562935829162598, 8758),\n",
       " (7.5659613609313965, 46389),\n",
       " (7.569497108459473, 37302),\n",
       " (7.570182800292969, 21297),\n",
       " (7.57380485534668, 4783),\n",
       " (7.577221870422363, 24498),\n",
       " (7.578456401824951, 26868),\n",
       " (7.5829033851623535, 31875),\n",
       " (7.582948207855225, 17372),\n",
       " (7.584005355834961, 30380),\n",
       " (7.584677696228027, 39360),\n",
       " (7.585422039031982, 34767),\n",
       " (7.5862298011779785, 16383),\n",
       " (7.592792987823486, 10379),\n",
       " (7.593934059143066, 660),\n",
       " (7.595131874084473, 47783),\n",
       " (7.596958160400391, 41919),\n",
       " (7.597875118255615, 9558),\n",
       " (7.599087238311768, 5972),\n",
       " (7.599728107452393, 22941),\n",
       " (7.601078510284424, 48476),\n",
       " (7.603824615478516, 23490),\n",
       " (7.6043381690979, 28977),\n",
       " (7.604435443878174, 50040),\n",
       " (7.6046223640441895, 55145),\n",
       " (7.6057610511779785, 51088),\n",
       " (7.607357025146484, 51935),\n",
       " (7.608504295349121, 42568),\n",
       " (7.608754634857178, 32995),\n",
       " (7.61138916015625, 2703),\n",
       " (7.61306095123291, 22279),\n",
       " (7.616915225982666, 55409),\n",
       " (7.617315769195557, 9192),\n",
       " (7.617422580718994, 40916),\n",
       " (7.618185997009277, 6304),\n",
       " (7.6194000244140625, 14350),\n",
       " (7.619867324829102, 6540),\n",
       " (7.620169162750244, 27483),\n",
       " (7.623393535614014, 21722),\n",
       " (7.623446941375732, 33613),\n",
       " (7.625916481018066, 43540),\n",
       " (7.626319885253906, 32214),\n",
       " (7.631556034088135, 7815),\n",
       " (7.6318864822387695, 1540),\n",
       " (7.632665157318115, 21484),\n",
       " (7.633517742156982, 984),\n",
       " (7.638670444488525, 28081),\n",
       " (7.639718055725098, 7445),\n",
       " (7.640625953674316, 45439),\n",
       " (7.641149044036865, 39559),\n",
       " (7.642895698547363, 47437),\n",
       " (7.64477014541626, 48472),\n",
       " (7.647558689117432, 46806),\n",
       " (7.650635719299316, 15927),\n",
       " (7.654295444488525, 4886),\n",
       " (7.659076690673828, 22528),\n",
       " (7.661324977874756, 43038),\n",
       " (7.661460876464844, 58776),\n",
       " (7.663905143737793, 9751),\n",
       " (7.664674758911133, 4630),\n",
       " (7.665673732757568, 45869),\n",
       " (7.666952610015869, 23962),\n",
       " (7.6697282791137695, 21370),\n",
       " (7.670355796813965, 10033),\n",
       " (7.671762943267822, 2114),\n",
       " (7.672097682952881, 10581),\n",
       " (7.672936916351318, 7947),\n",
       " (7.6730780601501465, 1030),\n",
       " (7.675963401794434, 25828),\n",
       " (7.676593780517578, 7684),\n",
       " (7.677696228027344, 41054),\n",
       " (7.678938388824463, 18460),\n",
       " (7.681242942810059, 34966),\n",
       " (7.6816725730896, 11760),\n",
       " (7.684609889984131, 48932),\n",
       " (7.685937404632568, 17608),\n",
       " (7.68607234954834, 10808),\n",
       " (7.6863274574279785, 50079),\n",
       " (7.687416076660156, 15689),\n",
       " (7.689835071563721, 47917),\n",
       " (7.6931843757629395, 40103),\n",
       " (7.694124698638916, 54124),\n",
       " (7.69597053527832, 9885),\n",
       " (7.697855472564697, 19572),\n",
       " (7.699193954467773, 4998),\n",
       " (7.699277877807617, 23528),\n",
       " (7.701784133911133, 9247),\n",
       " (7.703293800354004, 7368),\n",
       " (7.706912040710449, 1231),\n",
       " (7.708161354064941, 40427),\n",
       " (7.7087297439575195, 29670),\n",
       " (7.709011077880859, 35489),\n",
       " (7.7095746994018555, 24126),\n",
       " (7.713781356811523, 23345),\n",
       " (7.71514892578125, 56342),\n",
       " (7.7158355712890625, 33706),\n",
       " (7.718382358551025, 58991),\n",
       " (7.7190022468566895, 57243),\n",
       " (7.721272945404053, 27240),\n",
       " (7.7233381271362305, 14500),\n",
       " (7.724061012268066, 11052),\n",
       " (7.724578380584717, 51959),\n",
       " (7.725947380065918, 55562),\n",
       " (7.728584289550781, 44712),\n",
       " (7.729910373687744, 11579),\n",
       " (7.7316670417785645, 9653),\n",
       " (7.732254505157471, 610),\n",
       " (7.732270240783691, 26275),\n",
       " (7.733014106750488, 29008),\n",
       " (7.734501838684082, 22441),\n",
       " (7.735912322998047, 55627),\n",
       " (7.739259243011475, 34283),\n",
       " (7.741508483886719, 19586),\n",
       " (7.742550373077393, 55087),\n",
       " (7.742875099182129, 29934),\n",
       " (7.743017196655273, 43864),\n",
       " (7.746832370758057, 2220),\n",
       " (7.74739933013916, 34874),\n",
       " (7.748258590698242, 23567),\n",
       " (7.74893856048584, 55400),\n",
       " (7.751752853393555, 43842),\n",
       " (7.7519145011901855, 23346),\n",
       " (7.752070426940918, 16190),\n",
       " (7.7525315284729, 59171),\n",
       " (7.75395393371582, 26620),\n",
       " (7.754169940948486, 9949),\n",
       " (7.755263805389404, 20518),\n",
       " (7.755609512329102, 13342),\n",
       " (7.755664348602295, 21299),\n",
       " (7.756392955780029, 7638),\n",
       " (7.757282257080078, 2228),\n",
       " (7.75850248336792, 1635),\n",
       " (7.762383460998535, 57305),\n",
       " (7.764177322387695, 16791),\n",
       " (7.765088081359863, 47720),\n",
       " (7.767260551452637, 4532),\n",
       " (7.772494792938232, 33628),\n",
       " (7.775835037231445, 54061),\n",
       " (7.77665376663208, 46698),\n",
       " (7.781280517578125, 43930),\n",
       " (7.7823944091796875, 17877),\n",
       " (7.783046245574951, 23711),\n",
       " (7.784696102142334, 36002),\n",
       " (7.786612033843994, 28014),\n",
       " (7.788066387176514, 57240),\n",
       " (7.788557052612305, 13757),\n",
       " (7.790566921234131, 161),\n",
       " (7.790988445281982, 45738),\n",
       " (7.792088985443115, 10092),\n",
       " (7.79378604888916, 8301),\n",
       " (7.793898582458496, 21698),\n",
       " (7.795401096343994, 2368),\n",
       " (7.795752048492432, 216),\n",
       " (7.797952175140381, 13374),\n",
       " (7.798427581787109, 14297),\n",
       " (7.801393985748291, 36103),\n",
       " (7.802109718322754, 2578),\n",
       " (7.8025126457214355, 6144),\n",
       " (7.802794456481934, 56951),\n",
       " (7.803618431091309, 27834),\n",
       " (7.804502010345459, 31137),\n",
       " (7.806211471557617, 28095),\n",
       " (7.810652256011963, 22703),\n",
       " (7.812794208526611, 11689),\n",
       " (7.812933921813965, 29074),\n",
       " (7.816451549530029, 13938),\n",
       " (7.817764759063721, 9358),\n",
       " (7.820530414581299, 33635),\n",
       " (7.820610046386719, 18642),\n",
       " (7.822366714477539, 51942),\n",
       " (7.822525978088379, 5516),\n",
       " (7.823959827423096, 57575),\n",
       " (7.824189186096191, 1234),\n",
       " (7.827102184295654, 49057),\n",
       " (7.827648639678955, 56240),\n",
       " (7.828154563903809, 13512),\n",
       " (7.828448295593262, 22669),\n",
       " (7.829188823699951, 30169),\n",
       " (7.8305253982543945, 35875),\n",
       " (7.830607891082764, 30042),\n",
       " (7.8306708335876465, 45050),\n",
       " (7.831471920013428, 52798),\n",
       " (7.833851337432861, 4755),\n",
       " (7.834620952606201, 25813),\n",
       " (7.83485746383667, 46668),\n",
       " (7.83913516998291, 45335),\n",
       " (7.83998441696167, 26442),\n",
       " (7.842671871185303, 32359),\n",
       " (7.8438520431518555, 44089),\n",
       " (7.844367504119873, 37529),\n",
       " (7.844638347625732, 32165),\n",
       " (7.844710826873779, 14281),\n",
       " (7.851724624633789, 12088),\n",
       " (7.853035926818848, 59130),\n",
       " (7.856791019439697, 40443),\n",
       " (7.85886287689209, 40439),\n",
       " (7.859462738037109, 58080),\n",
       " (7.860087871551514, 19530),\n",
       " (7.860733509063721, 44764),\n",
       " (7.861012935638428, 40417),\n",
       " (7.8625946044921875, 38130),\n",
       " (7.866748809814453, 22076),\n",
       " (7.8668212890625, 53859),\n",
       " (7.868285179138184, 15660),\n",
       " (7.873703479766846, 38169),\n",
       " (7.875906944274902, 21755),\n",
       " (7.8767828941345215, 1524),\n",
       " (7.88318395614624, 41695),\n",
       " (7.884355545043945, 34654),\n",
       " (7.887765407562256, 30455),\n",
       " (7.888335704803467, 48582),\n",
       " (7.892842769622803, 57759),\n",
       " (7.897759914398193, 27377),\n",
       " (7.898865699768066, 37700),\n",
       " (7.903165340423584, 420),\n",
       " (7.903434753417969, 2054),\n",
       " (7.904226779937744, 12761),\n",
       " (7.905217170715332, 15921),\n",
       " (7.906367778778076, 24992),\n",
       " (7.906503677368164, 33452),\n",
       " (7.907007694244385, 41808),\n",
       " (7.909337520599365, 43867),\n",
       " (7.909500598907471, 9376),\n",
       " (7.911087989807129, 57306),\n",
       " (7.912734508514404, 46138),\n",
       " (7.914290904998779, 49041),\n",
       " (7.9159650802612305, 144),\n",
       " (7.918071746826172, 26200),\n",
       " (7.918680191040039, 29164),\n",
       " (7.922554969787598, 48411),\n",
       " (7.922749042510986, 2249),\n",
       " (7.922916889190674, 50601),\n",
       " (7.923019886016846, 14820),\n",
       " (7.923969745635986, 33566),\n",
       " (7.924933433532715, 17136),\n",
       " (7.925223350524902, 20619),\n",
       " (7.926474094390869, 18789),\n",
       " (7.927347183227539, 36807),\n",
       " (7.928351879119873, 59710),\n",
       " (7.931225299835205, 13210),\n",
       " (7.934537410736084, 51390),\n",
       " (7.941740036010742, 11709),\n",
       " (7.945641040802002, 52875),\n",
       " (7.947872161865234, 21512),\n",
       " (7.951500415802002, 1401),\n",
       " (7.952152252197266, 27733),\n",
       " (7.953454494476318, 26987),\n",
       " (7.954450607299805, 48004),\n",
       " (7.955305099487305, 11489),\n",
       " (7.956284046173096, 50745),\n",
       " (7.957462787628174, 18764),\n",
       " (7.9602766036987305, 10764),\n",
       " (7.9627275466918945, 17651),\n",
       " (7.967238903045654, 5029),\n",
       " (7.96748685836792, 37143),\n",
       " (7.96769905090332, 10409),\n",
       " (7.968194484710693, 45871),\n",
       " (7.969322204589844, 26399),\n",
       " (7.971871852874756, 19941),\n",
       " (7.972171306610107, 57850),\n",
       " (7.973101615905762, 8646),\n",
       " (7.974067211151123, 36755),\n",
       " (7.975003242492676, 26042),\n",
       " (7.977010726928711, 50812),\n",
       " (7.977319717407227, 26294),\n",
       " (7.978530406951904, 12848),\n",
       " (7.981082916259766, 38717),\n",
       " (7.981187343597412, 11151),\n",
       " (7.981869220733643, 3718),\n",
       " (7.984047889709473, 19872),\n",
       " (7.985048770904541, 44308),\n",
       " (7.986001968383789, 5367),\n",
       " (7.986266613006592, 59251),\n",
       " (7.9867730140686035, 27214),\n",
       " (7.98760986328125, 25764),\n",
       " (7.988422870635986, 25698),\n",
       " (7.988940715789795, 21443),\n",
       " (7.99138069152832, 38540),\n",
       " (7.991724014282227, 42976),\n",
       " (7.99273157119751, 20622),\n",
       " (7.992893695831299, 553),\n",
       " (7.994633197784424, 39492),\n",
       " (7.997013092041016, 46877),\n",
       " (7.997138023376465, 11251),\n",
       " (7.9979071617126465, 43192),\n",
       " (7.999281883239746, 27764),\n",
       " (7.999375343322754, 54233),\n",
       " (8.000405311584473, 34605),\n",
       " (8.00146198272705, 49275),\n",
       " (8.001873016357422, 3523),\n",
       " (8.0026216506958, 38310),\n",
       " (8.002866744995117, 39962),\n",
       " (8.003993034362793, 24029),\n",
       " (8.004263877868652, 27836),\n",
       " (8.004721641540527, 38843),\n",
       " (8.004844665527344, 16238),\n",
       " (8.005594253540039, 9422),\n",
       " (8.00803279876709, 29913),\n",
       " (8.009753227233887, 11734),\n",
       " (8.010384559631348, 458),\n",
       " (8.011988639831543, 56507),\n",
       " (8.013394355773926, 25041),\n",
       " (8.01693344116211, 44989),\n",
       " (8.018837928771973, 34870),\n",
       " (8.021062850952148, 15672),\n",
       " (8.022061347961426, 30123),\n",
       " (8.023477554321289, 59530),\n",
       " (8.023688316345215, 28346),\n",
       " (8.024497032165527, 10895),\n",
       " (8.028345108032227, 55220),\n",
       " (8.030110359191895, 7758),\n",
       " (8.030658721923828, 13011),\n",
       " (8.03115177154541, 23941),\n",
       " (8.03150463104248, 25703),\n",
       " (8.032655715942383, 52000),\n",
       " (8.036287307739258, 51184),\n",
       " (8.039569854736328, 7361),\n",
       " (8.04055404663086, 1712),\n",
       " (8.041770935058594, 27368),\n",
       " (8.042267799377441, 40957),\n",
       " (8.044073104858398, 24879),\n",
       " (8.044322967529297, 55539),\n",
       " (8.047541618347168, 27446),\n",
       " (8.049371719360352, 5052),\n",
       " (8.049543380737305, 28610),\n",
       " (8.049715042114258, 57539),\n",
       " (8.053099632263184, 27992),\n",
       " (8.053221702575684, 9927),\n",
       " (8.0545072555542, 32880),\n",
       " (8.05726146697998, 4119),\n",
       " (8.058243751525879, 49856),\n",
       " (8.059654235839844, 45101),\n",
       " (8.059672355651855, 37922),\n",
       " (8.0614595413208, 35217),\n",
       " (8.062554359436035, 44354),\n",
       " (8.064508438110352, 25951),\n",
       " (8.065163612365723, 47629),\n",
       " (8.065491676330566, 58315),\n",
       " (8.073107719421387, 56075),\n",
       " (8.074076652526855, 2726),\n",
       " (8.075135231018066, 16230),\n",
       " (8.07900333404541, 34878),\n",
       " (8.079784393310547, 27691),\n",
       " (8.081161499023438, 11230),\n",
       " (8.08251953125, 55288),\n",
       " (8.082863807678223, 1485),\n",
       " (8.083084106445312, 30286),\n",
       " (8.08309268951416, 16989),\n",
       " (8.083122253417969, 26709),\n",
       " (8.083629608154297, 26682),\n",
       " (8.085044860839844, 52992),\n",
       " (8.086593627929688, 56521),\n",
       " (8.087350845336914, 972),\n",
       " (8.087808609008789, 19755),\n",
       " (8.08851146697998, 57673),\n",
       " (8.089110374450684, 44559),\n",
       " (8.089804649353027, 13565),\n",
       " (8.090341567993164, 24146),\n",
       " (8.0907621383667, 39407),\n",
       " (8.09398365020752, 13468),\n",
       " (8.094152450561523, 59097),\n",
       " (8.094225883483887, 5849),\n",
       " (8.094287872314453, 49180),\n",
       " (8.095986366271973, 15904),\n",
       " (8.101724624633789, 3863),\n",
       " (8.102073669433594, 23),\n",
       " (8.103349685668945, 23013),\n",
       " (8.103947639465332, 4673),\n",
       " (8.105622291564941, 39458),\n",
       " (8.10595417022705, 5455),\n",
       " (8.110076904296875, 24811),\n",
       " (8.111617088317871, 54181),\n",
       " (8.112709999084473, 45300),\n",
       " (8.112771987915039, 27713),\n",
       " (8.113349914550781, 59729),\n",
       " (8.114465713500977, 43787),\n",
       " (8.115948677062988, 1614),\n",
       " (8.116142272949219, 34613),\n",
       " (8.116414070129395, 25252),\n",
       " (8.120088577270508, 11385),\n",
       " (8.120560646057129, 50608),\n",
       " (8.123790740966797, 24898),\n",
       " (8.12673568725586, 8094),\n",
       " (8.12756633758545, 9461),\n",
       " (8.12824821472168, 16799),\n",
       " (8.128447532653809, 8343),\n",
       " (8.128803253173828, 40807),\n",
       " (8.131011962890625, 20510),\n",
       " (8.131343841552734, 37730),\n",
       " (8.133160591125488, 28117),\n",
       " (8.139480590820312, 37995),\n",
       " (8.139514923095703, 17534),\n",
       " (8.14295768737793, 33983),\n",
       " (8.143332481384277, 49584),\n",
       " (8.144902229309082, 59052),\n",
       " (8.145347595214844, 57066),\n",
       " (8.147270202636719, 38982),\n",
       " (8.148530006408691, 3680),\n",
       " (8.150461196899414, 16708),\n",
       " (8.153888702392578, 51805),\n",
       " (8.154814720153809, 42856),\n",
       " (8.157825469970703, 41724),\n",
       " (8.159222602844238, 53074),\n",
       " (8.15927791595459, 13557),\n",
       " (8.159870147705078, 42526),\n",
       " (8.162541389465332, 14537),\n",
       " (8.165131568908691, 13660),\n",
       " (8.165803909301758, 42614),\n",
       " (8.167520523071289, 33779),\n",
       " (8.171954154968262, 45293),\n",
       " (8.174643516540527, 32716),\n",
       " (8.175570487976074, 58505),\n",
       " (8.176532745361328, 48229),\n",
       " (8.1790132522583, 6393),\n",
       " (8.179082870483398, 49501),\n",
       " (8.179600715637207, 30030),\n",
       " (8.181699752807617, 6403),\n",
       " (8.183216094970703, 54139),\n",
       " (8.183958053588867, 39747),\n",
       " (8.185751914978027, 14952),\n",
       " (8.186080932617188, 28122),\n",
       " (8.186408996582031, 11809),\n",
       " (8.187177658081055, 9531),\n",
       " (8.188690185546875, 13888),\n",
       " (8.190520286560059, 7725),\n",
       " (8.190642356872559, 37834),\n",
       " (8.191235542297363, 13516),\n",
       " (8.1924409866333, 31536),\n",
       " (8.192587852478027, 47346),\n",
       " (8.192731857299805, 44586),\n",
       " (8.195698738098145, 32222),\n",
       " (8.199177742004395, 14981),\n",
       " (8.199228286743164, 37530),\n",
       " (8.202107429504395, 7192),\n",
       " (8.207113265991211, 10829),\n",
       " (8.207966804504395, 10030),\n",
       " (8.210290908813477, 31116),\n",
       " (8.211091995239258, 34716),\n",
       " (8.213486671447754, 12345),\n",
       " (8.214765548706055, 265),\n",
       " (8.214917182922363, 34472),\n",
       " (8.215213775634766, 1376),\n",
       " (8.216940879821777, 16292),\n",
       " (8.218365669250488, 41911),\n",
       " (8.220993041992188, 7855),\n",
       " (8.22303581237793, 46509),\n",
       " (8.229050636291504, 999),\n",
       " (8.230523109436035, 28459),\n",
       " (8.230890274047852, 19437),\n",
       " (8.232488632202148, 39224),\n",
       " (8.233129501342773, 12956),\n",
       " (8.234249114990234, 1630),\n",
       " (8.234305381774902, 52980),\n",
       " (8.237801551818848, 45127),\n",
       " (8.23830795288086, 5776),\n",
       " (8.238409996032715, 33297),\n",
       " (8.239242553710938, 47288),\n",
       " (8.240537643432617, 12645),\n",
       " (8.240967750549316, 14539),\n",
       " (8.241907119750977, 46427),\n",
       " (8.243409156799316, 13466),\n",
       " (8.244661331176758, 409),\n",
       " (8.245370864868164, 23178),\n",
       " (8.2473783493042, 18009),\n",
       " (8.248855590820312, 36818),\n",
       " (8.248859405517578, 13518),\n",
       " (8.249757766723633, 33305),\n",
       " (8.249883651733398, 58563),\n",
       " (8.250975608825684, 33752),\n",
       " (8.251380920410156, 34681),\n",
       " (8.251569747924805, 39758),\n",
       " (8.252250671386719, 17108),\n",
       " (8.252883911132812, 15647),\n",
       " (8.253363609313965, 48199),\n",
       " (8.254405975341797, 35343),\n",
       " (8.254807472229004, 46783),\n",
       " (8.255134582519531, 34384),\n",
       " (8.256239891052246, 46399),\n",
       " (8.256491661071777, 34046),\n",
       " (8.25819206237793, 4215),\n",
       " (8.258368492126465, 27768),\n",
       " (8.261537551879883, 21180),\n",
       " (8.262534141540527, 46981),\n",
       " (8.262731552124023, 4495),\n",
       " (8.262796401977539, 48771),\n",
       " (8.262927055358887, 45524),\n",
       " (8.263191223144531, 55803),\n",
       " (8.265400886535645, 1991),\n",
       " (8.26558780670166, 21893),\n",
       " (8.266777038574219, 7799),\n",
       " (8.27075481414795, 4190),\n",
       " (8.271810531616211, 13745),\n",
       " (8.271904945373535, 41493),\n",
       " (8.27415657043457, 56631),\n",
       " (8.275127410888672, 25734),\n",
       " (8.277717590332031, 44132),\n",
       " (8.277822494506836, 52784),\n",
       " (8.279629707336426, 21509),\n",
       " (8.279932022094727, 37469),\n",
       " (8.28107738494873, 45480),\n",
       " (8.283235549926758, 52970),\n",
       " (8.283244132995605, 35061),\n",
       " (8.283370971679688, 21765),\n",
       " (8.286165237426758, 44888),\n",
       " (8.291544914245605, 56212),\n",
       " (8.291780471801758, 57043),\n",
       " (8.293665885925293, 5460),\n",
       " (8.297645568847656, 21580),\n",
       " (8.299084663391113, 14579),\n",
       " (8.301393508911133, 59190),\n",
       " (8.304015159606934, 25625),\n",
       " (8.305672645568848, 43704),\n",
       " (8.306626319885254, 25737),\n",
       " (8.30837631225586, 49271),\n",
       " (8.309898376464844, 37049),\n",
       " (8.310364723205566, 56643),\n",
       " (8.310558319091797, 37296),\n",
       " (8.3108549118042, 59767),\n",
       " (8.311357498168945, 18457),\n",
       " (8.312826156616211, 3467),\n",
       " (8.313901901245117, 50410),\n",
       " (8.314363479614258, 22379),\n",
       " (8.315845489501953, 5957),\n",
       " (8.317081451416016, 12505),\n",
       " (8.317306518554688, 16089),\n",
       " (8.318387031555176, 29698),\n",
       " (8.318472862243652, 20672),\n",
       " (8.319463729858398, 50401),\n",
       " (8.319954872131348, 58834),\n",
       " (8.320435523986816, 25389),\n",
       " (8.320945739746094, 9509),\n",
       " (8.32266902923584, 37484),\n",
       " (8.322806358337402, 44655),\n",
       " (8.322853088378906, 21452),\n",
       " (8.32510757446289, 22196),\n",
       " (8.326384544372559, 47493),\n",
       " (8.32648754119873, 55892),\n",
       " (8.329429626464844, 38626),\n",
       " (8.329949378967285, 6045),\n",
       " (8.331385612487793, 22422),\n",
       " (8.33271312713623, 26842),\n",
       " (8.333264350891113, 44074),\n",
       " (8.336186408996582, 47906),\n",
       " (8.3392915725708, 7177),\n",
       " (8.344759941101074, 49718),\n",
       " (8.345166206359863, 17935),\n",
       " (8.345246315002441, 24128),\n",
       " (8.3458833694458, 8232),\n",
       " (8.34710693359375, 53637),\n",
       " (8.348807334899902, 52697),\n",
       " (8.350645065307617, 42908),\n",
       " (8.352202415466309, 37651),\n",
       " (8.352531433105469, 13377),\n",
       " (8.353412628173828, 12161),\n",
       " (8.356233596801758, 53684),\n",
       " (8.359100341796875, 44904),\n",
       " (8.360917091369629, 24119),\n",
       " (8.364662170410156, 57872),\n",
       " (8.365134239196777, 11204),\n",
       " (8.367022514343262, 38959),\n",
       " (8.369176864624023, 41240),\n",
       " (8.369355201721191, 35741),\n",
       " (8.3728666305542, 44994),\n",
       " (8.374056816101074, 28291),\n",
       " (8.375336647033691, 3926),\n",
       " (8.376437187194824, 8608),\n",
       " (8.376782417297363, 57771),\n",
       " (8.377326011657715, 54566),\n",
       " (8.378324508666992, 45861),\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DL.x_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 4100.4366 - G_loss: 402.2642 - euclidean_distance_loss: 8.9987\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 2s 240us/step - loss: 1452.3827 - G_loss: 165.4667 - euclidean_distance_loss: 1.5977\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1307.6151 - G_loss: 163.0038 - euclidean_distance_loss: 1.2080\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1225.1043 - G_loss: 159.8741 - euclidean_distance_loss: 1.0026\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1222.3425 - G_loss: 160.5130 - euclidean_distance_loss: 0.9269\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1254.2453 - G_loss: 174.4783 - euclidean_distance_loss: 0.6848\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1238.9475 - G_loss: 159.6042 - euclidean_distance_loss: 1.2181\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 2s 246us/step - loss: 1148.1338 - G_loss: 156.8432 - euclidean_distance_loss: 0.6925\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 2s 249us/step - loss: 1125.8958 - G_loss: 158.5310 - euclidean_distance_loss: 0.4830\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1173.0164 - G_loss: 156.7342 - euclidean_distance_loss: 0.4593\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 2s 238us/step - loss: 1150.8917 - G_loss: 158.6684 - euclidean_distance_loss: 0.6197\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1112.2006 - G_loss: 157.3956 - euclidean_distance_loss: 0.4674\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 2s 240us/step - loss: 1104.4388 - G_loss: 158.2829 - euclidean_distance_loss: 0.4034\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 2s 242us/step - loss: 1095.8185 - G_loss: 157.7046 - euclidean_distance_loss: 0.3830\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 2s 243us/step - loss: 1093.3287 - G_loss: 157.8431 - euclidean_distance_loss: 0.3565\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1097.0396 - G_loss: 155.8947 - euclidean_distance_loss: 0.3385\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1087.5693 - G_loss: 157.9956 - euclidean_distance_loss: 0.3795\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1077.8247 - G_loss: 156.6681 - euclidean_distance_loss: 0.3415\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1116.1027 - G_loss: 164.0116 - euclidean_distance_loss: 0.3499\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 2s 244us/step - loss: 1092.6860 - G_loss: 158.7976 - euclidean_distance_loss: 0.4158\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 1075.1851 - G_loss: 156.9890 - euclidean_distance_loss: 0.3316\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 2s 249us/step - loss: 1084.3013 - G_loss: 160.4580 - euclidean_distance_loss: 0.3224\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1072.6872 - G_loss: 156.4535 - euclidean_distance_loss: 0.3613\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 2s 248us/step - loss: 1068.2516 - G_loss: 156.8303 - euclidean_distance_loss: 0.3628\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1065.2187 - G_loss: 157.2940 - euclidean_distance_loss: 0.3121\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 2s 246us/step - loss: 1059.4176 - G_loss: 156.9437 - euclidean_distance_loss: 0.3052\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 2s 245us/step - loss: 1056.9415 - G_loss: 156.8589 - euclidean_distance_loss: 0.3118\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1053.5817 - G_loss: 156.9991 - euclidean_distance_loss: 0.2869\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1050.1220 - G_loss: 156.2898 - euclidean_distance_loss: 0.2927\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1050.4798 - G_loss: 157.3106 - euclidean_distance_loss: 0.2689\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1046.3326 - G_loss: 156.7464 - euclidean_distance_loss: 0.2791\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 2s 249us/step - loss: 1060.2781 - G_loss: 156.3000 - euclidean_distance_loss: 0.2636\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 2s 249us/step - loss: 1055.3445 - G_loss: 158.0562 - euclidean_distance_loss: 0.3049\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 2s 250us/step - loss: 1048.4972 - G_loss: 156.6730 - euclidean_distance_loss: 0.2917\n",
      "Epoch 35/100\n",
      " 7000/10000 [====================>.........] - ETA: 0s - loss: 1046.4875 - G_loss: 157.2436 - euclidean_distance_loss: 0.2879"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-598aa8378bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     batch_size=config.batch_size)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.model.fit(\n",
    "    x={'A':x1,'B':x2},\n",
    "    y={'euclidean_distance':combo_y.reshape(-1,1),\n",
    "       'G':x1,\n",
    "       'G_1':x2,},\n",
    "    verbose=1,\n",
    "    epochs=config.epochs,\n",
    "    batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = trainer.E\n",
    "y_enc = encoder.predict(DL.sx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class,z_lat = y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_class[:,0],y_class[:,1],c=DL.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_builder = GResNet(y_dim=config.y_dim,z_dim=config.z_dim,dec_blocks=config.dec_blocks)\n",
    "# E_builder = EDense(enc_layers=config.enc_layers,z_dim=config.z_dim,)\n",
    "# trainer = Trainer(config,DL,E_builder,G_builder,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,idx = plot_ovt(DL,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.build_model()\n",
    "# trainer.E.inputs\n",
    "z_encoder = Model(\n",
    "    trainer.E.inputs[0],\n",
    "    trainer.E.get_layer(name='z_lat').output\n",
    ")\n",
    "classifier = Model(\n",
    "    trainer.E.inputs[0],\n",
    "    trainer.E.get_layer(name='class').output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "RF = to_categorical(np.ones(len(DL.sx_train)),num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.go(x=DL.sx_train,\n",
    "#            y={'class':DL.y_train_oh,'D':RF,'G':DL.sx_train},\n",
    "#            validation_split=0.05,\n",
    "#            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "#                          rotation=0.25,\n",
    "#                          translation=0.9,\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame.from_records(trainer.model.history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "metrics = ['loss','G_loss','class_acc']\n",
    "fig,axs = plt.subplots(nrows=len(metrics),sharex=True,figsize=(5,10))\n",
    "for metric_name,ax in zip(metrics,axs):\n",
    "    sns.scatterplot(data=hist_df[[metric_name,'val_'+metric_name]],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.dev_mode:\n",
    "    trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = trainer.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decoder_inp = Input(shape=(config.y_dim+config.z_dim,))\n",
    "# dec_layers = trainer.model.layers[-(1+(5*2)):]\n",
    "# print(dec_layers)\n",
    "# _gen_x = dec_layers[0](decoder_inp)\n",
    "# l = dec_layers[1]\n",
    "# isinstance(l,keras.layers.core.Reshape)\n",
    "# F = None\n",
    "# for l in dec_layers[1:]:\n",
    "#     print(type(l))\n",
    "    \n",
    "#     if isinstance(l,keras.layers.merge.Add):\n",
    "#         _gen_x = l([F,_gen_x])\n",
    "#     else:\n",
    "#         _gen_x = l(_gen_x)\n",
    "    \n",
    "#     if isinstance(l,keras.layers.convolutional.Conv2DTranspose):\n",
    "#         if l.kernel_size==(1,1):\n",
    "#             F = _gen_x\n",
    "            \n",
    "# # generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL.y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "classifier.evaluate(DL.sx_test,DL.y_test_oh,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc = z_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_class = classifier.predict(DL.sx_test,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec = np.concatenate([y_class,z_enc],axis=1)\n",
    "_lat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen = generator.predict(_lat_vec,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = np.random.randint(0,10000)\n",
    "plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_samples(DL.x_test[outl],DL.sx_test[outl],z_enc,y_class,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import var_expl\n",
    "dxs = DL.dx[1]-14\n",
    "dys = DL.dy[1]-14\n",
    "dtheta = DL.dtheta[1]\n",
    "fve_dx = var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "fve_dy = var_expl(features=z_enc,cond=dys,bins=21)\n",
    "fve_dt = var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm = np.nan_to_num((dxs.var()-fve_dx)/dxs.var())\n",
    "fve_dy_norm = np.nan_to_num((dys.var()-fve_dy)/dys.var())\n",
    "fve_dth_norm = (dtheta.var()-fve_dt)/dtheta.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=fve_dx_norm.mean(axis=0),y=fve_dy_norm.mean(axis=0),hue=np.arange(config.z_dim))\n",
    "plt.xlabel('fve_dx')\n",
    "plt.ylabel('fve_dy')\n",
    "# plt.ylim(-0.125,0.25)\n",
    "xdim = np.argmax(fve_dx_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dy_norm.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dy')\n",
    "# plt.ylim(-0.125,0.25)\n",
    "ydim = np.argmax(fve_dy_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dth_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dtheta')\n",
    "# plt.ylim(0.0,0.5)\n",
    "np.argmax(fve_dth_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],DL.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import Z_color_scatter\n",
    "Z_color_scatter(z_enc,[xdim,ydim],dxs)\n",
    "# plt.ylim(-3,3)\n",
    "# plt.xlim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outl = z_enc[:,4]>5\n",
    "plt.imshow(DL.sx_test[outl][np.random.randint(0,97)].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dys)\n",
    "# plt.ylim(-3,3)\n",
    "# plt.xlim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(dtheta,z_enc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
