{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Dense,Input,Lambda,Concatenate\n",
    "from keras.models import Model\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras.backend as K\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import process_mnist,gen_trajectory,gen_sorted_isomap,limit_mem\n",
    "from src.models import build_dense\n",
    "from src.data_loader import prepare_keras_dataset,Shifted_Data_Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading fashion_mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3125/60000 [00:00<00:01, 31238.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:01<00:00, 33758.21it/s]\n",
      " 37%|███▋      | 3651/10000 [00:00<00:00, 36494.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 36660.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# train the VAE on MNIST digits\n",
    "DL = Shifted_Data_Loader(dataset='fashion_mnist')\n",
    "class_ids = np.unique(DL.y_train)\n",
    "masks_train = [DL.y_train==i for i in class_ids]\n",
    "masks_test = [DL.y_test==i for i in class_ids]\n",
    "\n",
    "y_test_oh = to_categorical(DL.y_test,num_classes=10)\n",
    "y_train_oh = to_categorical(DL.y_train,num_classes=10)\n",
    "\n",
    "input_shape=(4*784,)\n",
    "print(DL.x_train.shape)\n",
    "print(DL.x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 250\n",
    "print(y_train[masks_train[2]][i])\n",
    "fig,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "axs[0].imshow(x_train[masks_train[2]][i].reshape(28,28))\n",
    "axs[1].imshow(sx_train[masks_train[2]][i].reshape(28*2,28*2))\n",
    "\n",
    "axs[0].get_xaxis().set_visible(False)\n",
    "axs[0].get_yaxis().set_visible(False)\n",
    "axs[1].get_xaxis().set_visible(False)\n",
    "axs[1].get_yaxis().set_visible(False)\n",
    "\n",
    "# fig.savefig('./shifted_mnist_3.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dims = [3000,1500]\n",
    "z_dim = 2\n",
    "y_dim = 3\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Brian Cheungs netowkr\n",
    "encoded = build_dense(inputs,encoding_dims,activations='relu')\n",
    "\n",
    "# encoded = build_dense(inputs,[512,encoding_dim],activations='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean = Dense(z_dim,name='z_mean')(encoded)\n",
    "# z_log_sigma = Dense(latent_dim)(encoded)\n",
    "\n",
    "def sampler(args):\n",
    "    mean,log_stddev = args\n",
    "    std_norm = K.random_normal(shape=(K.shape(mean)[0],latent_dim),mean=0,stddev=1)\n",
    "    \n",
    "    return mean + K.exp(log_stddev) * std_norm\n",
    "\n",
    "# lat_vec = Lambda(sampler)([z_mean,z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_mean = Dense(y_dim,name='y_mean')(encoded)\n",
    "# y_hat_sigma = Dense(y_dim,name='y_sigma')(encoded)\n",
    "# y_hat = Lambda(sampler, name='y_hat')([y_hat_mean,y_hat_sigma])\n",
    "y_hat = Dense(10,activation='softmax',name='y_hat')(encoded)\n",
    "\n",
    "# Concatenate with One-hot identity vector\n",
    "combo_vec = Concatenate()([z_mean,y_hat])\n",
    "\n",
    "decoded_mean = build_dense(combo_vec,[encoding_dims[1],encoding_dims[0]]+[4*784],activations=['relu','relu','sigmoid'])\n",
    "# decoded_mean = build_dense(combo_vec,[encoding_dim,512,784],activations=['relu','relu','sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import *\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "def acc(y_true,y_pred):\n",
    "    return categorical_accuracy(y_true,y_hat)\n",
    "\n",
    "def kl_loss_tot(y_true,y_pred):\n",
    "    return kl_loss_z(y_true,y_pred)\n",
    "\n",
    "def xentropy(y_true,y_pred):\n",
    "    return 2*categorical_crossentropy(y_true,y_hat)\n",
    "\n",
    "def recon_mse(y_true,y_pred):\n",
    "    return K.mean(K.sum(K.square(y_pred-inputs),axis=-1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = ReconstructionLoss(inputs=inputs,outputs=decoded_mean)\n",
    "xcov = XCov(y_hat,z_mean,weight=1)\n",
    "# kl_loss_z = KLDivergenceLoss(z_log_sigma,z_mean,weight=0.001,name='DKL_z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(inputs,decoded_mean)\n",
    "def vae_loss(y_true,y_pred):\n",
    "    total_loss = 0\n",
    "    loss_fns = [\n",
    "        K.sum(recon_loss(y_true,y_pred)),\n",
    "        10*xcov(y_true,y_pred),\n",
    "        K.sum(10*categorical_crossentropy(y_true,y_hat)),\n",
    "#         K.sum(kl_loss_z(y_true,y_pred))/128,\n",
    "#         K.sum(kl_loss_y(y_true,y_pred))\n",
    "    ]\n",
    "#     print(K.int_shape(xcov(y_true,y_pred)))\n",
    "    for L in loss_fns:\n",
    "        total_loss += L\n",
    "        \n",
    "    return total_loss\n",
    "# vae.compile(loss=vae_loss,optimizer='rmsprop')\n",
    "vae.compile(loss=vae_loss,optimizer='adadelta',metrics=[acc,xentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x=sx_train, y=y_train_oh,\n",
    "        shuffle=True,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_session().close()\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs,z_mean)\n",
    "classifier = Model(inputs,y_hat)\n",
    "decoder_inp = Input(shape=(12,))\n",
    "# _generator_x = build_dense(decoder_inp,[encoding_dim,256,784],activations=['relu','relu','sigmoid'])\n",
    "# generator = Model(decoder_inp,decoded_mean)\n",
    "# print(generator.summary())\n",
    "dec_layers = vae.layers[-3:]\n",
    "_gen_x = dec_layers[0](decoder_inp)\n",
    "_gen_x = dec_layers[1](_gen_x)\n",
    "outputs = dec_layers[2](_gen_x)\n",
    "generator = Model(decoder_inp,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(sx_test,batch_size=128)\n",
    "y_oh_enc = classifier.predict(sx_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sx_test[5].reshape(56,56))\n",
    "# generator.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x_test_encoded[:,0],x_test_encoded[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vec = np.concatenate([x_test_encoded[:5],y_oh_enc[:5]],axis=1)\n",
    "cat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_encoded[2]\n",
    "dec_test = generator.predict(cat_vec)\n",
    "plt.imshow(dec_test[4].reshape(56,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(date.today())\n",
    "save_dir = '/home/elijahc/projects/vae/models/'+str(date.today())+'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save(save_dir+'vae_3layer.h5',include_optimizer=False)\n",
    "# encoder.save(save_dir+'enc.h5',include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_lat(z,y_class,sweep=0,hold=1,num_std=2):\n",
    "    z_mean = z[:,sweep].mean()\n",
    "    z_std = z[:,sweep].std()\n",
    "    x0 = np.array([z_mean-(num_std*z_std),z[:,hold].mean()])\n",
    "    x1 = np.array([z_mean+(num_std*z_std),z[:,hold].mean()])\n",
    "    traj = gen_trajectory(np.concatenate([x0,y_class],axis=0),np.concatenate([x1,y_class],axis=0),delta=.1)\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z0_mean = np.mean(x_test_encoded[:,0])\n",
    "# z0_std = x_test_encoded[:,0].std()\n",
    "# z1_mean = x_test_encoded[:,1].mean()\n",
    "# z1_std = x_test_encoded[:,1].std()\n",
    "# x0 = np.array([z0_mean-(2*z0_std),z1_mean])\n",
    "# x1 = np.array([z0_mean+(2*z0_std),z1_mean])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = sweep_lat(x_test_encoded,y_oh_enc[5])\n",
    "dec_traj = K.get_value(generator(K.variable(traj)))\n",
    "dec_traj = dec_traj.reshape(11,56,56)\n",
    "fig, axs = plt.subplots(1,11,figsize=(10,10))\n",
    "for i,ax in enumerate(axs):\n",
    "    \n",
    "    ax.imshow(dec_traj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = sweep_lat(x_test_encoded,y_oh_enc[5],sweep=1,hold=0)\n",
    "dec_traj = K.get_value(generator(K.variable(traj)))\n",
    "dec_traj = dec_traj.reshape(11,56,56)\n",
    "fig, axs = plt.subplots(1,11,figsize=(10,10))\n",
    "for i,ax in enumerate(axs):\n",
    "    \n",
    "    ax.imshow(dec_traj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,11,figsize=(10,10))\n",
    "for i,ax in enumerate(axs):\n",
    "    \n",
    "    ax.imshow(dec_traj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=3\n",
    "sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# z0mean = z_mean_enc[:,0].mean()\n",
    "# z1mean = z_mean_enc[:,1].mean()\n",
    "# z0_sigma = z_mean_enc[:,0].std()\n",
    "# z1_sigma = z_mean_enc[:,1].std()\n",
    "# # z2_sigma = x_test_lat_enc[:,2].std()\n",
    "\n",
    "fig,axs = plt.subplots(examples,4,figsize=(6,8))\n",
    "choices = np.random.choice(np.arange(len(y_test)),examples)\n",
    "# lat_vec_ = z_mean_enc[choices]\n",
    "lat_vec_ = np.concatenate([x_test_encoded[choices],y_oh_enc[choices]],axis=1)\n",
    "print(lat_vec_.shape)\n",
    "dec_test = generator.predict(lat_vec_)\n",
    "\n",
    "# print(x_test_encoded[choices])\n",
    "\n",
    "for i,idx in enumerate(choices):\n",
    "    rec_true_im = x_test[idx].reshape(28,28)\n",
    "    in_im = sx_test[idx].reshape(28*2,28*2)\n",
    "    dec_im = dec_test[i].reshape(28*2,28*2)\n",
    "    \n",
    "    axs[i,0].imshow(rec_true_im)\n",
    "    axs[i,0].set_xticklabels([])\n",
    "    axs[i,0].set_yticklabels([])\n",
    "    \n",
    "    axs[i,1].imshow(in_im)\n",
    "    axs[i,1].set_xticklabels([])\n",
    "    axs[i,1].set_yticklabels([])\n",
    "    \n",
    "    axs[i,2].imshow(dec_im)\n",
    "    axs[i,2].set_xticklabels([])\n",
    "    axs[i,2].set_yticklabels([])\n",
    "#     axs[2,i].set_xlabel(\"class: {}\".format(str(np.argmax(y_class_enc[idx]))))\n",
    "    \n",
    "    axs[i,3].imshow(y_oh_enc[idx].reshape(-1,1).T)\n",
    "    axs[i,3].set_xticklabels([])\n",
    "    axs[i,3].set_yticklabels([])\n",
    "    axs[i,3].set_xlabel(\"class: {}\".format(str(np.argmax(y_oh_enc[idx]))))\n",
    "    \n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "# plt.imshow(dec_test[2].reshape(28,28).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = delta_test[:,0]\n",
    "dys = delta_test[:,1]\n",
    "sns.set_context('talk')\n",
    "plt.scatter(x_test_encoded[:,0],x_test_encoded[:,1],c=dxs-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dx in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z}_0$\")\n",
    "plt.ylabel(r\"$\\hat{Z}_1$\")\n",
    "plt.savefig(\"../figures/shifted_fashion_mnist_dx.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test_encoded[:,0],x_test_encoded[:,1],c=dys-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dy in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z}_0$\")\n",
    "plt.ylabel(r\"$\\hat{Z}_1$\")\n",
    "plt.savefig(\"../figures/shifted_fashion_mnist_dy.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axs = plt.subplots(1,2,figsize=(12,5))\n",
    "plt.scatter(dxs-14,dys-14,c=x_test_encoded[:,0])\n",
    "# con = plt.contourf(dxs-14,dys-14,z_mean_enc[:,0])\n",
    "# ax[1].scatter(dxs-14,dys-14,c=z_mean_enc[:,1])\n",
    "# ax[0].set_xlabel('dx')\n",
    "# ax[1].set_ylabel('dy')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r\"Shift ($\\Delta x$)\")\n",
    "plt.ylabel(r\"Shift ($\\Delta y$)\")\n",
    "plt.title(r\"dxdy shift in $\\hat{Z}_0$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_32 = vae.layers[6]\n",
    "enc_256 = vae.layers[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.trainable=False\n",
    "x = enc_32(encoder.outputs[0])\n",
    "y_class_oh = Dense(10,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = Model(inputs=inputs,outputs=y_class_oh)\n",
    "med.layers[-2].trainable=False\n",
    "for l in med.layers[1:4]:\n",
    "    l.trainable=False\n",
    "med.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = to_categorical(y_train,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med.fit(x_train,y_train_oh,\n",
    "        batch_size=128,\n",
    "        epochs=25,\n",
    "        validation_data=(x_test,to_categorical(y_test,num_classes=10))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g = generator.predict(x_test_encoded[:3])\n",
    "y_test_im = x_g.reshape(3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_im = x_test.reshape(10000,28,28)[:3]\n",
    "\n",
    "fig,axs = plt.subplots(1,3)\n",
    "for im,ax in zip(x_test_im,axs):\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3)\n",
    "for im,ax in zip(y_test_im,axs):\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med.evaluate(x_test,to_categorical(y_test,num_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
