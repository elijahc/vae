{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial and Identity Tandem VAE\n",
    "Inspired by Olshausen and Cheung's work we try to segregate identity from spatial information in an unsupervised way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- ~~Implement cross-covariance penalty~~\n",
    "    - https://stackoverflow.com/questions/45874928/how-to-compute-covariance-in-tensorflow\n",
    "    - https://arxiv.org/abs/1412.6583\n",
    "    - https://en.wikipedia.org/wiki/Cross-covariance\n",
    "    - ~~Needs to be per-batch basis, use regularization?~~ Just operate on the layer, it has shape [batch,dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijahc/.pyenv/versions/3.5.2/envs/jupyterlab/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import keras as keras\n",
    "from keras.layers import Dense,Input,Lambda,Concatenate,Activation\n",
    "from keras.models import Model,load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.losses import categorical_crossentropy,logcosh\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.callbacks import BaseLogger,RemoteMonitor,TerminateOnNaN\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from src.models import build_dense\n",
    "from src.utils import ElasticSearchMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test Fasion MNIST data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train,w_train), (x_test,y_test,w_test) = emnist.load_byclass()\n",
    "(x_train, y_train), (x_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "class_ids = np.unique(y_train)\n",
    "masks_train = [y_train==i for i in class_ids]\n",
    "masks_test = [y_test==i for i in class_ids]\n",
    "\n",
    "y_test_oh = to_categorical(y_test,num_classes=10)\n",
    "y_train_oh = to_categorical(y_train,num_classes=10)\n",
    "\n",
    "digit_mask = lambda y: y<10 \n",
    "uppercase = lambda y: (y>=10) & (y<36)\n",
    "lowercase = lambda y: (y>=36) & (y<62)\n",
    "\n",
    "input_shape=(784,)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "# plt.imshow(x_train[masks[4]][10].reshape(28,28).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3969/60000 [00:00<00:01, 39676.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:01<00:00, 40264.29it/s]\n",
      " 38%|███▊      | 3845/10000 [00:00<00:00, 38434.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 38676.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make dataset thats just a copy with random offsets\n",
    "num_train = len(y_train)\n",
    "num_test = len(y_test)\n",
    "\n",
    "# pre-allocate shifted inputs\n",
    "sx_train = np.empty((num_train,784*4))\n",
    "sx_test = np.empty((num_test,784*4))\n",
    "\n",
    "# pre-allocate list of dx,dy shifts for each image\n",
    "delta_train = np.empty((num_train,2))\n",
    "delta_test = np.empty((num_test,2))\n",
    "\n",
    "def random_offset(X,scale=2):\n",
    "    bg_size=(28*scale,28*scale)\n",
    "    \n",
    "    dx = int(np.random.randint(-10,10))+14\n",
    "    dy = int(np.random.randint(-10,10))+14\n",
    "    \n",
    "    dx = max(dx,0)\n",
    "    dx = min(dx,bg_size[0]-28)\n",
    "    \n",
    "    dy = max(dy,0)\n",
    "    dy = min(dy,bg_size[0]-28)\n",
    "#     print(dx,dy)\n",
    "    new_im = np.zeros(bg_size)\n",
    "    new_im[dx:dx+28,dy:dy+28] = letter\n",
    "    \n",
    "    return new_im,np.array([dx,dy])\n",
    "\n",
    "print('making training data...')\n",
    "for i in tqdm(np.arange(num_train)):\n",
    "    letter = x_train[i].reshape(28,28)\n",
    "    new_im,offsets = random_offset(letter,scale=2)\n",
    "    sx_train[i] = new_im.reshape(1,4*784)\n",
    "    delta_train[i] = offsets\n",
    "\n",
    "print('making testing data...')\n",
    "for i in tqdm(np.arange(num_test)):\n",
    "    letter = x_test[i].reshape(28,28)\n",
    "    new_im,offsets = random_offset(letter,scale=2)\n",
    "    sx_test[i] = new_im.reshape(1,4*784)\n",
    "    delta_test[i] = offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbe3815400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(delta_test[:,0],delta_test[:,1],bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a shifted digit on a larger background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbdf87f4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "print(y_train[masks_train[5]][i])\n",
    "fig,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "axs[0].imshow(x_train[masks_train[3]][i].reshape(28,28))\n",
    "axs[1].imshow(sx_train[masks_train[3]][i].reshape(28*2,28*2))\n",
    "\n",
    "axs[0].get_xaxis().set_visible(False)\n",
    "axs[0].get_yaxis().set_visible(False)\n",
    "axs[1].get_xaxis().set_visible(False)\n",
    "axs[1].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.savefig('./shifted_mnist_3.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "```\n",
    "|     Inputs (3136)     |\n",
    " \\      h1 (1500)      /\n",
    "  |     h2 (1500)     |\n",
    "  \n",
    "     |z_hat| |y_hat|\n",
    "     \n",
    "    /   h3 (1500)   \\\n",
    "   |    h4 (1500)    |\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dims = [3000,3000]\n",
    "z_dim = 2\n",
    "y_dim = 3\n",
    "\n",
    "# randomly shifted image\n",
    "inputs = Input(shape=(784*4,))\n",
    "# encoded = Dense(encoding_dim,activation='relu')(inputs)\n",
    "encoded = build_dense(inputs,encoding_dims,activations='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dist_sample = sampler( args=(mean,std) )\n",
    ">\n",
    ">parameterizes a normal distribution from a mean and std and samples it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(args):\n",
    "    mean,log_stddev = args\n",
    "    std_norm = K.random_normal(shape=(K.shape(mean)[0],K.shape(mean)[1]),mean=0,stddev=1)\n",
    "    \n",
    "    return mean + (K.exp(log_stddev) * std_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean = Dense(z_dim,name='z_mean')(encoded)\n",
    "# z_log_sigma = Dense(z_dim)(encoded)\n",
    "# \"layerize\" z_hat random variable\n",
    "# lat_vec = Lambda(sampler,name='z_sample')([z_mean,z_log_sigma])\n",
    "\n",
    "# y_hat_mean = Dense(y_dim,name='y_mean')(encoded)\n",
    "# y_hat_sigma = Dense(y_dim,name='y_sigma')(encoded)\n",
    "# y_hat = Lambda(sampler, name='y_hat')([y_hat_mean,y_hat_sigma])\n",
    "# y_hat = Dense(3,name='y_hat')(encoded)\n",
    "\n",
    "# latent class repr\n",
    "# y_hat = Dense(2,activation='sigmoid')(encoded)\n",
    "# y_int = Dense(encoding_dims[1],activation='relu')(y_hat)\n",
    "# y_int = Dense(250,activation='relu')(y_int)\n",
    "y_class = Dense(10,activation='softmax')(encoded)\n",
    "\n",
    "# Concatenate with One-hot identity vector\n",
    "combo_vec = Concatenate()([z_mean,y_class])\n",
    "\n",
    "# Expand back out input dimensions (batch_size x im_size)\n",
    "\n",
    "decoded_mean = build_dense(combo_vec,[encoding_dims[1],encoding_dims[0]]+[4*784],activations=['relu','relu','sigmoid'])\n",
    "# decoded_mean = build_dense(combo_vec,[encoding_dims[1],encoding_dims[0]]+[4*784],activations=['relu','relu','sigmoid'])\n",
    "tandem_vae = Model(inputs,decoded_mean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3000)         9411000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3000)         9003000     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            6002        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           30010       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           z_mean[0][0]                     \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3000)         39000       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3000)         9003000     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3136)         9411136     dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 36,903,148\n",
      "Trainable params: 36,903,148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tandem_vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Loss function\n",
    "\n",
    "- Reconstruction loss (sum of squared error)\n",
    "\n",
    "$ \\sum\\limits_{n} (X - \\bar{X})^2 $\n",
    "- Cross-covariance (XCov) of latent vars (z_hat, y_hat)\n",
    "- Classification loss (categorical crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import *\n",
    "        \n",
    "def acc(y_true,y_pred):\n",
    "    return categorical_accuracy(y_true,y_class)\n",
    "\n",
    "def kl_loss_tot(y_true,y_pred):\n",
    "    return kl_loss_z(y_true,y_pred)\n",
    "\n",
    "def xentropy(y_true,y_pred):\n",
    "    return 3*categorical_crossentropy(y_true,y_class)\n",
    "\n",
    "def recon_mse(y_true,y_pred):\n",
    "    return K.mean(K.sum(K.square(y_pred-inputs),axis=-1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = ReconstructionLoss(inputs=inputs,outputs=decoded_mean,weight=1)\n",
    "xcov = XCov(y_class,z_mean,weight=1)\n",
    "# kl_loss_z = KLDivergenceLoss(z_log_sigma,z_mean,weight=0.001,name='DKL_z')\n",
    "# kl_loss_y = KLDivergenceLoss(y_hat_sigma,y_hat_mean, weight=0.0001, name='DKL_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true,y_pred):\n",
    "    total_loss = 0\n",
    "    loss_fns = [\n",
    "        0*K.sum(recon_loss(y_true,y_pred)),\n",
    "        10*xcov(y_true,y_pred),\n",
    "        K.sum(10*categorical_crossentropy(y_true,y_class)),\n",
    "#         K.sum(kl_loss_z(y_true,y_pred))/128,\n",
    "#         K.sum(kl_loss_y(y_true,y_pred))\n",
    "    ]   \n",
    "    for L in loss_fns:\n",
    "        total_loss += L\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "tandem_vae.compile(loss=vae_loss,optimizer='adagrad',metrics=[recon_loss,recon_mse,xcov,acc,xentropy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = RemoteMonitor(root='http://localhost:9200',path='/tensorflow/train_batch/')\n",
    "examples=10\n",
    "choices = np.random.choice(np.arange(len(y_test)),examples)\n",
    "test_ims = sx_train[choices[:3]]\n",
    "# print(test_ims.shape)\n",
    "\n",
    "es_logger = ElasticSearchMonitor(root='http://localhost:9200',path='/tensorflow')\n",
    "ToN = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session ID:  eVQhRm\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.6688147967303', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '8.814244445722769e-10', 'xentropy': '43.44201842809606', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9265.33928978588', '@timestamp': '2018-07-30 11:56:02', 'recon': '0.2447923464289418', 'acc': '0.10074074074074074', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.2154694733796', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '9.807119859500801e-24', 'xentropy': '43.4875130287453', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.23585083912', '@timestamp': '2018-07-30 11:59:15', 'recon': '0.24464778444943605', 'acc': '0.10064814815035572', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.2154690212674', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '1.1113490663252252e-23', 'xentropy': '43.48751299483688', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.426835069444', '@timestamp': '2018-07-30 12:02:27', 'recon': '0.24464778446709667', 'acc': '0.1006481481525633', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.2154686234086', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '1.0232459970586739e-23', 'xentropy': '43.48751301292137', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.140348958334', '@timestamp': '2018-07-30 12:05:40', 'recon': '0.2446477844317754', 'acc': '0.10064814814925194', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.215467755353', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '1.2515136297428797e-23', 'xentropy': '43.48751301744249', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.140334490741', '@timestamp': '2018-07-30 12:08:53', 'recon': '0.24464778446709667', 'acc': '0.10064814814925194', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.2154681170429', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '1.46337801517253e-23', 'xentropy': '43.487513021963615', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.283596643518', '@timestamp': '2018-07-30 12:12:06', 'recon': '0.24464778456864533', 'acc': '0.10064814814594057', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n",
      "posted epoch results!\n",
      "{'val_acc': '0.09416666666666666', 'recon_mse': '767.2154686957465', 'val_xcov': '2.547284842344574e-25', 'val_loss': '9326.145061197916', 'xcov': '9.78639081950991e-24', 'xentropy': '43.48751294849537', 'val_recon_mse': '767.4723131510417', 'val_xentropy': '43.800920328776044', 'loss': '9275.331380642361', '@timestamp': '2018-07-30 12:15:17', 'recon': '0.24464778395493825', 'acc': '0.10064814814814815', 'session': 'eVQhRm', 'val_recon': '0.24472968769073486'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbdf78a748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tandem_vae.fit(x=sx_train,y=y_train_oh,validation_split=0.1,\n",
    "               shuffle=True,\n",
    "               epochs=7,\n",
    "               batch_size=64,\n",
    "               callbacks=[es_logger,ToN],\n",
    "               verbose=0\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3136)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3000)         9411000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3000)         9003000     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            6002        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           30010       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           z_mean[0][0]                     \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3000)         39000       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3000)         9003000     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3136)         9411136     dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 36,903,148\n",
      "Trainable params: 36,903,148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tandem_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a2b2926da05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz_mean_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_int_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "z_mean_encoder = Model(inputs,z_mean)\n",
    "y_hat_encoder = Model(inputs,y_hat)\n",
    "y_int_encoder = Model(inputs,y_int)\n",
    "classifier = Model(inputs,y_class)\n",
    "decoder_inp = Input(shape=(y_dim+z_dim,))\n",
    "dec_layers = tandem_vae.layers[-3:]\n",
    "_gen_x = dec_layers[0](decoder_inp)\n",
    "_gen_x = dec_layers[1](_gen_x)\n",
    "_gen_x = dec_layers[2](_gen_x)\n",
    "generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean_enc = z_mean_encoder.predict(sx_test,batch_size=128)\n",
    "y_class_enc = classifier.predict(sx_test,batch_size=128)\n",
    "y_hat_enc = y_hat_encoder.predict(sx_test,batch_size=128)\n",
    "y_int_enc = y_int_encoder.predict(sx_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n",
    "plt.scatter(y_hat_enc[:,1],y_hat_enc[:,2],c=y_test,cmap='magma')\n",
    "plt.xlabel('y_0')\n",
    "plt.ylabel('y_1')\n",
    "plt.title(r\"Latent Dimension $\\hat{Y}$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tandem_vae.save_weights('../models/tandem_vae/vae_weights.h5')\n",
    "# generator.save_weights('../models/tandem_vae/generator_weights.h5')\n",
    "# lat_encoder.save_weights('../models/tandem_vae/encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adagrad',metrics=['accuracy'])\n",
    "classifier_perf = classifier.evaluate(sx_test,to_categorical(y_test,num_classes=10))\n",
    "\n",
    "print('Classification Accuracy: ',classifier_perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].hist2d(z_mean_enc[:,0],z_mean_enc[:,1]);\n",
    "axs[1].hist2d(delta_test[:,0],delta_test[:,1]);\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=5\n",
    "sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "y_test_oh = to_categorical(y_test,num_classes=10)\n",
    "\n",
    "z0mean = z_mean_enc[:,0].mean()\n",
    "z1mean = z_mean_enc[:,1].mean()\n",
    "z0_sigma = z_mean_enc[:,0].std()\n",
    "z1_sigma = z_mean_enc[:,1].std()\n",
    "# z2_sigma = x_test_lat_enc[:,2].std()\n",
    "\n",
    "fig,axs = plt.subplots(examples,4,figsize=(6,8))\n",
    "choices = np.random.choice(np.arange(len(y_test)),examples)\n",
    "# lat_vec_ = z_mean_enc[choices]\n",
    "lat_vec_ = np.concatenate([z_mean_enc[choices],y_hat_enc[choices]],axis=1)\n",
    "print(lat_vec_.shape)\n",
    "dec_test = generator.predict(lat_vec_)\n",
    "\n",
    "# print(x_test_encoded[choices])\n",
    "\n",
    "for i,idx in enumerate(choices):\n",
    "    rec_true_im = x_test[idx].reshape(28,28)\n",
    "    in_im = sx_test[idx].reshape(28*2,28*2)\n",
    "    dec_im = dec_test[i].reshape(28*2,28*2)\n",
    "    \n",
    "    axs[i,0].imshow(rec_true_im)\n",
    "    axs[i,0].set_xticklabels([])\n",
    "    axs[i,0].set_yticklabels([])\n",
    "    \n",
    "    axs[i,1].imshow(in_im)\n",
    "    axs[i,1].set_xticklabels([])\n",
    "    axs[i,1].set_yticklabels([])\n",
    "    \n",
    "    axs[i,2].imshow(dec_im)\n",
    "    axs[i,2].set_xticklabels([])\n",
    "    axs[i,2].set_yticklabels([])\n",
    "#     axs[2,i].set_xlabel(\"class: {}\".format(str(np.argmax(y_class_enc[idx]))))\n",
    "    \n",
    "    axs[i,3].imshow(y_class_enc[idx].reshape(-1,1).T)\n",
    "    axs[i,3].set_xticklabels([])\n",
    "    axs[i,3].set_yticklabels([])\n",
    "    axs[i,3].set_xlabel(\"class: {}\".format(str(np.argmax(y_class_enc[idx]))))\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# sns.despine(fig=fig)\n",
    "# plt.imshow(dec_test[2].reshape(28,28).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2\n",
    "bins = 11\n",
    "\n",
    "all_sweeps = np.empty((examples,bins,4*784))\n",
    "\n",
    "\n",
    "z0s = np.linspace(z0mean+(-2*z0_sigma),z0mean+(2*z0_sigma),num=bins)\n",
    "z1s = np.linspace(z1mean+(-2*z1_sigma),z1mean+(2*z0_sigma),num=bins)\n",
    "# z2s = np.linspace(-2*z2_sigma,2*z2_sigma,num=10)\n",
    "\n",
    "fig,axs = plt.subplots(examples,bins,figsize=(15,int(15*(examples/bins))))\n",
    "\n",
    "for j,vec in enumerate(lat_vec_):\n",
    "    lat_size = vec.shape[-1]\n",
    "    sweep = np.empty((bins,lat_size))\n",
    "    \n",
    "    for i,z in enumerate(z0s):\n",
    "        sweep[i] = vec\n",
    "        sweep[i,0] = z\n",
    "    \n",
    "    im_sweep = generator.predict(sweep)\n",
    "    all_sweeps[j]=im_sweep\n",
    "    \n",
    "for i in np.arange(examples):\n",
    "    for j in np.arange(bins):\n",
    "        axs[i,j].imshow(all_sweeps[i,j].reshape(56,56))\n",
    "        axs[i,j].set_xticklabels([])\n",
    "        axs[i,j].set_yticklabels([])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(examples,bins,figsize=(14,int(14*(examples/bins))))\n",
    "\n",
    "for j,vec in enumerate(lat_vec_):\n",
    "    lat_size = vec.shape[-1]\n",
    "    sweep = np.empty((bins,lat_size))\n",
    "    for i,z in enumerate(z1s):\n",
    "        sweep[i] = vec\n",
    "        sweep[i,1] = z\n",
    "    \n",
    "    im_sweep = generator.predict(sweep)\n",
    "    all_sweeps[j]=im_sweep\n",
    "    \n",
    "for i in np.arange(examples):\n",
    "    for j in np.arange(bins):\n",
    "        axs[i,j].imshow(all_sweeps[i,j].reshape(56,56))\n",
    "        axs[i,j].set_xticklabels([])\n",
    "        axs[i,j].set_yticklabels([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "dxs = delta_test[:,0]\n",
    "dys = delta_test[:,1]\n",
    "\n",
    "g = sns.jointplot(dxs-14,z_mean_enc[:,0])\n",
    "g.set_axis_labels(xlabel='dx',ylabel='lat_z0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(dys-14,z_mean_enc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z_mean_enc[:,0],z_mean_enc[:,1],c=dxs-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dx in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z_0}$\")\n",
    "plt.ylabel(r\"$\\hat{Z_1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z_mean_enc[:,0],z_mean_enc[:,1],c=dys-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dy in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z_0}$\")\n",
    "plt.ylabel(r\"$\\hat{Z_1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axs = plt.subplots(1,2,figsize=(12,5))\n",
    "plt.scatter(dxs-14,dys-14,c=z_mean_enc[:,0])\n",
    "# con = plt.contourf(dxs-14,dys-14,z_mean_enc[:,0])\n",
    "# ax[1].scatter(dxs-14,dys-14,c=z_mean_enc[:,1])\n",
    "# ax[0].set_xlabel('dx')\n",
    "# ax[1].set_ylabel('dy')\n",
    "plt.colorbar()\n",
    "# plt.title('Latent Variable by x-shift (dx)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(dxs-14,dys-14,c=z_mean_enc[:,1],)\n",
    "plt.xlabel('z_0')\n",
    "plt.ylabel('z_1')\n",
    "plt.title('Latent Variable by y-shift (dy)')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import Isomap\n",
    "\n",
    "# iso = Isomap(n_neighbors=20,n_components=1)\n",
    "# lat_enc_iso = iso.fit_transform(X=x_test_lat_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_enc_iso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(lat_enc_iso),dxs-14,c=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(lat_enc_iso),dys-14,c=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x_test_loc_enc[:, 0], x_test_loc_enc[:, 1],\n",
    "            c=y_test,alpha=0.5\n",
    "           )\n",
    "plt.colorbar()\n",
    "plt.scatter(x=x_test_loc_enc[choices][:,0],y=x_test_loc_enc[choices][:,1],marker='+',\n",
    "            s=20**2,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bqplot.pyplot as bqplt\n",
    "from bqplot import Tooltip\n",
    "import pandas as pd\n",
    "\n",
    "recs = []\n",
    "for i,cid in enumerate(y_test):\n",
    "    recs.append(dict(\n",
    "        loc_z=x_test_loc_enc[i],\n",
    "        loc_z0=x_test_loc_enc[i][0],\n",
    "        loc_z1=x_test_loc_enc[i][1],\n",
    "        id_z=x_test_encoded[i],\n",
    "        id_z0=x_test_encoded[i][0],\n",
    "        id_z1=x_test_encoded[i][1],\n",
    "        class_id=cid,\n",
    "        dx=delta_test[i][0],\n",
    "        dy=delta_test[i][1]\n",
    "    ))\n",
    "enc_df = pd.DataFrame.from_records(recs)\n",
    "enc_df.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df.to_pickle('./tandem_encoder_df.pk')\n",
    "np.save('./sx_test.npy',sx_test)\n",
    "np.save('./dec_test.npy',dec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqplt.figure(title='Autoencoder Latent Space')\n",
    "# def_tt = Tooltip(fields=['x', 'y'], formats=['', '.2f'])\n",
    "# bqplt.scatter(enc_df.loc_z0.values,enc_df.loc_z1.values)\n",
    "# # plt.colorbar()\n",
    "# bqplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
