{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from src.losses import sse, mse\n",
    "from src.test_models.EBGAN import EBGAN,Generator,Encoder,resample,gradient_penalty_loss\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense,Concatenate,Input,Lambda,Activation,Reshape,LSTM,ConvLSTM2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from src.keras_callbacks import PrintHistory,Update_k\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config,_ = get_config()\n",
    "\n",
    "# Boilerplate\n",
    "setattr(config, 'proj_root', '/home/elijahc/projects/vae')\n",
    "setattr(config, 'log_dir', '/home/elijahc/projects/vae/logs')\n",
    "setattr(config, 'dev_mode',True)\n",
    "# setattr(config,'model_dir','/home/elijahc/projects/vae/models/2019-01-17/')\n",
    "\n",
    "# Architecture Params\n",
    "setattr(config, 'enc_layers', [3000,2000])\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 10)\n",
    "setattr(config, 'y_dim', 10)\n",
    "\n",
    "# Training Params\n",
    "setattr(config, 'batch_size', 512)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs', 100)\n",
    "setattr(config, 'monitor', 'val_loss')\n",
    "setattr(config, 'min_delta', 0.5)\n",
    "setattr(config, 'optimizer', 'adam')\n",
    "\n",
    "# Loss Weights\n",
    "setattr(config, 'xcov', 0)\n",
    "setattr(config, 'recon', 10)\n",
    "setattr(config, 'xent', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.dev_mode:\n",
    "    print('setting up...')\n",
    "    prepare_dirs_and_logger(config)\n",
    "    \n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_amt = 0.5 # Med\n",
    "DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model inputs\"\"\"\n",
    "\n",
    "class_input = Input(shape=(10,),name='class_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AutoEncoder Critic\"\"\"\n",
    "x = Input(shape=DL.input_shape,name='Image_input')\n",
    "\n",
    "encoder = Encoder(input_shape=DL.input_shape,\n",
    "                  y_dim=config.y_dim,\n",
    "                  z_dim=config.z_dim,\n",
    "                  layer_units=config.enc_layers)\n",
    "\n",
    "net_out = encoder.build(x)\n",
    "y = Activation('softmax',name='y')(net_out[0])\n",
    "z = Activation('linear',name='z')(net_out[1])\n",
    "\n",
    "# c = Activation('linear',name='critic_score')(net_out[2])\n",
    "\n",
    "yz = Concatenate(name='yz')([y,z])\n",
    "\n",
    "E = Model(inputs = x,\n",
    "          outputs = [y,z],\n",
    "          name='Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decoder \"\"\"\n",
    "decoder = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "Dec_input = Input(shape=(config.y_dim+config.z_dim,),name='Decoder_input')\n",
    "Dec_output = decoder.build(Dec_input)\n",
    "\n",
    "G = Model(inputs=Dec_input,\n",
    "          outputs=Dec_output,\n",
    "          name='Decoder')\n",
    "# G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = Activation('linear',name='x_pred')(G(yz))\n",
    "\n",
    "\n",
    "sse_layer = lambda x: K.expand_dims(sse(x,AE(x)))\n",
    "AE = Model(inputs=x,outputs=x_pred,name='AE')\n",
    "sse_out = Lambda(sse_layer)(AE(x))\n",
    "D = Model(\n",
    "    inputs=x,\n",
    "    outputs=sse_out,\n",
    "    name='D'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generator \"\"\"\n",
    "def gen_Z(y):\n",
    "    Z = K.random_normal(shape=(K.shape(y)[0],config.z_dim))\n",
    "    \n",
    "    return Z\n",
    "\n",
    "generator = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "G_input_y = Input(shape=(config.y_dim,),name='G_y')\n",
    "G_input_z = Lambda(gen_Z,name='G_z')(G_input_y)\n",
    "\n",
    "G_input = Concatenate(name='zy')([G_input_z,G_input_y])\n",
    "\n",
    "G_img = generator.build(G_input)\n",
    "\n",
    "Gen = Model(\n",
    "    inputs=G_input_y,\n",
    "    outputs=G_img,\n",
    "    name='Generator'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Outputs \"\"\"\n",
    "fake_img = Activation('linear',name='fake_img')(Gen(class_input))\n",
    "\n",
    "c_real = Activation('linear',name='C_real')(D(x))\n",
    "c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "# c_real = Activation('linear',name='C_real')(D(x))\n",
    "# c_recon = D(recon_img)\n",
    "# c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "\"\"\" Losses \"\"\"\n",
    "# GAN Losses\n",
    "GAN_d_loss = -1*(c_real - c_fake)\n",
    "GAN_g_loss = -1*c_fake\n",
    "\n",
    "# Gradient Penalty\n",
    "gp_loss = gradient_penalty_loss(x,fake_img,D)\n",
    "\n",
    "# Add Discriminator losses\n",
    "D.add_loss([GAN_d_loss])\n",
    "\n",
    "# Add Generator losses\n",
    "# Gen.add_loss([GAN_g_loss])\n",
    "\n",
    "EBGAN = Model(\n",
    "    inputs=[x,class_input],\n",
    "    outputs=[y,c_real,c_fake],\n",
    "    name='EBGAN'\n",
    ")\n",
    "# mod_outputs = [\n",
    "#     (recon_img, sse, config.recon),\n",
    "#     (y, 'categorical_crossentropy', config.xent),\n",
    "#     (c_fake,lambda yt,yp: GAN_d_loss+GAN_g_loss, 1),\n",
    "# ]\n",
    "\n",
    "# outs,ls,ws = zip(*mod_outputs)\n",
    "\n",
    "# VGAN = Model(\n",
    "# inputs=x,\n",
    "# outputs=outs)\n",
    "\n",
    "# losses = {k:v for k,v in zip(VGAN.output_names,ls)}\n",
    "# loss_W = {k:v for k,v in zip(VGAN.output_names,ws)}\n",
    "\n",
    "metrics = {\n",
    "    'y': 'accuracy',\n",
    "}\n",
    "\n",
    "EBGAN.compile(optimizer=config.optimizer,loss={'y':'categorical_crossentropy','C_real':lambda yt,yp:GAN_d_loss,'C_fake':lambda yt,yp:GAN_g_loss},metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBGAN.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "RF = to_categorical(np.ones(len(DL.sx_train)),num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_history = PrintHistory(print_keys=['loss','val_loss','val_y_acc'])\n",
    "# update_k = Update_k(k_var = k)\n",
    "callbacks=[\n",
    "    print_history,\n",
    "#     update_k\n",
    "]\n",
    "if config.monitor is not None:\n",
    "    early_stop = EarlyStopping(monitor=config.monitor,min_delta=config.min_delta,patience=10,restore_best_weights=True)\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "history = EBGAN.fit(x={'Image_input':DL.sx_train,'class_input':DL.y_train_oh},\n",
    "              y={\n",
    "                  'y':DL.y_train_oh,\n",
    "                  'C_real':RF,\n",
    "                  'C_fake':RF,\n",
    "                  },\n",
    "              verbose=0,\n",
    "              batch_size=config.batch_size,\n",
    "              callbacks=callbacks,\n",
    "              validation_split=0.05,\n",
    "              epochs=config.epochs,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # true_latent_vec = Concatenate()([y_class,z_lat_stats[0]])\n",
    "# latent_vec = Concatenate()([y,z_lat])\n",
    "# shuffled_lat = Concatenate()([y,z_sampled])\n",
    "# G = trainer.G\n",
    "# # recon = Activation('linear',name='G')(G(true_latent_vec))\n",
    "# fake_inp = G(latent_vec)\n",
    "# G_shuff = G(shuffled_lat)\n",
    "# # fake_lat_vec = Concatenate()(E(fake_inp))\n",
    "# # fake_ae = G(fake_lat_vec)\n",
    "\n",
    "# D_real = Activation('linear',name='D_real')(D(real_inp))\n",
    "# D_fake = Activation('linear',name='D_fake')(D(G_shuff))\n",
    "# # D_fake = E(fake_inp)[2]\n",
    "# D_all = Concatenate(axis=0,name='D_all')([D_fake,D_real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,idx = plot_ovt(DL,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_df = pd.DataFrame.from_records(trainer.model.history.history)\n",
    "hist_df = pd.DataFrame.from_records(VGAN.history.history)\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "metrics = ['loss','C_f_loss','y_acc']\n",
    "fig,axs = plt.subplots(nrows=len(metrics),sharex=True,figsize=(5,10))\n",
    "for metric_name,ax in zip(metrics,axs):\n",
    "    sns.scatterplot(data=hist_df[[metric_name,'val_'+metric_name]],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not config.dev_mode:\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_encoder = Model(x,z)\n",
    "classifier = Model(x,y)\n",
    "# y_lat_encoder = Model(trainer.E.input,trainer.y_lat)\n",
    "# decoder_inp = Input(shape=(config.y_dim+config.z_dim,))\n",
    "# dec_layers = trainer.model.layers[-(1+(5*2)):]\n",
    "# print(dec_layers)\n",
    "# _gen_x = dec_layers[0](decoder_inp)\n",
    "# l = dec_layers[1]\n",
    "# isinstance(l,keras.layers.core.Reshape)\n",
    "# F = None\n",
    "# for l in dec_layers[1:]:\n",
    "#     print(type(l))\n",
    "    \n",
    "#     if isinstance(l,keras.layers.merge.Add):\n",
    "#         _gen_x = l([F,_gen_x])\n",
    "#     else:\n",
    "#         _gen_x = l(_gen_x)\n",
    "    \n",
    "#     if isinstance(l,keras.layers.convolutional.Conv2DTranspose):\n",
    "#         if l.kernel_size==(1,1):\n",
    "#             F = _gen_x\n",
    "            \n",
    "# # generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL.y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "classifier.evaluate(DL.sx_test,DL.y_test_oh,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc = z_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "# y_lat = y_lat_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_lat = classifier.predict(DL.sx_test,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec = np.concatenate([y_lat,z_enc],axis=1)\n",
    "_lat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc_mu = np.mean(z_enc,axis=0)\n",
    "z_enc_cov = np.cov(z_enc,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(z_enc_mu,z_enc_cov,size=50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen = generator.predict(_lat_vec,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = np.random.randint(0,10000)\n",
    "plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec[rand_im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL2 = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_samples(DL.x_test,DL.sx_test,z_enc,y_lat,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc2 = z_encoder.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "y_lat2 = classifier.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "_lat_vec2 = np.concatenate([y_lat2,z_enc2],axis=1)\n",
    "regen2 = generator.predict(_lat_vec2,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import remove_axes,remove_labels\n",
    "from src.utils import gen_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 5\n",
    "rand_im = np.random.randint(0,10000,size=examples)\n",
    "fix,axs = plt.subplots(examples,11,figsize=(8,4))\n",
    "_lat_s = []\n",
    "regen_s = []\n",
    "out = gen_trajectory(z_enc[rand_im],z_enc2[rand_im],delta=.25)\n",
    "out_y = gen_trajectory(y_lat[rand_im],y_lat2[rand_im],delta=.25)\n",
    "\n",
    "for z,y in zip(out,out_y):\n",
    "    _lat = np.concatenate([y,z],axis=1)\n",
    "    _lat_s.append(_lat)\n",
    "    regen_s.append(generator.predict(_lat,batch_size=config.batch_size))\n",
    "\n",
    "i=0\n",
    "for axr,idx in zip(axs,rand_im):\n",
    "    axr[0].imshow(DL.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    axr[1].imshow(DL.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[2].imshow(regen[idx].reshape(56,56),cmap='gray')\n",
    "    for j,a in enumerate(axr[3:-3]):\n",
    "        a.imshow(regen_s[j][i,:].reshape(56,56),cmap='gray')\n",
    "#         a.imshow(s.reshape(56,56),cmap='gray')\n",
    "    axr[-3].imshow(regen2[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-2].imshow(DL2.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-1].imshow(DL2.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    for a in axr:\n",
    "        remove_axes(a)\n",
    "        remove_labels(a)\n",
    "    i+=1\n",
    "# plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feat_range = (0,50)\n",
    "z_enc_scaled = [MinMaxScaler(feat_range).fit_transform(z_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(config.z_dim)]\n",
    "z_enc_scaled = np.squeeze(np.array(z_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import dit\n",
    "from dit import Distribution\n",
    "dxs = DL.dx[1]-14\n",
    "dys = DL.dy[1]-14\n",
    "\n",
    "def mutual_information(X,Y):\n",
    "    XY_c = Counter(zip(X,Y))\n",
    "    XY_pmf = {k:v/float(sum(XY_c.values())) for k,v in XY_c.items()}\n",
    "    XY_jdist = Distribution(XY_pmf)\n",
    "        \n",
    "    return dit.shannon.mutual_information(XY_jdist,[0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dx_I = [mutual_information(z_enc_scaled[i],dxs.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dy_I = [mutual_information(z_enc_scaled[i],dys.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_class_I = [mutual_information(z_enc_scaled[i],DL.y_test) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_I_df = pd.DataFrame.from_records({'class':z_class_I,'dy':z_dy_I,'dx':z_dx_I})\n",
    "z_I_df['class'] = z_I_df['class'].values.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,5))\n",
    "ax.set_ylim(0,0.8)\n",
    "ax.set_xlim(0,0.8)\n",
    "points = plt.scatter(x=z_I_df['dx'],y=z_I_df['dy'],c=z_I_df['class'],cmap='plasma')\n",
    "plt.colorbar(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(z_dx_I,z_dy_I)\n",
    "ax.set_ylim(0,0.6)\n",
    "ax.set_xlim(0,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),sorted(z_dy_I,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import var_expl,norm_var_expl\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "dtheta = DL.dtheta[1]\n",
    "fve_dx = norm_var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "fve_dy = norm_var_expl(features=z_enc,cond=dys,bins=21)\n",
    "# fve_dt = norm_var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fve_dx_norm = (dxs.var()-fve_dx)/dxs.var()\n",
    "# fve_dy_norm = (dys.var()-fve_dy)/dys.var()\n",
    "# fve_dth_norm = (dtheta.var()-fve_dt)/dtheta.var()\n",
    "fve_dx_norm = fve_dx\n",
    "fve_dy_norm = fve_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm.shape\n",
    "# np.save(os.path.join(config.model_dir,'fve_dx_norm'),fve_dx_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(fve_dx_norm.mean(axis=0),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('fve_dx')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dx.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "xdim = np.argmax(fve_dx_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dy_norm.mean(axis=0)\n",
    "# np.save(os.path.join(config.model_dir,'fve_dy_norm'),fve_dy_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dy.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "ydim = np.argmax(fve_dy_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(config.z_dim),fve_dth_norm.mean(axis=0))\n",
    "# plt.xlabel('Z_n')\n",
    "# plt.ylabel('fve_dtheta')\n",
    "# # plt.ylim(0.0,0.5)\n",
    "# np.argmax(fve_dth_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import Z_color_scatter\n",
    "Z_color_scatter(z_enc,[xdim,ydim],dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[7,18],dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
