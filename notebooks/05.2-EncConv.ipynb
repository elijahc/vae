{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from brainscore.metrics import Score\n",
    "from brainscore.assemblies import walk_coords\n",
    "from scipy.stats import pearsonr\n",
    "from src.results.experiments import *\n",
    "from src.results.experiments import _DateExperimentLoader\n",
    "from src.models import EConvNet,GResNet\n",
    "from src.trainer import Trainer\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import norm\n",
    "from brainscore.metrics.correlation import Correlation, CrossCorrelation\n",
    "from brainscore.metrics.regression import pearsonr_correlation,CrossRegressedCorrelation,pls_regression,linear_regression\n",
    "from brainscore.metrics.behavior import I2n\n",
    "from brainscore.assemblies import split_assembly\n",
    "from brainio_base.assemblies import DataAssembly\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = Input(shape=(56,56,1))\n",
    "EBuilder = EConvNet(blocks=[32,64,128,256],z_dim=35)\n",
    "out = EBuilder.build(image_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 56, 56, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 454,656\n",
      "Trainable params: 454,144\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "mod = Model(image_in,out)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-76b55b890bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_builder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdec_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_blocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflatten_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "G_builder = GResNet(y_dim=config.y_dim,z_dim=config.z_dim,dec_blocks=config.dec_blocks,flatten_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_builder = GResNet(y_dim=config.y_dim,z_dim=config.z_dim,dec_blocks=config.dec_blocks,flatten_out=False)\n",
    "E_builder = EConvNet(blocks=config.enc_blocks,z_dim=config.z_dim,)\n",
    "trainer = Trainer(config,DL,E_builder,G_builder,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dicarlo(assembly,avg_repetition=True,variation=3,tasks=['ty','tz','rxy']):\n",
    "    stimulus_set = assembly.attrs['stimulus_set']\n",
    "    stimulus_set['dy_deg'] = stimulus_set.tz*stimulus_set.degrees\n",
    "    stimulus_set['dx_deg'] = stimulus_set.ty*stimulus_set.degrees\n",
    "    stimulus_set['dy_px'] = stimulus_set.dy_deg*32\n",
    "    stimulus_set['dx_px'] = stimulus_set.dx_deg*32\n",
    "    \n",
    "    assembly.attrs['stimulus_set'] = stimulus_set\n",
    "    \n",
    "    data = assembly.sel(variation=variation)\n",
    "    groups = ['category_name', 'object_name', 'image_id']+tasks\n",
    "    if not avg_repetition:\n",
    "        groups.append('repetition')\n",
    "        \n",
    "    data = data.multi_groupby(groups)     # (2)\n",
    "    data = data.mean(dim='presentation')\n",
    "    data = data.squeeze('time_bin')    #   (3)\n",
    "    data.attrs['stimulus_set'] = stimulus_set.query('variation == {}'.format(variation))\n",
    "    data = data.T\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_data = process_dicarlo(neural_data)\n",
    "hi_data = process_dicarlo(neural_data,variation=6)\n",
    "# lo_data = process_dicarlo(neural_data,variation=0)\n",
    "v4_med = med_data.sel(region='V4')\n",
    "it_med = med_data.sel(region='IT')\n",
    "\n",
    "v4_hi = hi_data.sel(region='V4')\n",
    "it_hi = hi_data.sel(region='IT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Our Experiments\n",
    "- Lg Feedforward (2019-06-03)\n",
    "    - (3000,2000,500,70)\n",
    "- Sm Feedforward (2019-05-24)\n",
    "    - (3000,2000,500,15)\n",
    "- Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg_ff = _DateExperimentLoader('2019-06-25')\n",
    "lg_ff = _DateExperimentLoader('2019-06-03')\n",
    "# sm_ff = _DateExperimentLoader('2019-05-24')\n",
    "lg_ff.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_xent = lg_ff.assemblies[0]\n",
    "lg_both = lg_ff.assemblies[1]\n",
    "lg_recon = lg_ff.assemblies[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainscore.assemblies import split_assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = tuple(np.logspace(-2,2,num=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RidgeCV(alphas=alphas,store_cv_values=True)\n",
    "tr,te = split_assembly(med_data.sel(region='IT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(tr.values,y=tr['tz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.alpha_)\n",
    "est.cv_values_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(med_data.ty*8,med_data.tz*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUCorrelation(da,neuroid_coord,correlation_vars,exclude_zeros=True):\n",
    "    if exclude_zeros:\n",
    "        nz_neuroids = da.groupby(neuroid_coord).sum('presentation').values!=0\n",
    "        da = da[:,nz_neuroids]\n",
    "    \n",
    "    correlations = np.empty((len(da[neuroid_coord]),len(correlation_vars)))\n",
    "    for i,nid in tqdm(enumerate(da[neuroid_coord].values),total=len(da[neuroid_coord])):\n",
    "        for j,prop in enumerate(correlation_vars):\n",
    "            n_act = da.sel(**{neuroid_coord:nid}).squeeze()\n",
    "            r,p = pearsonr(n_act,prop)\n",
    "            correlations[i,j] = np.abs(r)\n",
    "\n",
    "    neuroid_dim = da[neuroid_coord].dims\n",
    "    c = {coord: (dims, values) for coord, dims, values in walk_coords(da) if dims == neuroid_dim}\n",
    "    c['task']=('task',[v.name for v in correlation_vars])\n",
    "#     print(neuroid_dim)\n",
    "    result = Score(correlations,\n",
    "                       coords=c,\n",
    "                       dims=('neuroid','task'))\n",
    "    return result\n",
    "\n",
    "def result_to_df(SUC,corr_var_labels):\n",
    "    df = SUC.neuroid.to_dataframe().reset_index()\n",
    "    for label in corr_var_labels:\n",
    "        df[label]=SUC.sel(task=label).values\n",
    "    \n",
    "    return df\n",
    "\n",
    "class MURegressor(object):\n",
    "    def __init__(self,da,train_frac=0.8,n_splits=5,n_units=None,estimator=Ridge):\n",
    "        if n_units is not None:\n",
    "            self.neuroid_idxs = [np.array([random.randrange(len(da.neuroid_id)) for _ in range(n_units)]) for _ in range(n_splits)]\n",
    "        \n",
    "        self.original_data = da\n",
    "        self.train_frac = train_frac\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        splits = [split_assembly(self.original_data[:,n_idxs]) for n_idxs in tqdm(self.neuroid_idxs,total=n_splits,desc='CV-splitting')]\n",
    "        self.train = [tr for tr,te in splits]\n",
    "        self.test = [te for tr,te in splits]\n",
    "        \n",
    "        \n",
    "        self.estimators = [estimator() for _ in range(n_splits)]\n",
    "        \n",
    "    def fit(self,y_coord):\n",
    "        # Get Training data\n",
    "        for mod,train in tqdm(zip(self.estimators,self.train),total=len(self.train),desc='fitting'):\n",
    "#             print(train)\n",
    "            mod.fit(X=train.values,y=train[y_coord])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X=None):\n",
    "        if X is not None:\n",
    "            return [e.predict(X) for e in self.estimators]\n",
    "        else:\n",
    "            return [e.predict(te.values) for e,te in zip(self.estimators,self.test)]\n",
    "        \n",
    "    def score(self,y_coord):\n",
    "        return [e.score(te.values,te[y_coord].values) for e,te in zip(self.estimators,self.test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_regressors(data, filt='region',n_units=126,y_coords=['ty','tz'],task_names=None,estimator=Ridge):\n",
    "    subsets = np.unique(data[filt].values)\n",
    "    if task_names is None:\n",
    "        task_names = y_coords\n",
    "    dfs = []\n",
    "    for y,task in zip(y_coords,task_names):\n",
    "        print('regressing {}...'.format(y))\n",
    "        regressors = {k:MURegressor(data.sel(**{filt:k}),n_units=n_units,estimator=Ridge).fit(y_coord=y) for k in subsets}\n",
    "        df = pd.DataFrame.from_records({k:v.score(y_coord=y) for k,v in regressors.items()})\n",
    "        df = df.melt(var_name='region',value_name='performance')\n",
    "        df['task']=task\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df = stratified_regressors(hi_data,y_coords=['ty','tz','rxy'],n_units=100,\n",
    "#                               task_names=['tx','ty','rxy'],\n",
    "                              estimator=RidgeCV)\n",
    "med_df = stratified_regressors(med_data, y_coords=['ty','tz','rxy'],n_units=100,\n",
    "#                                task_names=['tx','ty','rxy'],\n",
    "                               estimator=RidgeCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',hue_order=['V4','IT'],data=med_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='task',y='performance',hue='region',hue_order=['V4','IT'],data=hi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_both_top = lg_both[:,lg_both.layer.isin([2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df = stratified_regressors(lg_both,filt='layer',y_coords=['tx','ty','rxy'],n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg_xent_top = lg_xent[:,lg_xent.layer.isin([2,3,4])]\n",
    "xent_df = stratified_regressors(lg_xent,filt='layer',y_coords=['tx','ty','rxy'],n_units=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='task',y='performance',hue='region',data=both_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='task',y='performance',hue='region',data=xent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_v4_MUR.score(y_coord='ty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tr.shape,te.shape) for tr,te in med_MUR_dicarlo.splits]\n",
    "[n for n in med_MUR_dicarlo.neuroid_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['tx','ty',\n",
    "#               'rxy',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_both = [pd.Series(lg_both[v].values,name=v) for v in ['tx','ty']]\n",
    "corr_both = SUCorrelation(lg_both,neuroid_coord='neuroid_id',correlation_vars=corr_vars_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_xent = [pd.Series(lg_xent[v].values,name=v) for v in ['tx','ty']]\n",
    "corr_xent = SUCorrelation(lg_xent,neuroid_coord='neuroid_id',correlation_vars=corr_vars_xent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars_recon = [pd.Series(lg_recon[v].values,name=v) for v in properties]\n",
    "corr_recon = SUCorrelation(lg_recon,neuroid_coord='neuroid_id',correlation_vars=corr_vars_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_hi_corr_vars = [\n",
    "    pd.Series(hi_data['ty'],name='tx'),\n",
    "    pd.Series(hi_data['tz'],name='ty'),\n",
    "    pd.Series(hi_data['rxy'],name='rxy'),\n",
    "]\n",
    "corr_dicarlo_hi = SUCorrelation(hi_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_hi_corr_vars,exclude_zeros=True)\n",
    "\n",
    "dicarlo_med_corr_vars = [\n",
    "    pd.Series(med_data['ty'],name='tx'),\n",
    "    pd.Series(med_data['tz'],name='ty'),\n",
    "    pd.Series(med_data['rxy'],name='rxy'),\n",
    "\n",
    "]\n",
    "corr_dicarlo_med = SUCorrelation(med_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_med_corr_vars,exclude_zeros=True)\n",
    "\n",
    "\n",
    "# dicarlo_lo_corr_vars = [\n",
    "#     pd.Series(lo_data['ty'],name='tx'),\n",
    "#     pd.Series(lo_data['tz'],name='ty'),\n",
    "# ]\n",
    "# corr_dicarlo_lo = SUCorrelation(lo_data,neuroid_coord='neuroid_id',correlation_vars=dicarlo_lo_corr_vars,exclude_zeros=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicarlo_med_df = result_to_df(corr_dicarlo_med,['tx','ty','rxy'])\n",
    "dicarlo_med_df['variation']=3\n",
    "\n",
    "dicarlo_hi_df = result_to_df(corr_dicarlo_hi,['tx','ty','rxy'])\n",
    "dicarlo_hi_df['variation']=6\n",
    "\n",
    "# dicarlo_lo_df = result_to_df(corr_dicarlo_lo,['tx','ty'])\n",
    "# dicarlo_lo_df['variation']=0\n",
    "# dicarlo_lo_df['norm_ty'] = dicarlo_lo_df['ty']\n",
    "\n",
    "# dicarlo_df = pd.concat([dicarlo_hi_df,dicarlo_med_df])\n",
    "# dicarlo_df['norm_ty'] = dicarlo_df['ty']/2\n",
    "\n",
    "# dicarlo_df = pd.concat([dicarlo_df,dicarlo_lo_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df = result_to_df(corr_both,['tx','ty'])\n",
    "both_df['norm_ty'] = both_df.ty\n",
    "\n",
    "xent_df = result_to_df(corr_xent,['tx','ty'])\n",
    "xent_df['norm_ty'] = xent_df.ty\n",
    "\n",
    "recon_df = result_to_df(corr_recon,['tx','ty'])\n",
    "recon_df['norm_ty'] = recon_df.ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(x,y,df,by='region',order=None):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets),plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "                               'xlim':(0.0,0.8),\n",
    "                               'ylim':(0.0,0.8)\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.kdeplot(sub_df[x],sub_df[y],ax=ax)\n",
    "        ax.set_title(\"{}: {}\".format(by,sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(y,df,by='region',order=None):\n",
    "    if order is not None:\n",
    "        subsets = order\n",
    "    else:\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        \n",
    "    plot_scale = 5\n",
    "    fig,axs = plt.subplots(1,len(subsets),figsize=(plot_scale*len(subsets),plot_scale),sharex=True,sharey=True,\n",
    "                           subplot_kw={\n",
    "                               'xlim':(0.0,0.8),\n",
    "                               'ylim':(0.0,0.8)\n",
    "                           })\n",
    "    \n",
    "    for ax,sub in zip(axs,subsets):\n",
    "        subsets = df[by].drop_duplicates().values\n",
    "        sub_df = df.query('{} == \"{}\"'.format(by,sub))\n",
    "        sns.barplot(x=by,y=y,ax=ax)\n",
    "\n",
    "# plot_bars(y='tx',df=both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='layer',y='ty',data=xent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','ty',both_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','ty',xent_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','norm_ty',recon_df,by='layer',order=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plot_kde('tx','ty',dicarlo_df.query('variation == 6'),by='region',order=['V4','IT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde('tx','ty',dicarlo_df.query('variation == 3'),by='region',order=['V4','IT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = corr.groupby('region')\n",
    "\n",
    "# corr_res = corr.reindex(task=corr.task,neuroid=corr.neuroid_id)\n",
    "corr= corr.name='both'\n",
    "corr.reset_coords()\n",
    "\n",
    "# g.groups\n",
    "# for l,grp in g:\n",
    "#     res_grp = grp.dropna('neuroid')\n",
    "#     res_grp.name=label\n",
    "#     res_grp = res_grp.reindex(task=res_grp.task,neuroid=res_\n",
    "#     print(res_grp)\n",
    "#     res_grp.to_dataframe(name='label').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = corr.dropna(dim='neuroid').reset_index(corr.dims).groupby('region')\n",
    "for label,group in g:\n",
    "    agg_dfs.append(group.reset_index(group.dims).to_dataframe(name='label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dicarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.groupby('neuroid_id').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,pearson3\n",
    "\n",
    "class XArraySUCorrelation(object):\n",
    "    def __init__(self,assembly,stimulus_coords='tx',neuroid_coord='neuroid_id',func=pearsonr):\n",
    "        self.stimulus_coord = stimulus_coord\n",
    "        self.func = func\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact_data = data.multi_groupby(['category_name', 'object_name', 'image_id'])\n",
    "# compact_data = compact_data.mean(dim='presentation')\n",
    "# compact_data = compact_data.squeeze('time_bin')  # (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compact_data = compact_data.T  # (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimulus_set['y_pix'] = scaler.fit_transform(stimulus_set.ty.values.reshape(-1,1))\n",
    "# stimulus_set['z_pix'] = scaler.fit_transform(stimulus_set.tz.values.reshape(-1,1))\n",
    "\n",
    "stimulus_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = stimulus_set.query('variation == 6')\n",
    "tx[['ty','tz','x','y','x_px','y_px']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(tx.ty,tx.tz,shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(v4_resp.x,v4_resp.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "\n",
    "def resp_dist(dat, presentation = None):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "    if presentation is None:\n",
    "        presentation = random.randrange(dat.values.shape[1])\n",
    "    \n",
    "    d = dat[:,presentation]\n",
    "    cat_name, obj_name, image_id, tz, ty = d.presentation.values.tolist()\n",
    "    image_path = stimulus_set.get_image(image_id)\n",
    "    props = stimulus_set.query('image_id == \"{}\"'.format(image_id))\n",
    "    g = sns.distplot(d.values,norm_hist=True,ax=axs[1])\n",
    "    \n",
    "    img = image.imread(image_path)\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title('{} tz:{} yz:{}'.format(obj_name, tz*8,ty*8))\n",
    "    axs[0].scatter(props.x_px.values+128,props.y_px.values+128)\n",
    "    print(props['image_file_name'].values)\n",
    "    print(props[['ty','tz']])\n",
    "    print(props[['x','y','x_px','y_px']])\n",
    "    \n",
    "    return g,props\n",
    "\n",
    "g,props = resp_dist(v4_resp)\n",
    "props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = neural_data.sel(variation=6)  # (1)\n",
    "x = x.multi_groupby(['category_name', 'object_name', 'image_id','repetition','ty','tz'])  # (2)\n",
    "x = x.mean(dim='presentation')\n",
    "x = x.squeeze('time_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_to_df(x):\n",
    "    ty = x.tz.values\n",
    "    tx = x.ty.values\n",
    "    xdf = pd.DataFrame(x.values.T,columns=x.neuroid_id.values)\n",
    "    xdf['class'] = x.object_name.values\n",
    "    xdf['dy']=ty\n",
    "    xdf['dx']=tx\n",
    "\n",
    "    return xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_resp.object_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=1,max_iter=10000,verbose=1)\n",
    "cross_val_score(clf,v4_resp.values.T,v4_resp.category_name.values,verbose=1,cv=5,n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=1,max_iter=10000,verbose=1)\n",
    "cross_val_score(clf,IT_resp.values.T,IT_resp.category_name.values,verbose=1,cv=5,n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels = v4_resp.object_name.values\n",
    "labeler\n",
    "for lab in np.unique(labels):\n",
    "    LabelBinarizer().transform()\n",
    "\n",
    "classifier = SVC(C=10)\n",
    "# cross_val_score(classifier,v4_resp.values.T,v4_resp.object_name.values,cv=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4 = x.sel(region='V4')\n",
    "v4_df = xr_to_df(v4)\n",
    "\n",
    "it = x.sel(region='IT')\n",
    "it_df = xr_to_df(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xarray.open_dataset('/home/elijahc/projects/vae/models/2019-06-03/xent_15_recon_25/label_corruption_0.0/dataset.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds['Only Recon']\n",
    "da.coords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_x_sel = dicarlo_r(v4.values.T,prop=v4_df.dx)\n",
    "v4_y_sel = dicarlo_r(v4.values.T,prop=v4_df.dy)\n",
    "\n",
    "it_x_sel = dicarlo_r(it.values.T,prop=it_df.dx)\n",
    "it_y_sel = dicarlo_r(it.values.T,prop=it_df.dy)\n",
    "\n",
    "# v4_class_sel = dprime(v4_df,num_units=len(v4_resp.neuroid_id),col='class',mask_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_results = pd.DataFrame({\n",
    "    'dx':v4_x_sel,\n",
    "    'dy':v4_y_sel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CrossRegressedCorrelation(regression=pls_regression(),correlation=pearsonr_correlation())\n",
    "v4_score = metric(v4,v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp_dist(v4_resp,random_n=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = stimulus_set.get_image(stimulus_set['image_id'][0])\n",
    "print(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-fastai (Python3.6.1)",
   "language": "python",
   "name": "py3-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
