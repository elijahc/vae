{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from src.losses import sse, mse\n",
    "from src.test_models.EBGAN import EBGAN,Generator,Encoder,resample,gradient_penalty_loss\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from src.keras_callbacks import PrintHistory,Update_k\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config,_ = get_config()\n",
    "\n",
    "# Boilerplate\n",
    "setattr(config, 'proj_root', '/home/elijahc/projects/vae')\n",
    "setattr(config, 'log_dir', '/home/elijahc/projects/vae/logs')\n",
    "setattr(config, 'dev_mode',True)\n",
    "# setattr(config,'model_dir','/home/elijahc/projects/vae/models/2019-01-17/')\n",
    "\n",
    "# Architecture Params\n",
    "setattr(config, 'enc_layers', [3000,2000])\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 10)\n",
    "setattr(config, 'y_dim', 10)\n",
    "\n",
    "# Training Params\n",
    "setattr(config, 'batch_size', 512)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs', 100)\n",
    "setattr(config, 'monitor', 'val_loss')\n",
    "setattr(config, 'min_delta', 0.5)\n",
    "setattr(config, 'optimizer', 'adam')\n",
    "\n",
    "# Loss Weights\n",
    "setattr(config, 'xcov', 0)\n",
    "setattr(config, 'recon', 10)\n",
    "setattr(config, 'xent', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'dev_mode': True,\n",
       " 'enc_layers': [3000, 2000],\n",
       " 'epochs': 100,\n",
       " 'log_dir': '/home/elijahc/projects/vae/logs',\n",
       " 'log_level': 'INFO',\n",
       " 'min_delta': 0.5,\n",
       " 'monitor': 'val_loss',\n",
       " 'optimizer': 'adam',\n",
       " 'proj_root': '/home/elijahc/projects/vae',\n",
       " 'recon': 10,\n",
       " 'xcov': 0,\n",
       " 'xent': 10,\n",
       " 'y_dim': 10,\n",
       " 'z_dim': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not config.dev_mode:\n",
    "    print('setting up...')\n",
    "    prepare_dirs_and_logger(config)\n",
    "    \n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr,y_tr),(x_te,y_te) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, num_enc_tokens))\n",
    "\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# enc_out,state_h,state_c = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ConvLSTM2D(8,(2,2),strides=(2,2),return_state=True,return_sequences=True)\n",
    "\n",
    "# encoder_outputs, state_h, state_c = encoder(enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiracDeltaFunc(object):\n",
    "    def __init__(self,t_open=0):\n",
    "        self.t = 0.\n",
    "        self.t_open = float(t_open)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        if self.t == self.t_open:\n",
    "            out = x * 1\n",
    "        else:\n",
    "            out = x * 0\n",
    "            \n",
    "        self.t += 1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V1Cell(ConvLSTM2DCell):\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 num_states,\n",
    "                 **kwargs):\n",
    "        self.num_states = num_states\n",
    "        self.input_gate = DiracDeltaFunc()\n",
    "        super(V1Cell, self).__init__(filters,kernel_size,**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters*self.num_states)\n",
    "        self.kernel_shape = kernel_shape\n",
    "        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters*self.num_states)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=recurrent_kernel_shape,\n",
    "            initializer=self.recurrent_initializer,\n",
    "            name='recurrent_kernel',\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "        if self.use_bias:\n",
    "            if self.unit_forget_bias:\n",
    "                def bias_initializer(_, *args, **kwargs):\n",
    "                    return K.concatenate([\n",
    "                        self.bias_initializer((self.filters,), *args, **kwargs),\n",
    "                        initializers.Ones()((self.filters,), *args, **kwargs),\n",
    "                        self.bias_initializer((self.filters * 2,), *args, **kwargs),\n",
    "                    ])\n",
    "            else:\n",
    "                bias_initializer = self.bias_initializer\n",
    "            self.bias = self.add_weight(shape=(self.filters * 2,),\n",
    "                                        name='bias',\n",
    "                                        initializer=bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        for i in np.arange(self.num_states):\n",
    "            setattr(self,'kernel_{}'.format(i),self.kernel[:,:,:,i*self.filters:self.filters*(i+1)])\n",
    "            setattr(self,'recurrent_kernel_{}'.format(i),self.recurrent_kernel[:,:,:,i*self.filters:self.filters*(i+1)])\n",
    "\n",
    "#         self.kernel_i = self.kernel[:, :, :, :self.filters]\n",
    "        \n",
    "#         self.recurrent_kernel_0 = self.recurrent_kernel[:, :, :, :self.filters]\n",
    "#         self.recurrent_kernel_1 = self.recurrent_kernel[:,:,:,self.filters:self.filters*2]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_i = self.bias[:self.filters]\n",
    "#             self.bias_f = self.bias[self.filters: self.filters * 2]\n",
    "#             self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n",
    "#             self.bias_o = self.bias[self.filters * 3:]\n",
    "        else:\n",
    "            self.bias_i = None\n",
    "#             self.bias_f = None\n",
    "#             self.bias_c = None\n",
    "#             self.bias_o = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self,inputs,states):\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "        \n",
    "        if 0 < self.dropout < 1.:\n",
    "            inputs_i = inputs * dp_mask[0]\n",
    "            inputs_f = inputs * dp_mask[1]\n",
    "            inputs_c = inputs * dp_mask[2]\n",
    "            inputs_o = inputs * dp_mask[3]\n",
    "        else:\n",
    "            inputs_i = inputs\n",
    "            inputs_f = inputs\n",
    "            inputs_c = inputs\n",
    "            inputs_o = inputs\n",
    "    \n",
    "        h_tm1 = states[0]  # previous memory state\n",
    "        \n",
    "        if 0 < self.recurrent_dropout < 1.:\n",
    "            h_tm1_i = h_tm1 * rec_dp_mask[0]\n",
    "            h_tm1_f = h_tm1 * rec_dp_mask[1]\n",
    "            h_tm1_c = h_tm1 * rec_dp_mask[2]\n",
    "            h_tm1_o = h_tm1 * rec_dp_mask[3]\n",
    "        else:\n",
    "            h_tm1_i = h_tm1\n",
    "            h_tm1_f = h_tm1\n",
    "            h_tm1_c = h_tm1\n",
    "            h_tm1_o = h_tm1\n",
    "        \n",
    "        \n",
    "        \n",
    "#         I = UpSampling2D(data_format=self.data_format)(h_tm1)\n",
    "#         print('I: ',K.int_shape(I))\n",
    "        print('inputs: ',inputs_i)\n",
    "        print('h_tm1: ',K.int_shape(h_tm1))\n",
    "        self.K = self.BRC(h_tm1, self.kernel_0)\n",
    "        print('K: ',K.int_shape(self.K))\n",
    "#         self.K_2 = self.BRC(K_1,self.recurrent_kernel_1)\n",
    "#         print('K_2: ',K.int_shape(K_2))\n",
    "        \n",
    "        self.h1 = inputs_i + (self.K+h_tm1)\n",
    "\n",
    "\n",
    "#         K_recurrent = UpSampling2D(size=(3,3),data_format='channels_last')(K_1)+I\n",
    "                \n",
    "        return self.h1, [self.h1]\n",
    "        \n",
    "    def input_conv(self, x, w, b=None, strides=None,padding='valid'):\n",
    "        conv_out = K.conv2d(x, w, strides=strides,\n",
    "                            padding=padding,\n",
    "                            data_format=self.data_format,\n",
    "                            dilation_rate=self.dilation_rate)\n",
    "        if b is not None:\n",
    "            conv_out = K.bias_add(conv_out, b,\n",
    "                                  data_format=self.data_format)\n",
    "        return conv_out\n",
    "    \n",
    "    def BRC(self,x,w):\n",
    "        net = BatchNormalization()(x)\n",
    "        net = Activation('relu')(net)\n",
    "        print('BN: ',K.int_shape(net))\n",
    "        net = self.recurrent_conv(net,w)\n",
    "        \n",
    "              \n",
    "        out = UpSampling2D(data_format=self.data_format)\n",
    "        print('out: ',K.int_shape(out))\n",
    "              \n",
    "        return out\n",
    "VC = V1Cell(filters=8,num_states=2,kernel_size=(2,2),strides=(2,2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "px:  (1, 5, 32, 32, 8)\n",
      "inputs:  Tensor(\"conv_rn_n2d_55/strided_slice_6:0\", shape=(1, 32, 32, 8), dtype=float32)\n",
      "h_tm1:  (1, 16, 16, 8)\n",
      "BN:  (1, 16, 16, 8)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'UpSampling2D' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-47ce06fe10b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"px: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mout_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvRNN2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    375\u001b[0m                                              \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_backwards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2922\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2923\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2924\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m<ipython-input-151-fb8d1f1395f5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h_tm1: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBRC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#         self.K_2 = self.BRC(K_1,self.recurrent_kernel_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-fb8d1f1395f5>\u001b[0m in \u001b[0;36mBRC\u001b[0;34m(self, x, w)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mint_shape\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UpSampling2D' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "C_RNN = ConvRNN2D(VC,return_sequences=True,return_state=True,stateful=True)\n",
    "t_unroll = 5\n",
    "# Channels_last format [batch,time,rows,cols,channels]\n",
    "input_shape = tuple([1,t_unroll]+list(x_tr.shape[1:]))\n",
    "enc_inputs = Input(batch_shape=input_shape)\n",
    "px = TimeDistributed(Conv2D(filters=8,kernel_size=(3,3),padding='same'))(enc_inputs)\n",
    "print(\"px: \",K.int_shape(px))\n",
    "out_c = C_RNN(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNResBlockCell(Layer):\n",
    "    def __init__(self,filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 strides=(1, 1),\n",
    "                 dilation_rate=(1, 1),\n",
    "                 kernel_activation='relu',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_constraint=None,\n",
    "                 recurrent_activation='relu',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 recurrent_constraint=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.dilation_rate = dilation_rate\n",
    "#         self.state_size = filters\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_activation=kernel_activation\n",
    "        self.kernel_initializer=kernel_initializer\n",
    "        self.kernel_constraint=kernel_constraint\n",
    "        self.recurrent_activation=recurrent_activation\n",
    "        self.recurrent_initializer=recurrent_initializer\n",
    "        self.recurrent_constraint=recurrent_constraint\n",
    "        \n",
    "        self.input_gate_func = DiracDeltaFunc()\n",
    "        self.state_size = (self.filters,self.filters)\n",
    "    \n",
    "        super(RNNResBlockCell, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "#         super(RNNResBlockCell, self).__init__(**kwargs)\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        \n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        \n",
    "        self.kernel_shape = kernel_shape\n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        \n",
    "        recurrent_kernel_shape = self.kernel_size + (self.filters,self.filters)\n",
    "        \n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=recurrent_kernel_shape,\n",
    "            initializer=self.recurrent_initializer,\n",
    "            name='recurrent_kernel',\n",
    "#             regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "        \n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        inputs = self.input_gate_func(inputs)\n",
    "        prev_output = states[0]\n",
    "        K = self.recurrent_conv(x=prev_output,w=self.recurrent_kernel)\n",
    "        I = self.input_identity(prev_output)\n",
    "        output = inputs + K + I\n",
    "        return output, [output]\n",
    "    \n",
    "    def input_conv(self, x, w, b=None, padding='valid'):\n",
    "        conv_out = K.conv2d(x, w, strides=self.strides,\n",
    "                            padding=padding,\n",
    "                            data_format=self.data_format,\n",
    "                            dilation_rate=self.dilation_rate)\n",
    "        if b is not None:\n",
    "            conv_out = K.bias_add(conv_out, b,\n",
    "                                  data_format=self.data_format)\n",
    "        return conv_out\n",
    "    \n",
    "    def input_identity(self,x):\n",
    "        I_out = K.identity(x,name='Identity')\n",
    "        return I_out\n",
    "    \n",
    "    def h1_recurrent(x,w):\n",
    "        return self.BRC(x,w)\n",
    "        \n",
    "    def BRC(self,x,w):\n",
    "        net = BatchNormalization()(x)\n",
    "        net = Activation('relu')(net)\n",
    "        net = K.conv2d(net,w,strides=(2,2),\n",
    "                       padding='same',\n",
    "                       data_format=self.data_format)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        out = K.conv2d(net,w,strides=(2,2),\n",
    "                       padding='same',\n",
    "                       data_format=self.data_format)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def recurrent_conv(self, x, w):\n",
    "        conv_out = K.conv2d(x, w, strides=(1, 1),\n",
    "                            padding='same',\n",
    "                            data_format=self.data_format)\n",
    "        return conv_out\n",
    "\n",
    "RRCell = RNNResBlockCell(filters=16,kernel_size=(3,3),data_format='channels_last',padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_RNN = ConvRNN2D(ConvLSTM2DCell(filters=64,kernel_size=(2,2),strides=(2,2)),return_sequences=True,return_state=True,stateful=True)\n",
    "t_unroll = 5\n",
    "# Channels_last format [batch,time,rows,cols,channels]\n",
    "input_shape = tuple([1,t_unroll]+list(x_tr.shape[1:]))\n",
    "enc_inputs = Input(batch_shape=input_shape)\n",
    "px = TimeDistributed(Conv2D(filters=16,kernel_size=(3,3),padding='same'))(enc_inputs)\n",
    "\n",
    "out_c = C_RNN(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'conv_rn_n2d_11/transpose_1:0' shape=(1, ?, 16, 16, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv_rn_n2d_11/while/Exit_3:0' shape=(1, 16, 16, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv_rn_n2d_11/while/Exit_4:0' shape=(1, 16, 16, 16) dtype=float32>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(inputs=enc_inputs,outputs=out_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'conv_rn_n2d_9/transpose_1:0' shape=(1, ?, 32, 32, 16) dtype=float32>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_net(x,filts=1,tsteps=5):\n",
    "#     net = RepeatVector(tsteps)(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def fwd_res(x,features=16):\n",
    "    net = BatchNormalization()(x)\n",
    "    net = Activation('relu')(net)\n",
    "    c_layer = ConvLSTM2D(filters=features,kernel_size=(3,3),padding=\"same\",\n",
    "                     activation=None,stateful=True)\n",
    "    out = c_layer(initial_state=)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(input_shape)\n",
    "\n",
    "latent_dim = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pnet = Conv2D(16,kernel_size=(3,3),padding=\"same\")(enc_inputs)\n",
    "\n",
    "# enc_inputs\n",
    "# px = pre_net(enc_inputs,filts=16)\n",
    "# net = BatchNormalization()(pnet)\n",
    "# net = Activation('relu')(net)\n",
    "c_layer = ConvLSTM2D(16,kernel_size=(3,3),padding=\"same\",\n",
    "                     activation=None,stateful=True,return_state=True,return_sequences=True)\n",
    "out_c, state_h, state_c = c_layer(enc_inputs)\n",
    "out\n",
    "mod = Model(inputs=enc_inputs,outputs=out_c)\n",
    "# net = fwd_res(enc_inputs,features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = pre_net(enc_inputs,filts=16)\n",
    "max_tsteps = 5\n",
    "from keras.layers import Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Masking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fwd_res(enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_amt = 0.5 # Med\n",
    "DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model inputs\"\"\"\n",
    "\n",
    "class_input = Input(shape=(10,),name='class_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AutoEncoder Critic\"\"\"\n",
    "x = Input(shape=DL.input_shape,name='Image_input')\n",
    "\n",
    "encoder = Encoder(input_shape=DL.input_shape,\n",
    "                  y_dim=config.y_dim,\n",
    "                  z_dim=config.z_dim,\n",
    "                  layer_units=config.enc_layers)\n",
    "\n",
    "net_out = encoder.build(x)\n",
    "y = Activation('softmax',name='y')(net_out[0])\n",
    "z = Activation('linear',name='z')(net_out[1])\n",
    "\n",
    "# c = Activation('linear',name='critic_score')(net_out[2])\n",
    "\n",
    "yz = Concatenate(name='yz')([y,z])\n",
    "\n",
    "E = Model(inputs = x,\n",
    "          outputs = [y,z],\n",
    "          name='Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decoder \"\"\"\n",
    "decoder = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "Dec_input = Input(shape=(config.y_dim+config.z_dim,),name='Decoder_input')\n",
    "Dec_output = decoder.build(Dec_input)\n",
    "\n",
    "G = Model(inputs=Dec_input,\n",
    "          outputs=Dec_output,\n",
    "          name='Decoder')\n",
    "# G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = Activation('linear',name='x_pred')(G(yz))\n",
    "\n",
    "\n",
    "sse_layer = lambda x: K.expand_dims(sse(x,AE(x)))\n",
    "AE = Model(inputs=x,outputs=x_pred,name='AE')\n",
    "sse_out = Lambda(sse_layer)(AE(x))\n",
    "D = Model(\n",
    "    inputs=x,\n",
    "    outputs=sse_out,\n",
    "    name='D'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generator \"\"\"\n",
    "def gen_Z(y):\n",
    "    Z = K.random_normal(shape=(K.shape(y)[0],config.z_dim))\n",
    "    \n",
    "    return Z\n",
    "\n",
    "generator = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "G_input_y = Input(shape=(config.y_dim,),name='G_y')\n",
    "G_input_z = Lambda(gen_Z,name='G_z')(G_input_y)\n",
    "\n",
    "G_input = Concatenate(name='zy')([G_input_z,G_input_y])\n",
    "\n",
    "G_img = generator.build(G_input)\n",
    "\n",
    "Gen = Model(\n",
    "    inputs=G_input_y,\n",
    "    outputs=G_img,\n",
    "    name='Generator'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Outputs \"\"\"\n",
    "fake_img = Activation('linear',name='fake_img')(Gen(class_input))\n",
    "\n",
    "c_real = Activation('linear',name='C_real')(D(x))\n",
    "c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "# c_real = Activation('linear',name='C_real')(D(x))\n",
    "# c_recon = D(recon_img)\n",
    "# c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "\"\"\" Losses \"\"\"\n",
    "# GAN Losses\n",
    "GAN_d_loss = -1*(c_real - c_fake)\n",
    "GAN_g_loss = -1*c_fake\n",
    "\n",
    "# Gradient Penalty\n",
    "gp_loss = gradient_penalty_loss(x,fake_img,D)\n",
    "\n",
    "# Add Discriminator losses\n",
    "D.add_loss([GAN_d_loss])\n",
    "\n",
    "# Add Generator losses\n",
    "# Gen.add_loss([GAN_g_loss])\n",
    "\n",
    "EBGAN = Model(\n",
    "    inputs=[x,class_input],\n",
    "    outputs=[y,c_real,c_fake],\n",
    "    name='EBGAN'\n",
    ")\n",
    "# mod_outputs = [\n",
    "#     (recon_img, sse, config.recon),\n",
    "#     (y, 'categorical_crossentropy', config.xent),\n",
    "#     (c_fake,lambda yt,yp: GAN_d_loss+GAN_g_loss, 1),\n",
    "# ]\n",
    "\n",
    "# outs,ls,ws = zip(*mod_outputs)\n",
    "\n",
    "# VGAN = Model(\n",
    "# inputs=x,\n",
    "# outputs=outs)\n",
    "\n",
    "# losses = {k:v for k,v in zip(VGAN.output_names,ls)}\n",
    "# loss_W = {k:v for k,v in zip(VGAN.output_names,ws)}\n",
    "\n",
    "metrics = {\n",
    "    'y': 'accuracy',\n",
    "}\n",
    "\n",
    "EBGAN.compile(optimizer=config.optimizer,loss={'y':'categorical_crossentropy','C_real':lambda yt,yp:GAN_d_loss,'C_fake':lambda yt,yp:GAN_g_loss},metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBGAN.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "RF = to_categorical(np.ones(len(DL.sx_train)),num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_history = PrintHistory(print_keys=['loss','val_loss','val_y_acc'])\n",
    "# update_k = Update_k(k_var = k)\n",
    "callbacks=[\n",
    "    print_history,\n",
    "#     update_k\n",
    "]\n",
    "if config.monitor is not None:\n",
    "    early_stop = EarlyStopping(monitor=config.monitor,min_delta=config.min_delta,patience=10,restore_best_weights=True)\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "history = EBGAN.fit(x={'Image_input':DL.sx_train,'class_input':DL.y_train_oh},\n",
    "              y={\n",
    "                  'y':DL.y_train_oh,\n",
    "                  'C_real':RF,\n",
    "                  'C_fake':RF,\n",
    "                  },\n",
    "              verbose=0,\n",
    "              batch_size=config.batch_size,\n",
    "              callbacks=callbacks,\n",
    "              validation_split=0.05,\n",
    "              epochs=config.epochs,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # true_latent_vec = Concatenate()([y_class,z_lat_stats[0]])\n",
    "# latent_vec = Concatenate()([y,z_lat])\n",
    "# shuffled_lat = Concatenate()([y,z_sampled])\n",
    "# G = trainer.G\n",
    "# # recon = Activation('linear',name='G')(G(true_latent_vec))\n",
    "# fake_inp = G(latent_vec)\n",
    "# G_shuff = G(shuffled_lat)\n",
    "# # fake_lat_vec = Concatenate()(E(fake_inp))\n",
    "# # fake_ae = G(fake_lat_vec)\n",
    "\n",
    "# D_real = Activation('linear',name='D_real')(D(real_inp))\n",
    "# D_fake = Activation('linear',name='D_fake')(D(G_shuff))\n",
    "# # D_fake = E(fake_inp)[2]\n",
    "# D_all = Concatenate(axis=0,name='D_all')([D_fake,D_real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,idx = plot_ovt(DL,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_df = pd.DataFrame.from_records(trainer.model.history.history)\n",
    "hist_df = pd.DataFrame.from_records(VGAN.history.history)\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "metrics = ['loss','C_f_loss','y_acc']\n",
    "fig,axs = plt.subplots(nrows=len(metrics),sharex=True,figsize=(5,10))\n",
    "for metric_name,ax in zip(metrics,axs):\n",
    "    sns.scatterplot(data=hist_df[[metric_name,'val_'+metric_name]],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not config.dev_mode:\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_encoder = Model(x,z)\n",
    "classifier = Model(x,y)\n",
    "# y_lat_encoder = Model(trainer.E.input,trainer.y_lat)\n",
    "# decoder_inp = Input(shape=(config.y_dim+config.z_dim,))\n",
    "# dec_layers = trainer.model.layers[-(1+(5*2)):]\n",
    "# print(dec_layers)\n",
    "# _gen_x = dec_layers[0](decoder_inp)\n",
    "# l = dec_layers[1]\n",
    "# isinstance(l,keras.layers.core.Reshape)\n",
    "# F = None\n",
    "# for l in dec_layers[1:]:\n",
    "#     print(type(l))\n",
    "    \n",
    "#     if isinstance(l,keras.layers.merge.Add):\n",
    "#         _gen_x = l([F,_gen_x])\n",
    "#     else:\n",
    "#         _gen_x = l(_gen_x)\n",
    "    \n",
    "#     if isinstance(l,keras.layers.convolutional.Conv2DTranspose):\n",
    "#         if l.kernel_size==(1,1):\n",
    "#             F = _gen_x\n",
    "            \n",
    "# # generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL.y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "classifier.evaluate(DL.sx_test,DL.y_test_oh,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc = z_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "# y_lat = y_lat_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_lat = classifier.predict(DL.sx_test,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec = np.concatenate([y_lat,z_enc],axis=1)\n",
    "_lat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc_mu = np.mean(z_enc,axis=0)\n",
    "z_enc_cov = np.cov(z_enc,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(z_enc_mu,z_enc_cov,size=50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen = generator.predict(_lat_vec,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = np.random.randint(0,10000)\n",
    "plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec[rand_im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL2 = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_samples(DL.x_test,DL.sx_test,z_enc,y_lat,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc2 = z_encoder.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "y_lat2 = classifier.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "_lat_vec2 = np.concatenate([y_lat2,z_enc2],axis=1)\n",
    "regen2 = generator.predict(_lat_vec2,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import remove_axes,remove_labels\n",
    "from src.utils import gen_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 5\n",
    "rand_im = np.random.randint(0,10000,size=examples)\n",
    "fix,axs = plt.subplots(examples,11,figsize=(8,4))\n",
    "_lat_s = []\n",
    "regen_s = []\n",
    "out = gen_trajectory(z_enc[rand_im],z_enc2[rand_im],delta=.25)\n",
    "out_y = gen_trajectory(y_lat[rand_im],y_lat2[rand_im],delta=.25)\n",
    "\n",
    "for z,y in zip(out,out_y):\n",
    "    _lat = np.concatenate([y,z],axis=1)\n",
    "    _lat_s.append(_lat)\n",
    "    regen_s.append(generator.predict(_lat,batch_size=config.batch_size))\n",
    "\n",
    "i=0\n",
    "for axr,idx in zip(axs,rand_im):\n",
    "    axr[0].imshow(DL.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    axr[1].imshow(DL.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[2].imshow(regen[idx].reshape(56,56),cmap='gray')\n",
    "    for j,a in enumerate(axr[3:-3]):\n",
    "        a.imshow(regen_s[j][i,:].reshape(56,56),cmap='gray')\n",
    "#         a.imshow(s.reshape(56,56),cmap='gray')\n",
    "    axr[-3].imshow(regen2[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-2].imshow(DL2.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-1].imshow(DL2.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    for a in axr:\n",
    "        remove_axes(a)\n",
    "        remove_labels(a)\n",
    "    i+=1\n",
    "# plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feat_range = (0,50)\n",
    "z_enc_scaled = [MinMaxScaler(feat_range).fit_transform(z_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(config.z_dim)]\n",
    "z_enc_scaled = np.squeeze(np.array(z_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import dit\n",
    "from dit import Distribution\n",
    "dxs = DL.dx[1]-14\n",
    "dys = DL.dy[1]-14\n",
    "\n",
    "def mutual_information(X,Y):\n",
    "    XY_c = Counter(zip(X,Y))\n",
    "    XY_pmf = {k:v/float(sum(XY_c.values())) for k,v in XY_c.items()}\n",
    "    XY_jdist = Distribution(XY_pmf)\n",
    "        \n",
    "    return dit.shannon.mutual_information(XY_jdist,[0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dx_I = [mutual_information(z_enc_scaled[i],dxs.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dy_I = [mutual_information(z_enc_scaled[i],dys.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_class_I = [mutual_information(z_enc_scaled[i],DL.y_test) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_I_df = pd.DataFrame.from_records({'class':z_class_I,'dy':z_dy_I,'dx':z_dx_I})\n",
    "z_I_df['class'] = z_I_df['class'].values.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,5))\n",
    "ax.set_ylim(0,0.8)\n",
    "ax.set_xlim(0,0.8)\n",
    "points = plt.scatter(x=z_I_df['dx'],y=z_I_df['dy'],c=z_I_df['class'],cmap='plasma')\n",
    "plt.colorbar(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(z_dx_I,z_dy_I)\n",
    "ax.set_ylim(0,0.6)\n",
    "ax.set_xlim(0,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),sorted(z_dy_I,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import var_expl,norm_var_expl\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "dtheta = DL.dtheta[1]\n",
    "fve_dx = norm_var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "fve_dy = norm_var_expl(features=z_enc,cond=dys,bins=21)\n",
    "# fve_dt = norm_var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fve_dx_norm = (dxs.var()-fve_dx)/dxs.var()\n",
    "# fve_dy_norm = (dys.var()-fve_dy)/dys.var()\n",
    "# fve_dth_norm = (dtheta.var()-fve_dt)/dtheta.var()\n",
    "fve_dx_norm = fve_dx\n",
    "fve_dy_norm = fve_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm.shape\n",
    "# np.save(os.path.join(config.model_dir,'fve_dx_norm'),fve_dx_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(fve_dx_norm.mean(axis=0),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('fve_dx')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dx.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "xdim = np.argmax(fve_dx_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dy_norm.mean(axis=0)\n",
    "# np.save(os.path.join(config.model_dir,'fve_dy_norm'),fve_dy_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dy.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "ydim = np.argmax(fve_dy_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(config.z_dim),fve_dth_norm.mean(axis=0))\n",
    "# plt.xlabel('Z_n')\n",
    "# plt.ylabel('fve_dtheta')\n",
    "# # plt.ylim(0.0,0.5)\n",
    "# np.argmax(fve_dth_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import Z_color_scatter\n",
    "Z_color_scatter(z_enc,[xdim,ydim],dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[7,18],dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
