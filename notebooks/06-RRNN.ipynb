{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from src.losses import sse, mse\n",
    "from src.test_models.EBGAN import EBGAN,Generator,Encoder,resample,gradient_penalty_loss\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import add\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from src.keras_callbacks import PrintHistory,Update_k\n",
    "from src.resnet import _bn_relu_conv, _shortcut, basic_block, _handle_dim_ordering,ResnetBuilder,_conv_bn_relu,_residual_block\n",
    "from recurrentshop import *\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config,_ = get_config()\n",
    "\n",
    "# Boilerplate\n",
    "setattr(config, 'proj_root', '/home/elijahc/projects/vae')\n",
    "setattr(config, 'log_dir', '/home/elijahc/projects/vae/logs')\n",
    "setattr(config, 'dev_mode',True)\n",
    "# setattr(config,'model_dir','/home/elijahc/projects/vae/models/2019-01-17/')\n",
    "\n",
    "# Architecture Params\n",
    "setattr(config, 'enc_layers', [3000,2000])\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 10)\n",
    "setattr(config, 'y_dim', 10)\n",
    "\n",
    "# Training Params\n",
    "setattr(config, 'batch_size', 512)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs', 100)\n",
    "setattr(config, 'monitor', 'val_loss')\n",
    "setattr(config, 'min_delta', 0.5)\n",
    "setattr(config, 'optimizer', 'adam')\n",
    "\n",
    "# Loss Weights\n",
    "setattr(config, 'xcov', 0)\n",
    "setattr(config, 'recon', 10)\n",
    "setattr(config, 'xent', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'dev_mode': True,\n",
       " 'enc_layers': [3000, 2000],\n",
       " 'epochs': 100,\n",
       " 'log_dir': '/home/elijahc/projects/vae/logs',\n",
       " 'log_level': 'INFO',\n",
       " 'min_delta': 0.5,\n",
       " 'monitor': 'val_loss',\n",
       " 'optimizer': 'adam',\n",
       " 'proj_root': '/home/elijahc/projects/vae',\n",
       " 'recon': 10,\n",
       " 'xcov': 0,\n",
       " 'xent': 10,\n",
       " 'y_dim': 10,\n",
       " 'z_dim': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not config.dev_mode:\n",
    "    print('setting up...')\n",
    "    prepare_dirs_and_logger(config)\n",
    "    \n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr,y_tr),(x_te,y_te) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, num_enc_tokens))\n",
    "\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# enc_out,state_h,state_c = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ConvLSTM2D(8,(2,2),strides=(2,2),return_state=True,return_sequences=True)\n",
    "\n",
    "# encoder_outputs, state_h, state_c = encoder(enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiracDeltaFunc(object):\n",
    "    def __init__(self,t_open=0):\n",
    "        self.t = 0.\n",
    "        self.t_open = float(t_open)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        if self.t == self.t_open:\n",
    "            out = x * 1\n",
    "        else:\n",
    "            out = x * 0\n",
    "            \n",
    "        self.t += 1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (32, 32, 16) (16, 16, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5db82e21bf7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_residual_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# tanh activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \"\"\"\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             output_shape = self._compute_elemwise_op_output_shape(output_shape,\n\u001b[0;32m---> 91\u001b[0;31m                                                                   shape)\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     raise ValueError('Operands could not be broadcast '\n\u001b[1;32m     60\u001b[0m                                      \u001b[0;34m'together with shapes '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                      str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (32, 32, 16) (16, 16, 32)"
     ]
    }
   ],
   "source": [
    "from recurrentshop import *\n",
    "x_t = Input(shape=(32,32,16)) # The input to the RNN at time t\n",
    "h_tm1 = Input(shape=(32,32,16))  # Previous hidden state\n",
    "\n",
    "# Compute new hidden state\n",
    "_handle_dim_ordering()\n",
    "k = _residual_block(basic_block,filters=32,repetitions=2)(h_tm1)\n",
    "\n",
    "h_t = add([x_t, k])\n",
    "\n",
    "# tanh activation\n",
    "# h_t = Activation('tanh')(h_t)\n",
    "\n",
    "# Build the RNN\n",
    "# RecurrentModel is a standard Keras `Recurrent` layer. \n",
    "# RecurrentModel also accepts arguments such as unroll, return_sequences etc\n",
    "rnn = RecurrentModel(input=x_t, initial_states=[h_tm1], output=h_t, final_states=[h_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4/add:0' shape=(?, 16, 16, 32) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRNCell2(Layer):\n",
    "    def __init__(self,filters,\n",
    "                 kernel_size,\n",
    "                 block_fn,\n",
    "                 num_states=1,\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.filters=filters\n",
    "        self.kernel_size=kernel_size\n",
    "        self.block_fn = block_fn\n",
    "        self.num_states=num_states\n",
    "        self.data_format = data_format\n",
    "        self.state_size = (self.filters)\n",
    "        super(RRNCell2, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.state_size = (1,)\n",
    "    \n",
    "    def call(self,inputs,states):\n",
    "        prev_output = states[0]\n",
    "        I = prev_output\n",
    "        k = self.block_fn(prev_output)\n",
    "        k_i = add([k,I])\n",
    "        \n",
    "        h = add([inputs,k_i])\n",
    "        \n",
    "        return h,[h]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResRNN(ConvRNN2D):\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        super(ConvRNN2D, self).__init__(cell,\n",
    "                                        return_sequences,\n",
    "                                        return_state,\n",
    "                                        go_backwards,\n",
    "                                        stateful,\n",
    "                                        unroll,\n",
    "                                        **kwargs)\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        cell = self.cell\n",
    "        if cell.data_format == 'channels_first':\n",
    "            rows = input_shape[3]\n",
    "            cols = input_shape[4]\n",
    "        elif cell.data_format == 'channels_last':\n",
    "            rows = input_shape[2]\n",
    "            cols = input_shape[3]\n",
    "        \n",
    "        output_shape = input_shape[:2] + (rows, cols, cell.filters)\n",
    "        output_shape = transpose_shape(output_shape, cell.data_format,\n",
    "                                       spatial_axes=(2, 3))\n",
    "        \n",
    "        if not self.return_sequences:\n",
    "            output_shape = output_shape[:1] + output_shape[2:]\n",
    "\n",
    "        if self.return_state:\n",
    "            output_shape = [output_shape]\n",
    "            base = (input_shape[0], rows, cols, cell.filters)\n",
    "            base = transpose_shape(base, cell.data_format, spatial_axes=(1, 2))\n",
    "            output_shape += [base[:] for _ in range(1)]\n",
    "        \n",
    "        return output_shape\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        \n",
    "        cell = self.cell\n",
    "        self.input_spec = [input_shape[2:5] for _ in range(input_shape[1])]\n",
    "        self.state_spec = [input_shape[2:5] for _ in range(input_shape[1])]\n",
    "        \n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = []\n",
    "            for state in initial_state:\n",
    "                try:\n",
    "                    shape = K.int_shape(state)\n",
    "                # Fix for Theano\n",
    "                except TypeError:\n",
    "                    shape = tuple(None for _ in range(K.ndim(state)))\n",
    "                self.state_spec.append(InputSpec(shape=shape))\n",
    "\n",
    "            additional_specs += self.state_spec\n",
    "            \n",
    "        for tensor in additional_inputs:\n",
    "            if K.is_keras_tensor(tensor) != K.is_keras_tensor(additional_inputs[0]):\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if K.is_keras_tensor(additional_inputs[0]):\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ConvRNN2D, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ConvRNN2D, self).__call__(inputs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR = ResRNN(RRNCell2(16,kernel_size=(3,3),block_fn=basic_block),return_sequences=False,return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR.compute_output_shape((1,5,32,32,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tuple([1,5]+list(x_tr.shape[1:]))\n",
    "enc_inputs = Input(batch_shape=input_shape)\n",
    "pre_x = TimeDistributed(Conv2D(16,kernel_size=(3,3),strides=(1,1),padding='same'))(enc_inputs)\n",
    "RR(pre_x,initial_state=pre_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V1Cell(ConvLSTM2DCell):\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 num_states,\n",
    "                 **kwargs):\n",
    "        self.num_states = num_states\n",
    "        self.input_gate = DiracDeltaFunc()\n",
    "        super(V1Cell, self).__init__(filters,kernel_size,**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters*self.num_states)\n",
    "        self.kernel_shape = kernel_shape\n",
    "        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters*self.num_states)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=recurrent_kernel_shape,\n",
    "            initializer=self.recurrent_initializer,\n",
    "            name='recurrent_kernel',\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "        if self.use_bias:\n",
    "            if self.unit_forget_bias:\n",
    "                def bias_initializer(_, *args, **kwargs):\n",
    "                    return K.concatenate([\n",
    "                        self.bias_initializer((self.filters,), *args, **kwargs),\n",
    "                        initializers.Ones()((self.filters,), *args, **kwargs),\n",
    "                        self.bias_initializer((self.filters * 2,), *args, **kwargs),\n",
    "                    ])\n",
    "            else:\n",
    "                bias_initializer = self.bias_initializer\n",
    "            self.bias = self.add_weight(shape=(self.filters * 2,),\n",
    "                                        name='bias',\n",
    "                                        initializer=bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        for i in np.arange(self.num_states):\n",
    "            setattr(self,'kernel_{}'.format(i),self.kernel[:,:,:,i*self.filters:self.filters*(i+1)])\n",
    "            setattr(self,'recurrent_kernel_{}'.format(i),self.recurrent_kernel[:,:,:,i*self.filters:self.filters*(i+1)])\n",
    "\n",
    "#         self.kernel_i = self.kernel[:, :, :, :self.filters]\n",
    "        \n",
    "#         self.recurrent_kernel_0 = self.recurrent_kernel[:, :, :, :self.filters]\n",
    "#         self.recurrent_kernel_1 = self.recurrent_kernel[:,:,:,self.filters:self.filters*2]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_i = self.bias[:self.filters]\n",
    "#             self.bias_f = self.bias[self.filters: self.filters * 2]\n",
    "#             self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n",
    "#             self.bias_o = self.bias[self.filters * 3:]\n",
    "        else:\n",
    "            self.bias_i = None\n",
    "#             self.bias_f = None\n",
    "#             self.bias_c = None\n",
    "#             self.bias_o = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self,inputs,states):\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "        \n",
    "        if 0 < self.dropout < 1.:\n",
    "            inputs_i = inputs * dp_mask[0]\n",
    "            inputs_f = inputs * dp_mask[1]\n",
    "            inputs_c = inputs * dp_mask[2]\n",
    "            inputs_o = inputs * dp_mask[3]\n",
    "        else:\n",
    "            inputs_i = inputs\n",
    "            inputs_f = inputs\n",
    "            inputs_c = inputs\n",
    "            inputs_o = inputs\n",
    "    \n",
    "        h_tm1 = states[0]  # previous memory state\n",
    "        \n",
    "        if 0 < self.recurrent_dropout < 1.:\n",
    "            h_tm1_i = h_tm1 * rec_dp_mask[0]\n",
    "            h_tm1_f = h_tm1 * rec_dp_mask[1]\n",
    "            h_tm1_c = h_tm1 * rec_dp_mask[2]\n",
    "            h_tm1_o = h_tm1 * rec_dp_mask[3]\n",
    "        else:\n",
    "            h_tm1_i = h_tm1\n",
    "            h_tm1_f = h_tm1\n",
    "            h_tm1_c = h_tm1\n",
    "            h_tm1_o = h_tm1\n",
    "        \n",
    "#         I = UpSampling2D(data_format=self.data_format)(h_tm1)\n",
    "#         print('I: ',K.int_shape(I))\n",
    "#         print('inputs: ',inputs_i)\n",
    "#         print('h_tm1: ',K.int_shape(h_tm1))\n",
    "        I = UpSampling2D(data_format=self.data_format)(h_tm1_i)\n",
    "#         I = h_tm1_i\n",
    "        print('I : ',K.int_shape(I))\n",
    "        bn = BatchNormalization()\n",
    "        relu = Activation('relu')\n",
    "        _bn_relu(bn,relu,)\n",
    "        net = Activation('relu')(I)\n",
    "#         print('BN: ',K.int_shape(net))\n",
    "        self.K = self.input_conv(net,self.kernel_0,self.bias_i,padding='same')\n",
    "#         self.K = self.BRC(I, self.kernel_0)\n",
    "        print('K: ',K.int_shape(self.K))\n",
    "#         self.K_2 = self.BRC(K_1,self.recurrent_kernel_1)\n",
    "#         print('out: ',K.int_shape(out))\n",
    "        print('inputs_i: ',K.int_shape(inputs_i))\n",
    "        out = Add()([self.K,h_tm1_i])\n",
    "        print('out: ',K.int_shape(out))\n",
    "        \n",
    "        self.h1 = _shortcut()\n",
    "\n",
    "\n",
    "#         K_recurrent = UpSampling2D(size=(3,3),data_format='channels_last')(K_1)+I\n",
    "                \n",
    "        return self.h1, [self.h1]\n",
    "    \n",
    "    def _bn_relu(x,bn,relu,idx):\n",
    "        return Lambda(lambda inp: relu(bn(inp)),name='bn_relu_{}'.format(idx))(x)\n",
    "    \n",
    "    def BRC(self,x,w):\n",
    "        net = BatchNormalization()(x)\n",
    "        net = Activation('relu')(net)\n",
    "        print('BN: ',K.int_shape(net))\n",
    "        out = self.recurrent_conv(net,w)\n",
    "        \n",
    "              \n",
    "#         out = UpSampling2D(data_format=self.data_format)\n",
    "        print('out: ',K.int_shape(out))\n",
    "              \n",
    "        return out\n",
    "VC = V1Cell(filters=8,num_states=1,kernel_size=(2,2),strides=(2,2),padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_RNN = ConvRNN2D(VC,return_sequences=True,return_state=True)\n",
    "t_unroll = 5\n",
    "# Channels_last format [batch,time,rows,cols,channels]\n",
    "input_shape = tuple([1,t_unroll]+list(x_tr.shape[1:]))\n",
    "enc_inputs = Input(batch_shape=input_shape)\n",
    "block_fn=basic_block\n",
    "enc_input = Input(shape=input_shape)\n",
    "conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(enc_input)\n",
    "pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "pool1\n",
    "block = pool1\n",
    "px = TimeDistributed(Conv2D(filters=8,kernel_size=(3,3),padding='same'))(enc_inputs)\n",
    "print(\"px: \",K.int_shape(px))\n",
    "out_c = C_RNN(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNResBlockCell(Layer):\n",
    "    def __init__(self,filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 strides=(1, 1),\n",
    "                 dilation_rate=(1, 1),\n",
    "                 kernel_activation='relu',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_constraint=None,\n",
    "                 recurrent_activation='relu',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 recurrent_constraint=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.dilation_rate = dilation_rate\n",
    "#         self.state_size = filters\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_activation=kernel_activation\n",
    "        self.kernel_initializer=kernel_initializer\n",
    "        self.kernel_constraint=kernel_constraint\n",
    "        self.recurrent_activation=recurrent_activation\n",
    "        self.recurrent_initializer=recurrent_initializer\n",
    "        self.recurrent_constraint=recurrent_constraint\n",
    "        \n",
    "        self.input_gate_func = DiracDeltaFunc()\n",
    "        self.state_size = (self.filters,self.filters)\n",
    "    \n",
    "        super(RNNResBlockCell, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "#         super(RNNResBlockCell, self).__init__(**kwargs)\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        \n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        \n",
    "        self.kernel_shape = kernel_shape\n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        \n",
    "        recurrent_kernel_shape = self.kernel_size + (self.filters,self.filters)\n",
    "        \n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=recurrent_kernel_shape,\n",
    "            initializer=self.recurrent_initializer,\n",
    "            name='recurrent_kernel',\n",
    "#             regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "        \n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        inputs = self.input_gate_func(inputs)\n",
    "        prev_output = states[0]\n",
    "        K = self.recurrent_conv(x=prev_output,w=self.recurrent_kernel)\n",
    "        I = self.input_identity(prev_output)\n",
    "        output = inputs + K + I\n",
    "        return output, [output]\n",
    "    \n",
    "    def input_conv(self, x, w, b=None, padding='valid'):\n",
    "        conv_out = K.conv2d(x, w, strides=self.strides,\n",
    "                            padding=padding,\n",
    "                            data_format=self.data_format,\n",
    "                            dilation_rate=self.dilation_rate)\n",
    "        if b is not None:\n",
    "            conv_out = K.bias_add(conv_out, b,\n",
    "                                  data_format=self.data_format)\n",
    "        return conv_out\n",
    "    \n",
    "    def input_identity(self,x):\n",
    "        I_out = K.identity(x,name='Identity')\n",
    "        return I_out\n",
    "    \n",
    "    def h1_recurrent(x,w):\n",
    "        return self.BRC(x,w)\n",
    "        \n",
    "    def BRC(self,x,w):\n",
    "        net = BatchNormalization()(x)\n",
    "        net = Activation('relu')(net)\n",
    "        net = K.conv2d(net,w,strides=(2,2),\n",
    "                       padding='same',\n",
    "                       data_format=self.data_format)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        out = K.conv2d(net,w,strides=(2,2),\n",
    "                       padding='same',\n",
    "                       data_format=self.data_format)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def recurrent_conv(self, x, w):\n",
    "        conv_out = K.conv2d(x, w, strides=(1, 1),\n",
    "                            padding='same',\n",
    "                            data_format=self.data_format)\n",
    "        return conv_out\n",
    "\n",
    "RRCell = RNNResBlockCell(filters=8,kernel_size=(3,3),data_format='channels_last',padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_RNN = ConvRNN2D(ConvLSTM2DCell(filters=64,kernel_size=(2,2),strides=(2,2)),return_sequences=True,return_state=True,stateful=True)\n",
    "t_unroll = 5\n",
    "# Channels_last format [batch,time,rows,cols,channels]\n",
    "input_shape = tuple([1,t_unroll]+list(x_tr.shape[1:]))\n",
    "enc_inputs = Input(batch_shape=input_shape)\n",
    "px = TimeDistributed(Conv2D(filters=8,kernel_size=(3,3),padding='same'))(enc_inputs)\n",
    "\n",
    "out_c = C_RNN(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(inputs=enc_inputs,outputs=out_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_net(x,filts=1,tsteps=5):\n",
    "#     net = RepeatVector(tsteps)(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def fwd_res(x,features=16):\n",
    "    net = BatchNormalization()(x)\n",
    "    net = Activation('relu')(net)\n",
    "    c_layer = ConvLSTM2D(filters=features,kernel_size=(3,3),padding=\"same\",\n",
    "                     activation=None,stateful=True)\n",
    "    out = c_layer(initial_state=)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(input_shape)\n",
    "\n",
    "latent_dim = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pnet = Conv2D(16,kernel_size=(3,3),padding=\"same\")(enc_inputs)\n",
    "\n",
    "# enc_inputs\n",
    "# px = pre_net(enc_inputs,filts=16)\n",
    "# net = BatchNormalization()(pnet)\n",
    "# net = Activation('relu')(net)\n",
    "c_layer = ConvLSTM2D(16,kernel_size=(3,3),padding=\"same\",\n",
    "                     activation=None,stateful=True,return_state=True,return_sequences=True)\n",
    "out_c, state_h, state_c = c_layer(enc_inputs)\n",
    "out\n",
    "mod = Model(inputs=enc_inputs,outputs=out_c)\n",
    "# net = fwd_res(enc_inputs,features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = pre_net(enc_inputs,filts=16)\n",
    "max_tsteps = 5\n",
    "from keras.layers import Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Masking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fwd_res(enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_amt = 0.5 # Med\n",
    "DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model inputs\"\"\"\n",
    "\n",
    "class_input = Input(shape=(10,),name='class_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AutoEncoder Critic\"\"\"\n",
    "x = Input(shape=DL.input_shape,name='Image_input')\n",
    "\n",
    "encoder = Encoder(input_shape=DL.input_shape,\n",
    "                  y_dim=config.y_dim,\n",
    "                  z_dim=config.z_dim,\n",
    "                  layer_units=config.enc_layers)\n",
    "\n",
    "net_out = encoder.build(x)\n",
    "y = Activation('softmax',name='y')(net_out[0])\n",
    "z = Activation('linear',name='z')(net_out[1])\n",
    "\n",
    "# c = Activation('linear',name='critic_score')(net_out[2])\n",
    "\n",
    "yz = Concatenate(name='yz')([y,z])\n",
    "\n",
    "E = Model(inputs = x,\n",
    "          outputs = [y,z],\n",
    "          name='Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decoder \"\"\"\n",
    "decoder = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "Dec_input = Input(shape=(config.y_dim+config.z_dim,),name='Decoder_input')\n",
    "Dec_output = decoder.build(Dec_input)\n",
    "\n",
    "G = Model(inputs=Dec_input,\n",
    "          outputs=Dec_output,\n",
    "          name='Decoder')\n",
    "# G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = Activation('linear',name='x_pred')(G(yz))\n",
    "\n",
    "\n",
    "sse_layer = lambda x: K.expand_dims(sse(x,AE(x)))\n",
    "AE = Model(inputs=x,outputs=x_pred,name='AE')\n",
    "sse_out = Lambda(sse_layer)(AE(x))\n",
    "D = Model(\n",
    "    inputs=x,\n",
    "    outputs=sse_out,\n",
    "    name='D'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generator \"\"\"\n",
    "def gen_Z(y):\n",
    "    Z = K.random_normal(shape=(K.shape(y)[0],config.z_dim))\n",
    "    \n",
    "    return Z\n",
    "\n",
    "generator = Generator(y_dim = config.y_dim,\n",
    "                      z_dim = config.z_dim,\n",
    "                      dec_blocks= config.dec_blocks)\n",
    "\n",
    "G_input_y = Input(shape=(config.y_dim,),name='G_y')\n",
    "G_input_z = Lambda(gen_Z,name='G_z')(G_input_y)\n",
    "\n",
    "G_input = Concatenate(name='zy')([G_input_z,G_input_y])\n",
    "\n",
    "G_img = generator.build(G_input)\n",
    "\n",
    "Gen = Model(\n",
    "    inputs=G_input_y,\n",
    "    outputs=G_img,\n",
    "    name='Generator'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Outputs \"\"\"\n",
    "fake_img = Activation('linear',name='fake_img')(Gen(class_input))\n",
    "\n",
    "c_real = Activation('linear',name='C_real')(D(x))\n",
    "c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "# c_real = Activation('linear',name='C_real')(D(x))\n",
    "# c_recon = D(recon_img)\n",
    "# c_fake = Activation('linear',name='C_fake')(D(fake_img))\n",
    "\n",
    "\"\"\" Losses \"\"\"\n",
    "# GAN Losses\n",
    "GAN_d_loss = -1*(c_real - c_fake)\n",
    "GAN_g_loss = -1*c_fake\n",
    "\n",
    "# Gradient Penalty\n",
    "gp_loss = gradient_penalty_loss(x,fake_img,D)\n",
    "\n",
    "# Add Discriminator losses\n",
    "D.add_loss([GAN_d_loss])\n",
    "\n",
    "# Add Generator losses\n",
    "# Gen.add_loss([GAN_g_loss])\n",
    "\n",
    "EBGAN = Model(\n",
    "    inputs=[x,class_input],\n",
    "    outputs=[y,c_real,c_fake],\n",
    "    name='EBGAN'\n",
    ")\n",
    "# mod_outputs = [\n",
    "#     (recon_img, sse, config.recon),\n",
    "#     (y, 'categorical_crossentropy', config.xent),\n",
    "#     (c_fake,lambda yt,yp: GAN_d_loss+GAN_g_loss, 1),\n",
    "# ]\n",
    "\n",
    "# outs,ls,ws = zip(*mod_outputs)\n",
    "\n",
    "# VGAN = Model(\n",
    "# inputs=x,\n",
    "# outputs=outs)\n",
    "\n",
    "# losses = {k:v for k,v in zip(VGAN.output_names,ls)}\n",
    "# loss_W = {k:v for k,v in zip(VGAN.output_names,ws)}\n",
    "\n",
    "metrics = {\n",
    "    'y': 'accuracy',\n",
    "}\n",
    "\n",
    "EBGAN.compile(optimizer=config.optimizer,loss={'y':'categorical_crossentropy','C_real':lambda yt,yp:GAN_d_loss,'C_fake':lambda yt,yp:GAN_g_loss},metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBGAN.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "RF = to_categorical(np.ones(len(DL.sx_train)),num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_history = PrintHistory(print_keys=['loss','val_loss','val_y_acc'])\n",
    "# update_k = Update_k(k_var = k)\n",
    "callbacks=[\n",
    "    print_history,\n",
    "#     update_k\n",
    "]\n",
    "if config.monitor is not None:\n",
    "    early_stop = EarlyStopping(monitor=config.monitor,min_delta=config.min_delta,patience=10,restore_best_weights=True)\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "history = EBGAN.fit(x={'Image_input':DL.sx_train,'class_input':DL.y_train_oh},\n",
    "              y={\n",
    "                  'y':DL.y_train_oh,\n",
    "                  'C_real':RF,\n",
    "                  'C_fake':RF,\n",
    "                  },\n",
    "              verbose=0,\n",
    "              batch_size=config.batch_size,\n",
    "              callbacks=callbacks,\n",
    "              validation_split=0.05,\n",
    "              epochs=config.epochs,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # true_latent_vec = Concatenate()([y_class,z_lat_stats[0]])\n",
    "# latent_vec = Concatenate()([y,z_lat])\n",
    "# shuffled_lat = Concatenate()([y,z_sampled])\n",
    "# G = trainer.G\n",
    "# # recon = Activation('linear',name='G')(G(true_latent_vec))\n",
    "# fake_inp = G(latent_vec)\n",
    "# G_shuff = G(shuffled_lat)\n",
    "# # fake_lat_vec = Concatenate()(E(fake_inp))\n",
    "# # fake_ae = G(fake_lat_vec)\n",
    "\n",
    "# D_real = Activation('linear',name='D_real')(D(real_inp))\n",
    "# D_fake = Activation('linear',name='D_fake')(D(G_shuff))\n",
    "# # D_fake = E(fake_inp)[2]\n",
    "# D_all = Concatenate(axis=0,name='D_all')([D_fake,D_real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,idx = plot_ovt(DL,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_df = pd.DataFrame.from_records(trainer.model.history.history)\n",
    "hist_df = pd.DataFrame.from_records(VGAN.history.history)\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "metrics = ['loss','C_f_loss','y_acc']\n",
    "fig,axs = plt.subplots(nrows=len(metrics),sharex=True,figsize=(5,10))\n",
    "for metric_name,ax in zip(metrics,axs):\n",
    "    sns.scatterplot(data=hist_df[[metric_name,'val_'+metric_name]],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not config.dev_mode:\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_encoder = Model(x,z)\n",
    "classifier = Model(x,y)\n",
    "# y_lat_encoder = Model(trainer.E.input,trainer.y_lat)\n",
    "# decoder_inp = Input(shape=(config.y_dim+config.z_dim,))\n",
    "# dec_layers = trainer.model.layers[-(1+(5*2)):]\n",
    "# print(dec_layers)\n",
    "# _gen_x = dec_layers[0](decoder_inp)\n",
    "# l = dec_layers[1]\n",
    "# isinstance(l,keras.layers.core.Reshape)\n",
    "# F = None\n",
    "# for l in dec_layers[1:]:\n",
    "#     print(type(l))\n",
    "    \n",
    "#     if isinstance(l,keras.layers.merge.Add):\n",
    "#         _gen_x = l([F,_gen_x])\n",
    "#     else:\n",
    "#         _gen_x = l(_gen_x)\n",
    "    \n",
    "#     if isinstance(l,keras.layers.convolutional.Conv2DTranspose):\n",
    "#         if l.kernel_size==(1,1):\n",
    "#             F = _gen_x\n",
    "            \n",
    "# # generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL.y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "classifier.evaluate(DL.sx_test,DL.y_test_oh,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc = z_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "# y_lat = y_lat_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_lat = classifier.predict(DL.sx_test,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec = np.concatenate([y_lat,z_enc],axis=1)\n",
    "_lat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc_mu = np.mean(z_enc,axis=0)\n",
    "z_enc_cov = np.cov(z_enc,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(z_enc_mu,z_enc_cov,size=50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen = generator.predict(_lat_vec,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = np.random.randint(0,10000)\n",
    "plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec[rand_im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL2 = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                         rotation=None,\n",
    "                         translation=translation_amt,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_samples(DL.x_test,DL.sx_test,z_enc,y_lat,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc2 = z_encoder.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "y_lat2 = classifier.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "_lat_vec2 = np.concatenate([y_lat2,z_enc2],axis=1)\n",
    "regen2 = generator.predict(_lat_vec2,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import remove_axes,remove_labels\n",
    "from src.utils import gen_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 5\n",
    "rand_im = np.random.randint(0,10000,size=examples)\n",
    "fix,axs = plt.subplots(examples,11,figsize=(8,4))\n",
    "_lat_s = []\n",
    "regen_s = []\n",
    "out = gen_trajectory(z_enc[rand_im],z_enc2[rand_im],delta=.25)\n",
    "out_y = gen_trajectory(y_lat[rand_im],y_lat2[rand_im],delta=.25)\n",
    "\n",
    "for z,y in zip(out,out_y):\n",
    "    _lat = np.concatenate([y,z],axis=1)\n",
    "    _lat_s.append(_lat)\n",
    "    regen_s.append(generator.predict(_lat,batch_size=config.batch_size))\n",
    "\n",
    "i=0\n",
    "for axr,idx in zip(axs,rand_im):\n",
    "    axr[0].imshow(DL.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    axr[1].imshow(DL.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[2].imshow(regen[idx].reshape(56,56),cmap='gray')\n",
    "    for j,a in enumerate(axr[3:-3]):\n",
    "        a.imshow(regen_s[j][i,:].reshape(56,56),cmap='gray')\n",
    "#         a.imshow(s.reshape(56,56),cmap='gray')\n",
    "    axr[-3].imshow(regen2[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-2].imshow(DL2.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-1].imshow(DL2.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    for a in axr:\n",
    "        remove_axes(a)\n",
    "        remove_labels(a)\n",
    "    i+=1\n",
    "# plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feat_range = (0,50)\n",
    "z_enc_scaled = [MinMaxScaler(feat_range).fit_transform(z_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(config.z_dim)]\n",
    "z_enc_scaled = np.squeeze(np.array(z_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import dit\n",
    "from dit import Distribution\n",
    "dxs = DL.dx[1]-14\n",
    "dys = DL.dy[1]-14\n",
    "\n",
    "def mutual_information(X,Y):\n",
    "    XY_c = Counter(zip(X,Y))\n",
    "    XY_pmf = {k:v/float(sum(XY_c.values())) for k,v in XY_c.items()}\n",
    "    XY_jdist = Distribution(XY_pmf)\n",
    "        \n",
    "    return dit.shannon.mutual_information(XY_jdist,[0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dx_I = [mutual_information(z_enc_scaled[i],dxs.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dy_I = [mutual_information(z_enc_scaled[i],dys.astype(int)+14) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_class_I = [mutual_information(z_enc_scaled[i],DL.y_test) for i in np.arange(config.z_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_I_df = pd.DataFrame.from_records({'class':z_class_I,'dy':z_dy_I,'dx':z_dx_I})\n",
    "z_I_df['class'] = z_I_df['class'].values.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,5))\n",
    "ax.set_ylim(0,0.8)\n",
    "ax.set_xlim(0,0.8)\n",
    "points = plt.scatter(x=z_I_df['dx'],y=z_I_df['dy'],c=z_I_df['class'],cmap='plasma')\n",
    "plt.colorbar(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(z_dx_I,z_dy_I)\n",
    "ax.set_ylim(0,0.6)\n",
    "ax.set_xlim(0,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),sorted(z_dy_I,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import var_expl,norm_var_expl\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "dtheta = DL.dtheta[1]\n",
    "fve_dx = norm_var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "fve_dy = norm_var_expl(features=z_enc,cond=dys,bins=21)\n",
    "# fve_dt = norm_var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fve_dx_norm = (dxs.var()-fve_dx)/dxs.var()\n",
    "# fve_dy_norm = (dys.var()-fve_dy)/dys.var()\n",
    "# fve_dth_norm = (dtheta.var()-fve_dt)/dtheta.var()\n",
    "fve_dx_norm = fve_dx\n",
    "fve_dy_norm = fve_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm.shape\n",
    "# np.save(os.path.join(config.model_dir,'fve_dx_norm'),fve_dx_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(fve_dx_norm.mean(axis=0),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('fve_dx')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dx.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "xdim = np.argmax(fve_dx_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dy_norm.mean(axis=0)\n",
    "# np.save(os.path.join(config.model_dir,'fve_dy_norm'),fve_dy_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dy.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "ydim = np.argmax(fve_dy_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(config.z_dim),fve_dth_norm.mean(axis=0))\n",
    "# plt.xlabel('Z_n')\n",
    "# plt.ylabel('fve_dtheta')\n",
    "# # plt.ylim(0.0,0.5)\n",
    "# np.argmax(fve_dth_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import Z_color_scatter\n",
    "Z_color_scatter(z_enc,[xdim,ydim],dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[7,18],dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
