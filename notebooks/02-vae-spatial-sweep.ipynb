{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from src.metrics import var_expl\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'data_dir': 'data',\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'dev_mode': False,\n",
       " 'enc_layers': [3000, 2000],\n",
       " 'epochs': 100,\n",
       " 'log_dir': '../logs',\n",
       " 'log_level': 'INFO',\n",
       " 'min_delta': 0.5,\n",
       " 'monitor': 'val_G_loss',\n",
       " 'optimizer': 'adam',\n",
       " 'recon': 5,\n",
       " 'xcov': 1000,\n",
       " 'xent': 10,\n",
       " 'y_dim': 10,\n",
       " 'z_dim': 10}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config,_ = get_config()\n",
    "setattr(config, 'batch_size', 512)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs', 100)\n",
    "setattr(config, 'enc_layers', [3000,2000])\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 10)\n",
    "setattr(config, 'xcov', 1000)\n",
    "setattr(config, 'recon', 5)\n",
    "setattr(config, 'log_dir', '../logs')\n",
    "setattr(config, 'dev_mode',False)\n",
    "setattr(config, 'monitor', 'val_G_loss')\n",
    "setattr(config, 'min_delta', 0.5)\n",
    "# setattr(config, 'xcov', None)\n",
    "setattr(config, 'optimizer', 'adam')\n",
    "\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up...\n"
     ]
    }
   ],
   "source": [
    "if not config.dev_mode:\n",
    "        print('setting up...')\n",
    "        prepare_dirs_and_logger(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_val = 0\n",
    "def trainer_generator(translation_vals):\n",
    "    for tx_val in translation_vals:\n",
    "        \n",
    "        # Update config\n",
    "        setattr(config, 'max_translation',tx_val)\n",
    "        setattr(config,'model_name','translation'+str(tx_val)+config.model_name)\n",
    "        prepare_dirs_and_logger(config)\n",
    "        with open(os.path.join(config.model_dir,'params.json'), 'w') as fp:\n",
    "            json.dump(vars(config), fp)\n",
    "        \n",
    "        print('Starting run tx=',tx_val)\n",
    "        \n",
    "        # Build Dataloader \n",
    "        if tx_val==0:\n",
    "            shift = None\n",
    "        else:\n",
    "            shift = tx_val\n",
    "        DL = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                             rotation=None,\n",
    "                             translation=shift,\n",
    "                            )\n",
    "        G_builder = GResNet(y_dim=config.y_dim,z_dim=config.z_dim,dec_blocks=config.dec_blocks)\n",
    "        E_builder = EDense(enc_layers=config.enc_layers,z_dim=config.z_dim,)\n",
    "        trainer = Trainer(config,DL,E_builder,G_builder,)\n",
    "        yield trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = trainer_generator([0.0,0.15,0.3,0.5,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run tx= 0.0\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  None\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           117.2644    63.5031     0.3213      \n",
      "1:           27.6169     28.9169     0.4767      \n",
      "2:           22.0376     25.207      0.5747      \n",
      "3:           19.7434     20.7395     0.602       \n",
      "4:           18.0581     18.6643     0.6077      \n",
      "5:           17.0386     18.7438     0.7473      \n",
      "6:           16.283      18.0107     0.836       \n",
      "7:           15.4867     15.858      0.8487      \n",
      "8:           14.9485     15.0814     0.856       \n",
      "9:           14.4488     14.3334     0.857       \n",
      "10:          14.0752     14.0168     0.8633      \n",
      "11:          13.7958     14.2705     0.867       \n",
      "12:          13.4436     13.39       0.869       \n",
      "13:          13.1954     13.1105     0.8723      \n",
      "14:          12.9537     13.2338     0.8737      \n",
      "15:          12.7318     12.7487     0.8747      \n",
      "16:          12.5263     12.6902     0.877       \n",
      "17:          12.3643     12.4626     0.881       \n",
      "18:          12.2623     12.6843     0.8797      \n",
      "19:          12.1687     12.508      0.8797      \n",
      "20:          11.9143     11.9461     0.885       \n",
      "21:          11.8998     12.2263     0.8827      \n",
      "22:          11.7059     12.082      0.8863      \n",
      "23:          11.5799     12.099      0.888       \n",
      "24:          11.5166     11.8476     0.888       \n",
      "25:          11.4624     11.79       0.886       \n",
      "26:          11.3738     11.9264     0.8873      \n",
      "27:          11.289      11.5388     0.8887      \n",
      "28:          11.2258     11.3987     0.8917      \n",
      "29:          11.1347     11.2192     0.8903      \n",
      "30:          11.0006     11.2745     0.8927      \n",
      "31:          10.9985     11.2503     0.893       \n",
      "32:          10.8913     11.1116     0.8907      \n",
      "33:          10.8209     11.315      0.8963      \n",
      "34:          10.8582     11.3046     0.8917      \n",
      "35:          10.7151     11.0982     0.8953      \n",
      "36:          10.7235     10.9104     0.8933      \n",
      "37:          10.6267     11.2326     0.8933      \n",
      "38:          10.5417     10.8088     0.8937      \n",
      "39:          10.5529     11.1148     0.8947      \n",
      "40:          10.4609     11.7077     0.8987      \n",
      "41:          10.4757     11.1127     0.8947      \n",
      "42:          10.5351     10.9392     0.8993      \n",
      "43:          10.3215     10.5748     0.8963      \n",
      "44:          10.3531     10.7299     0.8927      \n",
      "45:          10.2936     10.533      0.8997      \n",
      "46:          10.2745     10.5989     0.893       \n",
      "47:          10.2962     10.7732     0.9003      \n",
      "48:          10.206      10.4823     0.8987      \n",
      "Starting run tx= 0.15\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.15\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           98.0536     81.0645     0.1357      \n",
      "1:           34.2979     56.077      0.1753      \n",
      "2:           28.1522     45.0358     0.2083      \n",
      "3:           24.9189     58.8788     0.5383      \n",
      "4:           22.526      48.0457     0.6693      \n",
      "5:           21.0513     35.1612     0.7777      \n",
      "6:           19.5321     25.5176     0.7907      \n",
      "7:           18.5981     24.5522     0.805       \n",
      "8:           17.8791     19.5695     0.811       \n",
      "9:           17.3033     18.0415     0.818       \n",
      "10:          16.8698     17.5716     0.822       \n",
      "11:          16.459      16.6468     0.8263      \n",
      "12:          16.0109     16.2688     0.827       \n",
      "13:          15.6979     15.9415     0.8333      \n",
      "14:          15.449      15.7008     0.84        \n",
      "15:          15.2362     15.484      0.835       \n",
      "16:          14.9643     15.525      0.833       \n",
      "17:          14.7687     15.0904     0.839       \n",
      "18:          14.5255     14.7588     0.8437      \n",
      "19:          14.3588     14.7908     0.8447      \n",
      "20:          14.198      14.6786     0.844       \n",
      "21:          14.0407     14.4225     0.851       \n",
      "22:          13.8918     14.1248     0.8427      \n",
      "23:          13.7497     13.9445     0.8447      \n",
      "24:          13.5671     13.95       0.851       \n",
      "25:          13.4849     13.9564     0.8503      \n",
      "26:          13.4711     14.0927     0.848       \n",
      "27:          13.2865     13.6488     0.8527      \n",
      "28:          13.1747     13.3672     0.8543      \n",
      "29:          13.0816     13.3082     0.8543      \n",
      "30:          12.9372     13.7013     0.8557      \n",
      "31:          12.8257     13.237      0.859       \n",
      "32:          12.781      13.3077     0.8587      \n",
      "33:          12.7276     13.3435     0.8627      \n",
      "34:          12.6645     13.3011     0.8627      \n",
      "35:          12.5932     12.9453     0.8593      \n",
      "36:          12.468      13.1079     0.8653      \n",
      "37:          12.4777     12.8119     0.8657      \n",
      "38:          12.3321     12.7511     0.8653      \n",
      "39:          12.2859     13.0656     0.868       \n",
      "40:          12.3229     12.7677     0.871       \n",
      "41:          12.1741     12.5254     0.8687      \n",
      "42:          12.1312     12.7901     0.871       \n",
      "43:          12.0947     12.5778     0.873       \n",
      "44:          11.9468     12.4793     0.872       \n",
      "45:          11.9616     12.7454     0.8727      \n",
      "Starting run tx= 0.3\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.3\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           123.9711    76.089      0.3907      \n",
      "1:           35.9132     37.062      0.567       \n",
      "2:           29.0609     31.2667     0.6783      \n",
      "3:           25.3559     27.975      0.7153      \n",
      "4:           23.2742     25.7182     0.7363      \n",
      "5:           21.6968     40.401      0.751       \n",
      "6:           22.6199     21.9865     0.7603      \n",
      "7:           19.9766     21.099      0.7727      \n",
      "8:           18.904      19.8562     0.7773      \n",
      "9:           18.3515     18.2123     0.7803      \n",
      "10:          17.7407     17.8427     0.7903      \n",
      "11:          17.2524     17.4711     0.789       \n",
      "12:          16.8622     17.0593     0.797       \n",
      "13:          16.5364     17.0063     0.7943      \n",
      "14:          16.1743     16.1242     0.799       \n",
      "15:          15.8476     15.938      0.7983      \n",
      "16:          15.6574     15.6371     0.8053      \n",
      "17:          15.3983     15.4476     0.805       \n",
      "18:          15.1256     15.7475     0.8067      \n",
      "19:          14.996      15.2794     0.807       \n",
      "20:          14.7667     15.5174     0.8097      \n",
      "21:          14.5662     14.6873     0.811       \n",
      "22:          14.3909     14.9325     0.8157      \n",
      "23:          14.3627     14.3281     0.8147      \n",
      "24:          14.1329     14.9024     0.818       \n",
      "25:          14.0203     14.333      0.8183      \n",
      "26:          13.9207     14.0199     0.8247      \n",
      "27:          13.764      14.4634     0.8223      \n",
      "28:          13.7198     14.0123     0.8227      \n",
      "29:          13.5713     13.8291     0.825       \n",
      "30:          13.4056     13.8728     0.826       \n",
      "31:          13.4728     14.3231     0.8237      \n",
      "32:          13.3943     13.8216     0.8257      \n",
      "33:          13.2351     14.0113     0.8257      \n",
      "34:          13.1607     13.8328     0.828       \n",
      "35:          13.0749     13.6856     0.8273      \n",
      "36:          13.0512     13.3801     0.8303      \n",
      "37:          12.9445     13.9291     0.8263      \n",
      "38:          12.8816     13.2691     0.8297      \n",
      "39:          12.8077     13.2976     0.826       \n",
      "40:          12.8254     13.2986     0.8307      \n",
      "41:          12.682      13.2286     0.827       \n",
      "42:          12.6994     13.1414     0.8293      \n",
      "43:          12.6195     13.1664     0.8323      \n",
      "44:          12.5264     13.1065     0.8313      \n",
      "45:          12.543      13.01       0.8343      \n",
      "46:          12.5239     12.9183     0.8323      \n",
      "Starting run tx= 0.5\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.5\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           127.3221    70.3344     0.2477      \n",
      "1:           37.6616     48.2836     0.398       \n",
      "2:           30.5565     37.1468     0.6487      \n",
      "3:           27.057      29.8224     0.6923      \n",
      "4:           25.2283     26.8993     0.723       \n",
      "5:           24.7117     25.5445     0.7357      \n",
      "6:           22.997      24.2101     0.7423      \n",
      "7:           22.2345     22.5493     0.753       \n",
      "8:           21.1614     21.0032     0.7553      \n",
      "9:           20.305      21.9097     0.7547      \n",
      "10:          19.4544     21.1986     0.762       \n",
      "11:          21.1412     22.4084     0.7693      \n",
      "12:          20.0635     25.1027     0.775       \n",
      "13:          18.2573     21.9789     0.7717      \n",
      "14:          17.9795     19.8785     0.7783      \n",
      "15:          17.4084     18.9692     0.7793      \n",
      "16:          17.1222     17.6287     0.788       \n",
      "17:          17.0195     17.8292     0.7817      \n",
      "18:          16.711      17.356      0.7877      \n",
      "19:          16.509      16.3828     0.7953      \n",
      "20:          16.343      16.7684     0.7957      \n",
      "21:          16.0998     16.7881     0.801       \n",
      "22:          15.864      16.4251     0.8047      \n",
      "23:          16.2208     16.7059     0.7987      \n",
      "24:          15.8292     16.056      0.7997      \n",
      "25:          15.4562     15.7878     0.8007      \n",
      "26:          15.396      15.8636     0.8027      \n",
      "27:          15.1975     15.3712     0.8047      \n",
      "28:          15.1334     15.5029     0.7963      \n",
      "29:          15.119      18.7745     0.798       \n",
      "30:          15.4148     15.2389     0.808       \n",
      "31:          14.7797     15.9761     0.8077      \n",
      "32:          14.9348     15.3383     0.809       \n",
      "33:          14.7207     15.0617     0.808       \n",
      "34:          14.6        15.6724     0.8053      \n",
      "35:          14.4878     14.6886     0.813       \n",
      "36:          14.3605     14.5799     0.8087      \n",
      "37:          14.3512     15.236      0.811       \n",
      "38:          14.257      14.8587     0.8093      \n",
      "39:          14.4517     16.4624     0.808       \n",
      "40:          14.2822     14.6493     0.8103      \n",
      "41:          14.0723     14.8158     0.8173      \n",
      "42:          14.0069     14.8319     0.8133      \n",
      "43:          13.9057     14.4262     0.8157      \n",
      "44:          13.9327     14.8983     0.8157      \n",
      "45:          13.7622     14.3255     0.821       \n",
      "Starting run tx= 0.7\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.7\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           140.338     84.7372     0.1007      \n",
      "1:           44.7671     58.8582     0.283       \n",
      "2:           34.0586     48.7843     0.554       \n",
      "3:           29.1386     33.6322     0.6267      \n",
      "4:           26.5511     28.1443     0.6833      \n",
      "5:           24.9095     26.7325     0.7057      \n",
      "6:           24.05       25.1358     0.717       \n",
      "7:           23.0315     23.4783     0.723       \n",
      "8:           22.4789     22.9339     0.7357      \n",
      "9:           21.7214     22.4659     0.738       \n",
      "10:          21.0712     22.9785     0.7507      \n",
      "11:          20.4653     21.4495     0.7503      \n",
      "12:          20.1923     21.1392     0.7623      \n",
      "13:          19.5338     20.9584     0.7633      \n",
      "14:          19.1026     19.4105     0.7637      \n",
      "15:          18.7437     19.2223     0.7767      \n",
      "16:          18.2158     18.7194     0.7833      \n",
      "17:          18.2115     18.4082     0.7717      \n",
      "18:          17.5545     20.0485     0.7823      \n",
      "19:          17.6846     18.192      0.7827      \n",
      "20:          17.3324     17.5592     0.7837      \n",
      "21:          17.0581     18.0799     0.7847      \n",
      "22:          16.8391     17.2761     0.785       \n",
      "23:          16.8374     17.8819     0.7883      \n",
      "24:          16.4647     17.7812     0.7947      \n",
      "25:          16.3095     16.8243     0.792       \n",
      "26:          16.2777     23.7352     0.7777      \n",
      "27:          18.0015     17.5105     0.7923      \n",
      "28:          16.0764     16.8553     0.7883      \n",
      "29:          15.8575     16.3354     0.7927      \n",
      "30:          15.7305     16.4459     0.7857      \n",
      "31:          15.5122     15.905      0.7943      \n",
      "32:          15.3927     15.8925     0.7893      \n",
      "33:          15.2658     16.0371     0.7933      \n",
      "34:          15.0982     15.787      0.7967      \n",
      "35:          15.1203     16.1104     0.8023      \n",
      "36:          15.0914     15.5277     0.7957      \n",
      "37:          14.9011     15.3791     0.801       \n",
      "38:          15.1245     16.0531     0.7917      \n",
      "39:          14.8128     15.6738     0.7997      \n",
      "40:          14.8046     15.295      0.7993      \n",
      "41:          14.5813     15.1941     0.7993      \n",
      "42:          14.5612     15.5736     0.7987      \n",
      "43:          14.5267     15.51       0.804       \n",
      "44:          14.5789     15.4176     0.7963      \n",
      "45:          14.4486     15.1947     0.7953      \n",
      "46:          14.2794     14.9492     0.8047      \n",
      "47:          14.3088     20.5471     0.792       \n",
      "Starting run tx= 0.9\n",
      "input_shape:  (3136,)\n",
      "dataset:  fashion_mnist\n",
      "scale:  2\n",
      "tx_max:  0.9\n",
      "rot_max:  None\n",
      "loading fashion_mnist...\n",
      "sx_train:  (60000, 3136)\n",
      "making training data...\n",
      "making testing data...\n",
      "building encoder...\n",
      "building decoder/generator...\n",
      "Epoch        G_loss      val_G_loss  val_class_acc\n",
      "0:           127.4207    93.3357     0.1587      \n",
      "1:           40.6435     63.5443     0.456       \n",
      "2:           31.6951     36.0576     0.5887      \n",
      "3:           28.3765     29.5412     0.6397      \n",
      "4:           26.6141     27.4176     0.6813      \n",
      "5:           25.2763     25.5473     0.7013      \n",
      "6:           24.2512     25.2068     0.711       \n",
      "7:           23.4968     24.1236     0.7217      \n",
      "8:           22.7183     22.9586     0.721       \n",
      "9:           21.9769     22.376      0.7277      \n",
      "10:          21.5292     22.8581     0.7177      \n",
      "11:          21.2001     21.1156     0.7237      \n",
      "12:          20.7402     20.5337     0.7333      \n",
      "13:          20.0578     20.6643     0.7373      \n",
      "14:          19.7581     20.2613     0.741       \n",
      "15:          19.3609     20.9064     0.749       \n",
      "16:          19.2141     19.5766     0.7477      \n",
      "17:          18.7327     19.2404     0.752       \n",
      "18:          18.5164     18.8474     0.7547      \n",
      "19:          18.2182     18.5825     0.7607      \n",
      "20:          18.0909     18.3271     0.7627      \n",
      "21:          17.9137     18.4034     0.7547      \n",
      "22:          17.6883     18.7651     0.763       \n",
      "23:          17.4736     18.2681     0.7647      \n",
      "24:          17.3112     17.7688     0.764       \n",
      "25:          17.1457     17.5477     0.763       \n",
      "26:          16.926      17.454      0.7727      \n",
      "27:          16.9222     17.7635     0.769       \n",
      "28:          16.7172     17.4038     0.7707      \n",
      "29:          16.6287     17.2615     0.7783      \n",
      "30:          16.478      17.5929     0.7687      \n",
      "31:          16.3769     17.001      0.7737      \n",
      "32:          16.2596     16.9517     0.7753      \n",
      "33:          16.0912     16.7789     0.7717      \n",
      "34:          16.0621     16.814      0.776       \n",
      "35:          15.9771     16.8012     0.7787      \n",
      "36:          15.8577     16.8692     0.7743      \n",
      "37:          15.7985     16.5953     0.7753      \n",
      "38:          15.644      16.5875     0.778       \n",
      "39:          15.5927     16.245      0.769       \n",
      "40:          15.5241     16.9052     0.7743      \n",
      "41:          15.4855     16.2649     0.78        \n",
      "42:          15.4017     16.3752     0.78        \n",
      "43:          15.3398     16.168      0.7737      \n",
      "44:          15.2997     16.2372     0.787       \n",
      "45:          15.1728     15.9762     0.7783      \n",
      "46:          15.1075     16.1026     0.7793      \n",
      "47:          15.0989     16.0009     0.7793      \n",
      "48:          15.0693     16.0349     0.7737      \n",
      "49:          14.9686     15.934      0.7703      \n",
      "50:          14.914      16.0687     0.7797      \n",
      "51:          14.7954     15.886      0.7753      \n",
      "52:          14.7437     16.0422     0.7867      \n",
      "53:          14.7497     15.7011     0.777       \n",
      "54:          14.6273     15.6724     0.7873      \n",
      "55:          14.5867     15.7874     0.786       \n"
     ]
    }
   ],
   "source": [
    "for trn in trainers:\n",
    "    DL = trn.data_loader\n",
    "    config = trn.config\n",
    "    tx_val = trn.config.max_translation\n",
    "    trn.compile_model()\n",
    "    RF = to_categorical(np.ones(len(trn.data_loader.sx_train)),num_classes=2)\n",
    "    val_pct = 0.05\n",
    "    \n",
    "    cut_pt = int(len(trn.data_loader.sx_train)*(1-val_pct))\n",
    "    \n",
    "    tr_x = trn.data_loader.sx_train[:cut_pt]\n",
    "    val_x = trn.data_loader.sx_train[cut_pt:]\n",
    "    tr_y = {'class':trn.data_loader.y_train_oh[:cut_pt],'D':RF[:cut_pt],'G':trn.data_loader.sx_train[:cut_pt]}\n",
    "    val_y = {'class':trn.data_loader.y_train_oh[cut_pt:],'D':RF[cut_pt:],'G':trn.data_loader.sx_train[cut_pt:]}\n",
    "    \n",
    "    trn.go(x=tr_x,\n",
    "           y=tr_y,\n",
    "           validation_data=(val_x,val_y),\n",
    "           verbose=0)\n",
    "    \n",
    "    hist_df = pd.DataFrame.from_records(trn.model.history.history)\n",
    "    hist_df.to_pickle(os.path.join(config.model_dir,'tx_'+str(tx_val)+'training_hist.pk'))\n",
    "    \n",
    "    z_encoder = Model(trn.E.input,trn.z_lat)\n",
    "    classifier = Model(trn.E.input,trn.y_class)\n",
    "    z_enc = z_encoder.predict(trn.data_loader.sx_test,batch_size=config.batch_size)\n",
    "    class_enc = classifier.predict(trn.data_loader.sx_test,batch_size=config.batch_size)\n",
    "    np.save(os.path.join(config.model_dir,''.join(['z_enc_','tr',str(tx_val)])),z_enc)\n",
    "    np.save(os.path.join(config.model_dir,''.join(['class_enc_','tr',str(tx_val)])),class_enc)\n",
    "    dxs = trn.data_loader.dx[1]-14\n",
    "    dys = trn.data_loader.dy[1]-14\n",
    "    np.save(os.path.join(config.model_dir,'dxs_'+'tr'+str(tx_val)),dxs)\n",
    "    np.save(os.path.join(config.model_dir,'dys_'+'tr'+str(tx_val)),dys)\n",
    "# #     dtheta = DL.dtheta[1]\n",
    "#     fve_dx = var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "#     fve_dy = var_expl(features=z_enc,cond=dys,bins=21)\n",
    "    \n",
    "#     fve_dx_norm = np.nan_to_num((dxs.var()-fve_dx)/dxs.var())\n",
    "#     fve_dy_norm = np.nan_to_num((dys.var()-fve_dy)/dys.var())\n",
    "# #     fve_dt = var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
