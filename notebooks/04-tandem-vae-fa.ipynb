{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial and Identity Tandem VAE\n",
    "Inspired by Olshausen and Cheung's work we try to segregate identity from spatial information in an unsupervised way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- ~~Implement cross-covariance penalty~~\n",
    "    - https://stackoverflow.com/questions/45874928/how-to-compute-covariance-in-tensorflow\n",
    "    - https://arxiv.org/abs/1412.6583\n",
    "    - https://en.wikipedia.org/wiki/Cross-covariance\n",
    "    - ~~Needs to be per-batch basis, use regularization?~~ Just operate on the layer, it has shape [batch,dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import keras as keras\n",
    "from keras.layers import Dense,Input,Lambda,Concatenate,Activation\n",
    "from keras.models import Model,load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.losses import categorical_crossentropy,logcosh\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.callbacks import BaseLogger,RemoteMonitor,TerminateOnNaN\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from src.models import build_dense\n",
    "from src.utils import ElasticSearchMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test Fasion MNIST data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train,w_train), (x_test,y_test,w_test) = emnist.load_byclass()\n",
    "(x_train, y_train), (x_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "class_ids = np.unique(y_train)\n",
    "masks_train = [y_train==i for i in class_ids]\n",
    "masks_test = [y_test==i for i in class_ids]\n",
    "\n",
    "y_test_oh = to_categorical(y_test,num_classes=10)\n",
    "y_train_oh = to_categorical(y_train,num_classes=10)\n",
    "\n",
    "digit_mask = lambda y: y<10 \n",
    "uppercase = lambda y: (y>=10) & (y<36)\n",
    "lowercase = lambda y: (y>=36) & (y<62)\n",
    "\n",
    "input_shape=(784,)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "# plt.imshow(x_train[masks[4]][10].reshape(28,28).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2281/60000 [00:00<00:02, 22800.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:01<00:00, 36655.81it/s]\n",
      " 38%|███▊      | 3823/10000 [00:00<00:00, 38218.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 38731.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make dataset thats just a copy with random offsets\n",
    "num_train = len(y_train)\n",
    "num_test = len(y_test)\n",
    "\n",
    "# pre-allocate shifted inputs\n",
    "sx_train = np.empty((num_train,784*4))\n",
    "sx_test = np.empty((num_test,784*4))\n",
    "\n",
    "# pre-allocate list of dx,dy shifts for each image\n",
    "delta_train = np.empty((num_train,2))\n",
    "delta_test = np.empty((num_test,2))\n",
    "\n",
    "def random_offset(X,scale=2):\n",
    "    bg_size=(28*scale,28*scale)\n",
    "    \n",
    "    dx = int(np.random.randint(-12,12))+14\n",
    "    dy = int(np.random.randint(-12,12))+14\n",
    "    \n",
    "    dx = max(dx,0)\n",
    "    dx = min(dx,bg_size[0]-28)\n",
    "    \n",
    "    dy = max(dy,0)\n",
    "    dy = min(dy,bg_size[0]-28)\n",
    "#     print(dx,dy)\n",
    "    new_im = np.zeros(bg_size)\n",
    "    new_im[dx:dx+28,dy:dy+28] = letter\n",
    "    \n",
    "    return new_im,np.array([dx,dy])\n",
    "\n",
    "print('making training data...')\n",
    "for i in tqdm(np.arange(num_train)):\n",
    "    letter = x_train[i].reshape(28,28)\n",
    "    new_im,offsets = random_offset(letter,scale=2)\n",
    "    sx_train[i] = new_im.reshape(1,4*784)\n",
    "    delta_train[i] = offsets\n",
    "\n",
    "print('making testing data...')\n",
    "for i in tqdm(np.arange(num_test)):\n",
    "    letter = x_test[i].reshape(28,28)\n",
    "    new_im,offsets = random_offset(letter,scale=2)\n",
    "    sx_test[i] = new_im.reshape(1,4*784)\n",
    "    delta_test[i] = offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE4RJREFUeJzt3X1sneV5x/HfZR+/20mcOElNYohIeCltIKEpGi3bYGwI0CTgHzamdalaKaiFqmxUGkLbirZVQ1Vh6z9DCwWRVhQNjTD4o1oL6QujUNQkS0lCgECbN892YnAaO7Fjn3Ou/eGTykudHJ9zPfGx7nw/UuST43Nf58pznvPL48fnvh9zdwEA0lJX6wYAANkj3AEgQYQ7ACSIcAeABBHuAJAgwh0AElQ23M2sx8x+ZGZvmdluM/ty6f6HzKzXzHaU/tx67tsFAMyElfucu5l1S+p29+1m1iFpm6TbJd0pacTdv3Hu2wQAVCJX7gHu3iepr3R72Mz2SFp2rhsDAFSv7JH7/3uw2QpJr0j6uKS/kvRZScckbZV0v7sPTTNmg6QNktTcap+4aGVDqOED/UtC460YGi5JyrfEazQei88MLjRZaPwV3UfCPew6sjhcIzcWLqF8c2x8XT7eQ24s/pqOd8ReU0nqmH8iNH60vzXcQ7HsYWN59ePx7Zlvjm3PLPaLfHxzavzgoUF3r+jNNuNwN7N2ST+R9DV332xmSyUNSnJJ/6DJUzefO1uNy69s8sdfXF5Jf7/lS1+/JzS+IbbfS5I+WB2vsfyH8b3m2EWxd9D2v3ss3MNH/+2L4Rqdb8f/xz26KvbZgOYP4kGy8J2T4RqHbmgK1/j9m3eExu985KpwD6Nd8c9qzNsff48MXRp7j7QMxveLwbXxGvvu+8o2d19XyZgZvQJm1iDpOUlPu/tmSXL3AXcvuHtR0uOSrqm0YQDAuTGTT8uYpCck7XH3R6fc3z3lYXdI2pV9ewCAaszkZ5ZPS/qMpJ1mdurnvQcl3WVmazR5WmafpLvPSYcAgIrN5NMyr0qa7rcS38u+HQBAFpihCgAJItwBIEGEOwAkiHAHgAQR7gCQoAwmCc/c/oEl+uI37w3VWPaT2JR5G45PUe36YbiEigs6wjVat38YGv+xzvjs0gv/6bVwjeLvrg3XWPDj3tB4awmuXyDJc/XhGiv+/mC4xmsjsfmEPS+/He5hwZJF4RqaiM9QbQv+U4od8bUDxjrnh2tUgyN3AEgQ4Q4ACSLcASBBhDsAJIhwB4AEEe4AkCDCHQASRLgDQIIIdwBIEOEOAAma1eUHVBe/EviJFQtC41t/OhBrQFJxZU+4Rv3QcLhG9LK77b3xC/fmVlwYruHvxpYOkKT8xd3lH3S2HnJz4zinMV8I16gLXqfbWlrCPRTa48s5ZMFGJ0Ljs3ifDl/aHq5RjbmxRwMAMkW4A0CCCHcASBDhDgAJItwBIEGEOwAkiHAHgAQR7gCQIMIdABJEuANAgmZ3+YGilDsRK9G6fX+shcsuijUgqW5oJFyj2B6/qnr0f+ZCU7gFeUu8SLGzI1wj9+7BWA8XxpYvkKS692M9SJIWxpbXkKSO3tgSBoXF8R7qj/w6XKOQwX5hY7G1GAqH/jfcw5LXLgjXqCb1OHIHgAQR7gCQIMIdABJEuANAggh3AEgQ4Q4ACSLcASBBhDsAJIhwB4AEEe4AkKCyyw+YWY+kb0taKsklbXT3b5rZQkn/LmmFpH2S7nT3obPVqh+X5h0IXt09nw8NrxsZiz2/JA3Fp1ZbLr7ygy+cHxo/0WrhHrJQd6AvXMO7l9S8B5sXny7vHx4N1ziydllo/Pytw+EeJro7wzWiS0pIkpYsCg2vW7Qw3MKJpbU5hp7Js+Yl3e/uV0j6HUn3mNkVkh6QtMXdL5G0pfR3AMAcUDbc3b3P3beXbg9L2iNpmaTbJG0qPWyTpNvPVZMAgMpU9POCma2QtFbSG5KWuvupn2X7NXnaBgAwB8w43M2sXdJzku5z92NTv+fursnz8dON22BmW81s68TJ+FK5AIDyZhTuZtagyWB/2t03l+4eMLPu0ve7JR2ebqy7b3T3de6+rqGpPYueAQBllA13MzNJT0ja4+6PTvnWi5LWl26vl/RC9u0BAKoxk8/jfVrSZyTtNLMdpfselPSwpGfN7POavFDIneemRQBApcqGu7u/KulMH4i+Mdt2AABZYIYqACSIcAeABMXnwFegmJNGu2L/n7QFr1Lv/7M7NF6SbO3HwjVGl7WFa7S9/l5ofPNQV7gHr68P17CJ2JISUvwq99YR/yRXsb01XMO749Pdmz6o/bIS9cOx10OSihfHllGQpEJzMOK64vtF7sS0nxI/5zhyB4AEEe4AkCDCHQASRLgDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABM3qDNXcwnF1/umhUI1BLQ+Nr199bWi8JA33xGcAWjFcQgdvuiQ0/ppPvBPu4a3nLg/X8Fx8VmZbb2yDnlwQP85pGYy/qHWF+GzG6//s56Hx2w9cHe4hdzy+LT5Y3RCu0dof256jXfH3+j9+4alwjTseq3wMR+4AkCDCHQASRLgDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABBHuAJAgwh0AEjSryw+MjzTq4E9jywes2DESGl/3zv7QeElatGxpuIaNxi8g7C1NofH9K1aGe1i+ty9cI794XrhGbvevYgVamsM9+OL4MgrRC31L0ve/vy40ftXPDoR7OL76gnCNns3xfcvGxkPjiws6wj38Zc9fhGtIX6l4BEfuAJAgwh0AEkS4A0CCCHcASBDhDgAJItwBIEGEOwAkiHAHgAQR7gCQIMIdABI0q8sPWFGqH41dTdxGJ0LjJ66KT7lvGIwtgSBJo6sWh2u0vN0fGj8+b1G4h7bg9G5Jajg4GK7hGSwfEFXoiC0HIUm5Ix+Gayx600Pjvbkx3EPbnoFwjWL/4XANzY8tbWF98R6Wb4kvr7GvijEcuQNAggh3AEgQ4Q4ACSLcASBBZcPdzJ40s8NmtmvKfQ+ZWa+Z7Sj9ufXctgkAqMRMjtyfknTzNPf/s7uvKf35XrZtAQAiyoa7u78iKf75LADArImcc7/XzN4snbbpPNODzGyDmW01s635E8cDTwcAmKlqw/0xSSslrZHUJ+mRMz3Q3Te6+zp3X5drbavy6QAAlagq3N19wN0L7l6U9Lika7JtCwAQUdXyA2bW7e6nLk1+h6RdZ3v8b8YVpKah4NTolobQ+Ia+o6HxkpRfHJ9O3Pjr+LT96DTx1sPxHpSrD5fI7zsQrlE/L/aa+Hh8W+TezYdr5C/tCdcoBhcV8eb4Mgqxd3nJqhXxGoVCaLjXx/fv493xGtUouxuY2TOSrpfUZWaHJH1V0vVmtkaTr+E+SXefwx4BABUqG+7uftc0dz9xDnoBAGSEGaoAkCDCHQASRLgDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABAUnKlfGilLDiViNugOxq6pPXLos1oCk+pH4VHXb8364RvTK7gOf7A63sPz1+NXhT97yyXCN5v7YjpXF61G8ML49szDeYaHx0SU+JKluZCxco9jeHK5hQydD4+tGY+MlqdC4MFyjGhy5A0CCCHcASBDhDgAJItwBIEGEOwAkiHAHgAQR7gCQIMIdABJEuANAggh3AEjQrC4/kG+Vjqwrhmos+vn80PjGX8Wny2fh+A2rwzVyY7Eru7f2Z3CN+gyuUN88GJ+qXj80HBrvjY3hHmwsvixFfkFTvEZrbPkB27k33INnsF8Uc/Fjz7rh46Hxo6t7wj20DMYyr1ocuQNAggh3AEgQ4Q4ACSLcASBBhDsAJIhwB4AEEe4AkCDCHQASRLgDQIIIdwBI0KwuP5A7Li15IzY1WhP5bJqpsbY9A+EaxfbW0PjOo/Eru9uRD8M1Chd3h2vU52NLMaghg7dCb/w1bTz8QbhG/lOXh8bb8vjrYUdjy0FIkhWCr6kkjcaWtqgrxJfomAguB1EtjtwBIEGEOwAkiHAHgAQR7gCQIMIdABJEuANAggh3AEhQ2XA3syfN7LCZ7Zpy30Ize8nM9pa+dp7bNgEAlZjJkftTkm4+7b4HJG1x90skbSn9HQAwR5QNd3d/RdLp0xBvk7SpdHuTpNsz7gsAEFDtnOul7t5Xut0vaemZHmhmGyRtkKS2j7Tpo1/aXeVTTvrZqtWh8Z1vx69EXj8en5JcNxGv0X9tfWj87be+Hu5hy79eG67ReCyDKd6XXxgan8VrOu+Xo+EaR65uC9f48z/ZEhq/qfUPwj20HQyX0MnOLKbtLw6NrstgBYRL/nhvuMb2JysfE/6Fqru7pDO+M9x9o7uvc/d1zQuao08HAJiBasN9wMy6Jan09XB2LQEAoqoN9xclrS/dXi/phWzaAQBkYSYfhXxG0uuSLjOzQ2b2eUkPS/ojM9sr6Q9LfwcAzBFlf6Hq7ned4Vs3ZtwLACAjzFAFgAQR7gCQIMIdABJEuANAggh3AEhQBpd8n7njQy3a9mxs+YCLNx8KjR9dFZuOLElNr8aWUJAkrVoRLrHy/djc6G0vXx3uYUn/YLiGDZ8I1/CO1pr3MNHTFa5xwQv7wzW+0xX7INuqTbH3mCQVFs8P18iCjU7UugW9l7+kJs/LkTsAJIhwB4AEEe4AkCDCHQASRLgDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABM3q8gN1ealpKHaV+WJ7bJp5449/ERovSb76snCN+qHhcI2oI1fGl2JYdnAoXMMn4lPEbfRkaPzx1ReEe2geHAvXKCxekEEfsfFZLNHR3HssXCO/IPZel6SGkdiyEj4af02lhRnUqBxH7gCQIMIdABJEuANAggh3AEgQ4Q4ACSLcASBBhDsAJIhwB4AEEe4AkKBZnaFabJBOfMRCNWwsNhMxi9mldVlc0DlXH65hY+Oh8R29sQtsS5If6gvXsLb4TMTozOXWvfELfash/nbKYlZmMdhGXSE2i1ySJrrawzUa3opfLDz8L1myKNzDyIr4+6waHLkDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABBHuAJAgwh0AEkS4A0CCCHcASNDsXiB7XOo4UAzViE65t+am0HhJ0uEP4jVamsMlfOH80Pixzvj/7fMyWDrAWlrCNcYXx/qYaJsX7qF9R2+4Rl1zY7hGPviS5I7GlviQpPojR8M1PIOp/9FlEBp+8X64h4U7u8I1qlmIIRTuZrZP0rCkgqS8u6+L1AMAZCOLI/cb3D2DVZcAAFnhnDsAJCga7i7pB2a2zcw2TPcAM9tgZlvNbGv+5PHg0wEAZiJ6WuY6d+81syWSXjKzt939lakPcPeNkjZKUtuinvhC0QCAskJH7u7eW/p6WNLzkq7JoikAQEzV4W5mbWbWceq2pJsk7cqqMQBA9SKnZZZKet7MTtX5rrv/VyZdAQBCqg53d/+lpKsy7AUAkBE+CgkACZrV5QdkktdbqIRPTMR6eG9fbLwkzY9PVc9E70BoeFtfZ0aNxHhHBksY5GMfxGrpjX9MN38ovvxAFm/Inpdrf8w20ROfcp8Fy8eWO8limZCRnnCJqtR+LwAAZI5wB4AEEe4AkCDCHQASRLgDQIIIdwBIEOEOAAki3AEgQYQ7ACSIcAeABM3q8gOtS05ozb07QjV2n7gyNH54WX1ovCQ1nIhfc+T4BbFlGCQpNxobf//n/iPcw7f+5o5wjbHO+DFG+6F8aPzglS3hHsZv/lS4xmh3IVzjX275Tmz8F+4K9zB4ZVO4RuNw/H022hV7ny1ti68dsObGd8I19v5t5WM4cgeABBHuAJAgwh0AEkS4A0CCCHcASBDhDgAJItwBIEGEOwAkiHAHgAQR7gCQIHOPT/Gd8ZOZHZG0f9aeMK5L0mCtm5jD2D7lsY3KYxuVd5m7d1QyYFbXlnH3xbP5fFFmttXd19W6j7mK7VMe26g8tlF5Zra10jGclgGABBHuAJAgwv3sNta6gTmO7VMe26g8tlF5FW+jWf2FKgBgdnDkDgAJItwBIEGE+zTMbJ+Z7TSzHdV8BClFZvakmR02s11T7ltoZi+Z2d7S185a9lhrZ9hGD5lZb2lf2mFmt9ayx1oysx4z+5GZvWVmu83sy6X72Y9KzrKNKt6POOc+DTPbJ2mduzOxosTMfk/SiKRvu/vHS/d9XdKH7v6wmT0gqdPd/7qWfdbSGbbRQ5JG3P0btextLjCzbknd7r7dzDokbZN0u6TPiv1I0lm30Z2qcD/iyB0z4u6vSPrwtLtvk7SpdHuTJnfC89YZthFK3L3P3beXbg9L2iNpmdiPfuMs26hihPv0XNIPzGybmW2odTNz2FJ37yvd7pe0tJbNzGH3mtmbpdM25+0ph6nMbIWktZLeEPvRtE7bRlKF+xHhPr3r3P1qSbdIuqf04zbOwifP73GO77c9JmmlpDWS+iQ9Utt2as/M2iU9J+k+dz829XvsR5Om2UYV70eE+zTcvbf09bCk5yVdU9uO5qyB0jnCU+cKD9e4nznH3QfcveDuRUmP6zzfl8ysQZOh9bS7by7dzX40xXTbqJr9iHA/jZm1lX6RITNrk3STpF1nH3XeelHS+tLt9ZJeqGEvc9Kp0Cq5Q+fxvmRmJukJSXvc/dEp32I/KjnTNqpmP+LTMqcxs4s1ebQuTa6a+V13/1oNW5oTzOwZSddrcnnWAUlflfSfkp6VdKEml3K+093P218onmEbXa/JH6Vd0j5Jd085v3xeMbPrJP23pJ2SiqW7H9TkOWX2I511G92lCvcjwh0AEsRpGQBIEOEOAAki3AEgQYQ7ACSIcAeABBHuAJAgwh0AEvR/klj9j3EYovAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(delta_test[:,0],delta_test[:,1],bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a shifted digit on a larger background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 120\n",
    "fashion_category = 9\n",
    "print(y_train[masks_train[fashion_category]][i])\n",
    "fig,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "axs[0].imshow(x_train[masks_train[fashion_category]][i].reshape(28,28))\n",
    "axs[1].imshow(sx_train[masks_train[fashion_category]][i].reshape(28*2,28*2))\n",
    "\n",
    "axs[0].get_xaxis().set_visible(False)\n",
    "axs[0].get_yaxis().set_visible(False)\n",
    "axs[1].get_xaxis().set_visible(False)\n",
    "axs[1].get_yaxis().set_visible(False)\n",
    "\n",
    "# fig.savefig('./shifted_mnist_3.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "```\n",
    "|     Inputs (3136)     |\n",
    " \\      h1 (1500)      /\n",
    "  |     h2 (1500)     |\n",
    "  \n",
    "     |z_hat| |y_hat|\n",
    "     \n",
    "    /   h3 (1500)   \\\n",
    "   |    h4 (1500)    |\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dims = [3000,2000]\n",
    "z_dim = 3\n",
    "y_dim = 10\n",
    "\n",
    "# randomly shifted image\n",
    "inputs = Input(shape=(784*4,))\n",
    "# encoded = Dense(encoding_dim,activation='relu')(inputs)\n",
    "encoded = build_dense(inputs,encoding_dims,activations='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dist_sample = sampler( args=(mean,std) )\n",
    ">\n",
    ">parameterizes a normal distribution from a mean and std and samples it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean = Dense(z_dim,name='z_mean')(encoded)\n",
    "# q_mean = Dense(q_dim,name='q_mean')(encoded)\n",
    "# zz_mean = Dense(2,name='zz')(encoded)\n",
    "# z_log_sigma = Dense(z_dim)(encoded)\n",
    "# \"layerize\" z_hat random variable\n",
    "# lat_vec = Lambda(sampler,name='z_sample')([z_mean,z_log_sigma])\n",
    "\n",
    "# y_hat_mean = Dense(y_dim,name='y_mean')(encoded)\n",
    "# y_hat_sigma = Dense(y_dim,name='y_sigma')(encoded)\n",
    "# y_hat = Lambda(sampler, name='y_hat')([y_hat_mean,y_hat_sigma])\n",
    "# y_hat = Dense(3,name='y_hat')(encoded)\n",
    "\n",
    "# latent class repr\n",
    "# y_hat = Dense(2,activation='sigmoid')(encoded)\n",
    "# y_int = Dense(encoding_dims[1],activation='relu')(y_hat)\n",
    "# y_int = Dense(250,activation='relu')(y_int)\n",
    "y_class = Dense(10,activation='softmax')(encoded)\n",
    "\n",
    "# Concatenate with One-hot identity vector\n",
    "combo_vec = Concatenate()([z_mean,y_class])\n",
    "\n",
    "# Expand back out input dimensions (batch_size x im_size)\n",
    "\n",
    "decoded_mean = build_dense(combo_vec,[encoding_dims[1],encoding_dims[0]]+[4*784],activations=['relu','relu','sigmoid'])\n",
    "# decoded_mean = build_dense(combo_vec,[encoding_dims[1],encoding_dims[0]]+[4*784],activations=['relu','relu','sigmoid'])\n",
    "tandem_vae = Model(inputs,decoded_mean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tandem_vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Loss function\n",
    "\n",
    "- Reconstruction loss (sum of squared error)\n",
    "\n",
    "$ \\sum\\limits_{n} (X - \\bar{X})^2 $\n",
    "- Cross-covariance (XCov) of latent vars (z_hat, y_hat)\n",
    "- Classification loss (categorical crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import *\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = ReconstructionLoss(inputs=inputs,outputs=decoded_mean,weight=20)\n",
    "xcov = XCov(y_class,z_mean,weight=1)\n",
    "# kl_loss_z = KLDivergenceLoss(z_log_sigma,z_mean,weight=0.001,name='DKL_z')\n",
    "# kl_loss_y = KLDivergenceLoss(y_hat_sigma,y_hat_mean, weight=0.0001, name='DKL_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true,y_pred):\n",
    "    total_loss = 0\n",
    "    loss_fns = [\n",
    "        K.sum(recon_loss(y_true,y_pred)),\n",
    "        10*xcov(y_true,y_pred),\n",
    "        K.sum(10*categorical_crossentropy(y_true,y_class)),\n",
    "#         K.sum(kl_loss_z(y_true,y_pred))/128,\n",
    "#         K.sum(kl_loss_y(y_true,y_pred))\n",
    "    ]   \n",
    "    for L in loss_fns:\n",
    "        total_loss += L\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "tandem_vae.compile(loss=vae_loss,optimizer='nadam',metrics=[recon_loss,recon_mse,xcov,acc,xentropy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = RemoteMonitor(root='http://localhost:9200',path='/tensorflow/train_batch/')\n",
    "examples=10\n",
    "choices = np.random.choice(np.arange(len(y_test)),examples)\n",
    "test_ims = sx_train[choices[:3]]\n",
    "# print(test_ims.shape)\n",
    "\n",
    "es_logger = ElasticSearchMonitor(root='http://localhost:9200',path='/tensorflow')\n",
    "ToN = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tandem_vae.fit(x=sx_train,y=y_train_oh,validation_split=0.1,\n",
    "               shuffle=True,\n",
    "               epochs=10,\n",
    "               batch_size=128,\n",
    "               callbacks=[es_logger,ToN],\n",
    "               verbose=0\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tandem_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean_encoder = Model(inputs,z_mean)\n",
    "# y_hat_encoder = Model(inputs,y_class)\n",
    "classifier = Model(inputs,y_class)\n",
    "decoder_inp = Input(shape=(y_dim+z_dim,))\n",
    "dec_layers = tandem_vae.layers[-3:]\n",
    "_gen_x = dec_layers[0](decoder_inp)\n",
    "_gen_x = dec_layers[1](_gen_x)\n",
    "_gen_x = dec_layers[2](_gen_x)\n",
    "generator = Model(decoder_inp,_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean_enc = z_mean_encoder.predict(sx_test,batch_size=128)\n",
    "y_class_enc = classifier.predict(sx_test,batch_size=128)\n",
    "# y_hat_enc = y_hat_encoder.predict(sx_test,batch_size=128)\n",
    "# y_int_enc = y_int_encoder.predict(sx_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n",
    "plt.scatter(y_class_enc[:,1],y_class_enc[:,2],c=y_test,cmap='magma')\n",
    "plt.xlabel('y_0')\n",
    "plt.ylabel('y_1')\n",
    "plt.title(r\"Latent Dimension $\\hat{Y}$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tandem_vae.save_weights('../models/tandem_vae/vae_weights.h5')\n",
    "# generator.save_weights('../models/tandem_vae/generator_weights.h5')\n",
    "# lat_encoder.save_weights('../models/tandem_vae/encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "classifier_perf = classifier.evaluate(sx_test,to_categorical(y_test,num_classes=10))\n",
    "\n",
    "print('Classification Accuracy: ',classifier_perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].hist2d(z_mean_enc[:,0],z_mean_enc[:,3]);\n",
    "axs[1].hist2d(delta_test[:,0],delta_test[:,1]);\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=5\n",
    "space_dims = [2,1]\n",
    "sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "y_test_oh = to_categorical(y_test,num_classes=10)\n",
    "\n",
    "z0mean = z_mean_enc[:,space_dims[0]].mean()\n",
    "z1mean = z_mean_enc[:,space_dims[1]].mean()\n",
    "z0_sigma = z_mean_enc[:,space_dims[0]].std()\n",
    "z1_sigma = z_mean_enc[:,space_dims[1]].std()\n",
    "# z2_sigma = x_test_lat_enc[:,2].std()\n",
    "\n",
    "fig,axs = plt.subplots(examples,4,figsize=(6,8))\n",
    "choices = np.random.choice(np.arange(len(y_test)),examples)\n",
    "# lat_vec_ = z_mean_enc[choices]\n",
    "lat_vec_ = np.concatenate([z_mean_enc[choices],y_class_enc[choices]],axis=1)\n",
    "print(lat_vec_.shape)\n",
    "dec_test = generator.predict(lat_vec_)\n",
    "\n",
    "# print(x_test_encoded[choices])\n",
    "\n",
    "for i,idx in enumerate(choices):\n",
    "    rec_true_im = x_test[idx].reshape(28,28)\n",
    "    in_im = sx_test[idx].reshape(28*2,28*2)\n",
    "    dec_im = dec_test[i].reshape(28*2,28*2)\n",
    "    \n",
    "    axs[i,0].imshow(rec_true_im)\n",
    "    axs[i,0].set_xticklabels([])\n",
    "    axs[i,0].set_yticklabels([])\n",
    "    \n",
    "    axs[i,1].imshow(in_im)\n",
    "    axs[i,1].set_xticklabels([])\n",
    "    axs[i,1].set_yticklabels([])\n",
    "    \n",
    "    axs[i,2].imshow(dec_im)\n",
    "    axs[i,2].set_xticklabels([])\n",
    "    axs[i,2].set_yticklabels([])\n",
    "#     axs[2,i].set_xlabel(\"class: {}\".format(str(np.argmax(y_class_enc[idx]))))\n",
    "    \n",
    "    axs[i,3].imshow(y_class_enc[idx].reshape(-1,1).T)\n",
    "    axs[i,3].set_xticklabels([])\n",
    "    axs[i,3].set_yticklabels([])\n",
    "    axs[i,3].set_xlabel(\"class: {}\".format(str(np.argmax(y_class_enc[idx]))))\n",
    "    \n",
    "plt.tight_layout()\n",
    "sns.despine(fig=fig)\n",
    "# plt.imshow(dec_test[2].reshape(28,28).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2\n",
    "bins = 11\n",
    "\n",
    "all_sweeps = np.empty((examples,bins,4*784))\n",
    "\n",
    "\n",
    "z0s = np.linspace(z0mean+(-2*z0_sigma),z0mean+(2*z0_sigma),num=bins)\n",
    "z1s = np.linspace(z1mean+(-2*z1_sigma),z1mean+(2*z0_sigma),num=bins)\n",
    "# z2s = np.linspace(-2*z2_sigma,2*z2_sigma,num=10)\n",
    "\n",
    "fig,axs = plt.subplots(examples,bins,figsize=(15,int(15*(examples/bins))))\n",
    "\n",
    "for j,vec in enumerate(lat_vec_):\n",
    "    lat_size = vec.shape[-1]\n",
    "    sweep = np.empty((bins,lat_size))\n",
    "    \n",
    "    for i,z in enumerate(z0s):\n",
    "        sweep[i] = vec\n",
    "        sweep[i,space_dims[0]] = z\n",
    "    \n",
    "    im_sweep = generator.predict(sweep)\n",
    "    all_sweeps[j]=im_sweep\n",
    "    \n",
    "for i in np.arange(examples):\n",
    "    for j in np.arange(bins):\n",
    "        axs[i,j].imshow(all_sweeps[i,j].reshape(56,56))\n",
    "        axs[i,j].set_xticklabels([])\n",
    "        axs[i,j].set_yticklabels([])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(examples,bins,figsize=(14,int(14*(examples/bins))))\n",
    "\n",
    "for j,vec in enumerate(lat_vec_):\n",
    "    lat_size = vec.shape[-1]\n",
    "    sweep = np.empty((bins,lat_size))\n",
    "    for i,z in enumerate(z1s):\n",
    "        sweep[i] = vec\n",
    "        sweep[i,space_dims[1]] = z\n",
    "    \n",
    "    im_sweep = generator.predict(sweep)\n",
    "    all_sweeps[j]=im_sweep\n",
    "    \n",
    "for i in np.arange(examples):\n",
    "    for j in np.arange(bins):\n",
    "        axs[i,j].imshow(all_sweeps[i,j].reshape(56,56))\n",
    "        axs[i,j].set_xticklabels([])\n",
    "        axs[i,j].set_yticklabels([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file='../z_mean_enc.npy',arr=z_mean_enc)\n",
    "np.save(file='../delta_test.npy',arr=delta_test)\n",
    "np.save(file='../y_class_enc.npy',arr=y_class_enc)\n",
    "np.save(file='../y_test_oh.npy',arr=y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "dxs = delta_test[:,0]\n",
    "dys = delta_test[:,1]\n",
    "\n",
    "g = sns.jointplot(z_mean_enc[:,2],dxs-14,kind='reg')\n",
    "g.set_axis_labels(xlabel='z_2',ylabel='dx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(z_mean_enc[:,0],dys-14,kind='reg')\n",
    "g.set_axis_labels(xlabel='lat_z2',ylabel='dy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z_mean_enc[:,2],z_mean_enc[:,0],c=dxs-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dx in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z_0}$\")\n",
    "plt.ylabel(r\"$\\hat{Z_1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z_mean_enc[:,2],z_mean_enc[:,1],c=dys-14)\n",
    "plt.colorbar()\n",
    "plt.title(r\"dy in $\\hat{Z}$\")\n",
    "plt.xlabel(r\"$\\hat{Z_0}$\")\n",
    "plt.ylabel(r\"$\\hat{Z_1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z_mean_enc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tandem_vae.sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "tandem_vae.save_weights('../logs/fashion_mnist_0905_080017/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "load_test = load_model('../logs/fashion_mnist_0905_080017/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(dxs-14,dys-14,c=z_mean_enc[:,1],)\n",
    "plt.xlabel('z_0')\n",
    "plt.ylabel('z_1')\n",
    "plt.title('Latent Variable by y-shift (dy)')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import Isomap\n",
    "\n",
    "# iso = Isomap(n_neighbors=20,n_components=1)\n",
    "# lat_enc_iso = iso.fit_transform(X=x_test_lat_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_enc_iso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(lat_enc_iso),dxs-14,c=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(lat_enc_iso),dys-14,c=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x_test_loc_enc[:, 0], x_test_loc_enc[:, 1],\n",
    "            c=y_test,alpha=0.5\n",
    "           )\n",
    "plt.colorbar()\n",
    "plt.scatter(x=x_test_loc_enc[choices][:,0],y=x_test_loc_enc[choices][:,1],marker='+',\n",
    "            s=20**2,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bqplot.pyplot as bqplt\n",
    "from bqplot import Tooltip\n",
    "import pandas as pd\n",
    "\n",
    "recs = []\n",
    "for i,cid in enumerate(y_test):\n",
    "    recs.append(dict(\n",
    "        loc_z=x_test_loc_enc[i],\n",
    "        loc_z0=x_test_loc_enc[i][0],\n",
    "        loc_z1=x_test_loc_enc[i][1],\n",
    "        id_z=x_test_encoded[i],\n",
    "        id_z0=x_test_encoded[i][0],\n",
    "        id_z1=x_test_encoded[i][1],\n",
    "        class_id=cid,\n",
    "        dx=delta_test[i][0],\n",
    "        dy=delta_test[i][1]\n",
    "    ))\n",
    "enc_df = pd.DataFrame.from_records(recs)\n",
    "enc_df.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df.to_pickle('./tandem_encoder_df.pk')\n",
    "np.save('./sx_test.npy',sx_test)\n",
    "np.save('./dec_test.npy',dec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqplt.figure(title='Autoencoder Latent Space')\n",
    "# def_tt = Tooltip(fields=['x', 'y'], formats=['', '.2f'])\n",
    "# bqplt.scatter(enc_df.loc_z0.values,enc_df.loc_z1.values)\n",
    "# # plt.colorbar()\n",
    "# bqplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
