{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrupted labels are a useful way to measure a networks generalization potential\n",
    "- https://arxiv.org/pdf/1611.03530.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm as tqdm\n",
    "# from tqdm.autonotebook import tqdm as autotqdm\n",
    "\n",
    "import brainscore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader,upsample_dataset\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.plot import enc_dec_samples\n",
    "from src.models import GResNet,EDense,EConvNet\n",
    "from src.test_models.infoduplex import INFODCDuplex\n",
    "from src.test_models.dcduplex import DCDuplex\n",
    "from src.test_models.drduplex import DRDuplex\n",
    "from src.published_models.dcgan import DCGAN\n",
    "from src.config import get_config\n",
    "from src.trainer import Trainer\n",
    "from src.utils import prepare_dirs_and_logger\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import adadelta\n",
    "\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config,_ = get_config()\n",
    "# Boilerplate\n",
    "setattr(config, 'proj_root', '/home/elijahc/projects/vae')\n",
    "setattr(config, 'log_dir', '/home/elijahc/projects/vae/logs')\n",
    "setattr(config, 'dev_mode',False)\n",
    "setattr(config, 'seed', 7)\n",
    "setattr(config, 'project','vae')\n",
    "# setattr(config, 'ecc_max',4.8/8.0)\n",
    "setattr(config, 'bg_noise',0.0)\n",
    "# setattr(config, 'contrast_level',0.3)\n",
    "# setattr(config, 'rot_max',90.0/360.0)\n",
    "setattr(config, 'rot_max',0)\n",
    "\n",
    "# Architecture Params\n",
    "setattr(config, 'enc_layers', [3000,2000,500])\n",
    "setattr(config, 'enc_arch', 'feedforward')\n",
    "\n",
    "# setattr(config, 'enc_layers', [3000,2000,500])\n",
    "# setattr(config, 'enc_arch', 'resnet')\n",
    "\n",
    "setattr(config, 'dec_blocks', [4,2,1])\n",
    "setattr(config, 'z_dim', 50)\n",
    "setattr(config, 'y_dim', 20)\n",
    "\n",
    "# Training Params\n",
    "setattr(config, 'batch_size', 512)\n",
    "setattr(config, 'dataset', 'fashion_mnist')\n",
    "setattr(config, 'epochs',1200)\n",
    "setattr(config, 'monitor', None)\n",
    "# setattr(config, 'lr', 10)\n",
    "# setattr(config, 'min_delta', 0.25)\n",
    "# setattr(config, 'monitor', 'val_loss')\n",
    "setattr(config, 'optimizer', 'nadam')\n",
    "setattr(config, 'label_corruption',0.0)\n",
    "\n",
    "# if config.ecc_max == 0.:\n",
    "#     translation_amt = None\n",
    "# else:\n",
    "#     translation_amt = config.ecc_max\n",
    "\n",
    "# if config.rot_max == 0.:\n",
    "#     rot_max = None\n",
    "# else:\n",
    "#     rot_max = config.rot_max\n",
    "    \n",
    "# if config.bg_noise == 0.:\n",
    "#     bg_noise = None\n",
    "# else:\n",
    "#     bg_noise = config.bg_noise\n",
    "\n",
    "# Loss Weights\n",
    "setattr(config, 'xcov', 0)\n",
    "setattr(config, 'recon', 1)\n",
    "setattr(config, 'xent', 20)\n",
    "# setattr(config,'model_dir','/home/elijahc/projects/vae/models/2019-05-25/recon_{}_ecc_{}/label_corruption_{}'.format(config.recon,config.ecc_max,config.label_corruption))\n",
    "setattr(config,'model_dir','/home/elijahc/projects/vae/models/2019-08-13/xent_{}_recon_{}/stim_var_{}'.format(config.xent,config.recon,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajajDataLoader(object):\n",
    "    def __init__(self,fp='/home/elijahc/projects/vae/data/dicarlo_images/',flatten=False):\n",
    "        self.fp = fp\n",
    "        self.stimulus_set = pd.read_csv(os.path.join(self.fp,'stimulus_set.csv'))\n",
    "        self.num_classes = len(self.stimulus_set.object_name.drop_duplicates().values)\n",
    "        self.sm_images = np.load(os.path.join(self.fp,'sm_imgs_56x56.npy'))\n",
    "        num_images = self.sm_images.shape[0]\n",
    "\n",
    "        if flatten:\n",
    "            self.x_all = self.sm_images.reshape(num_images,np.prod(self.sm_images.shape[1:]))\n",
    "            self.input_shape = (np.prod(self.sm_images.shape[1:]),)\n",
    "        else:\n",
    "            self.input_shape = self.sm_images.shape[1:]+(1,)\n",
    "            self.x_all = self.sm_images.reshape(num_images,*self.input_shape)\n",
    "            \n",
    "#         lo_hi_var_idxs = self.stimulus_set.variation!=3\n",
    "#         med_var_idxs = self.stimulus_set.variation<=3\n",
    "#         self.x_train = self.x_all[lo_hi_var_idxs]\n",
    "        self.x_train = self.x_all\n",
    "#         self.x_test = self.x_all[med_var_idxs]\n",
    "        \n",
    "        y_label_encoder = LabelEncoder()\n",
    "        self.y_train_labels = self.stimulus_set.object_name.values\n",
    "#         self.y_train_labels = self.stimulus_set.category_name.values[lo_hi_var_idxs]\n",
    "#         self.y_test_labels = self.stimulus_set.category_name.values[med_var_idxs]\n",
    "        \n",
    "        self.y_train = y_label_encoder.fit_transform(self.y_train_labels)\n",
    "        self.y_train_oh = to_categorical(self.y_train)\n",
    "        \n",
    "#         self.y_test = y_label_encoder.fit_transform(self.y_test_labels)\n",
    "#         self.y_test_oh = to_categorical(self.y_test)\n",
    "    def training_data(self):\n",
    "        return (self.x_train,self.y_train_oh)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = MajajDataLoader()\n",
    "mod = DRDuplex(img_shape=(56,56,1),\n",
    "               num_classes=DL.num_classes,\n",
    "               recon=config.recon,\n",
    "               xent=config.xent,\n",
    "               kernel_regularization=0.00005,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "model_input (InputLayer)        (None, 56, 56, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (Model)                 (None, 70)           16448570    model_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Generator (Model)               (None, 56, 56, 1)    168129      Encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Classifier (Model)              (None, 64)           16443899    model_input[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 16,629,563\n",
      "Trainable params: 16,629,051\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up...\n",
      "/home/elijahc/projects/vae/logs/0905_135744_fashion_mnist  does not exist...\n",
      "creating...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'bg_noise': 0.0,\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'dev_mode': False,\n",
       " 'enc_arch': 'feedforward',\n",
       " 'enc_layers': [3000, 2000, 500],\n",
       " 'epochs': 1200,\n",
       " 'label_corruption': 0.0,\n",
       " 'log_dir': '/home/elijahc/projects/vae/logs',\n",
       " 'log_level': 'INFO',\n",
       " 'model_dir': '/home/elijahc/projects/vae/models/2019-08-13/xent_20_recon_1/stim_var_0',\n",
       " 'model_name': '0905_135744_fashion_mnist',\n",
       " 'monitor': None,\n",
       " 'optimizer': 'nadam',\n",
       " 'proj_root': '/home/elijahc/projects/vae',\n",
       " 'project': 'vae',\n",
       " 'recon': 1,\n",
       " 'rot_max': 0,\n",
       " 'run_dir': '/home/elijahc/projects/vae/logs/0905_135744_fashion_mnist',\n",
       " 'seed': 7,\n",
       " 'xcov': 0,\n",
       " 'xent': 20,\n",
       " 'y_dim': 20,\n",
       " 'z_dim': 50}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "if not config.dev_mode:\n",
    "    print('setting up...')\n",
    "    prepare_dirs_and_logger(config)\n",
    "    \n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec(model,DL):\n",
    "    rand_im = np.random.randint(0,DL.x_train.shape[0])\n",
    "    im = DL.x_train[rand_im]\n",
    "\n",
    "    latent_rep = model.E.predict(im.reshape(1,56,56,1))\n",
    "\n",
    "    fig,axs = plt.subplots(1,2,figsize=(8,4))\n",
    "\n",
    "    axs[0].imshow(im.reshape(56,56),cmap='gray')\n",
    "    axs[1].imshow(model.G.predict(latent_rep).reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch        loss        G_loss      C_loss      C_acc       val_C_acc   \n",
      "0:           361.1706    263.9873    4.1687      0.0191      0.0191      \n",
      "1:           345.5903    248.4095    4.1686      0.0218      0.0104      \n",
      "2:           324.6677    227.537     4.1662      0.0183      0.0139      \n",
      "3:           322.1712    225.0545    4.1655      0.017       0.0069      \n",
      "4:           317.2821    220.2385    4.1619      0.0214      0.0191      \n",
      "5:           313.0805    216.1463    4.1565      0.0218      0.0156      \n",
      "6:           309.1433    212.2217    4.156       0.0189      0.0156      \n",
      "7:           303.1259    206.2934    4.1516      0.0216      0.0174      \n",
      "8:           297.9636    201.1473    4.1508      0.0226      0.0139      \n",
      "9:           294.5984    197.8314    4.1484      0.0222      0.0104      \n",
      "10:          291.5673    194.8375    4.1467      0.0241      0.0226      \n",
      "11:          288.038     191.3509    4.1446      0.0249      0.0156      \n",
      "12:          285.3067    188.7275    4.1393      0.028       0.0174      \n",
      "13:          289.1586    192.5581    4.1404      0.026       0.0191      \n",
      "14:          284.7203    188.2105    4.1359      0.0247      0.0139      \n",
      "15:          283.0191    186.5771    4.1326      0.0284      0.0208      \n",
      "16:          282.9899    186.645     4.1279      0.0287      0.0208      \n",
      "17:          282.4669    186.1067    4.1287      0.0314      0.0156      \n",
      "18:          279.8173    183.5986    4.1217      0.0311      0.0191      \n",
      "19:          280.9633    184.7519    4.1214      0.0282      0.0087      \n",
      "20:          277.8882    181.7392    4.1184      0.0295      0.0208      \n",
      "21:          278.8725    182.7452    4.1174      0.0293      0.026       \n",
      "22:          276.5054    180.5416    4.1093      0.0322      0.0243      \n",
      "23:          276.4845    180.5512    4.1079      0.0307      0.0243      \n",
      "24:          276.4737    180.5761    4.1062      0.0297      0.0174      \n",
      "25:          273.7939    177.9763    4.1023      0.0353      0.0226      \n",
      "26:          270.7903    175.0937    4.0963      0.0312      0.0104      \n",
      "27:          269.539     173.9637    4.0903      0.0374      0.0191      \n",
      "28:          263.6169    168.104     4.0873      0.0341      0.0191      \n",
      "29:          259.3356    163.8305    4.087       0.0378      0.0156      \n",
      "30:          257.7659    162.4236    4.0789      0.0388      0.0226      \n",
      "31:          252.9103    157.6941    4.0727      0.0413      0.0243      \n",
      "32:          251.3069    156.2081    4.0669      0.0407      0.0208      \n",
      "33:          253.1611    158.0596    4.0672      0.0394      0.0278      \n",
      "34:          248.6222    153.6178    4.0624      0.0399      0.0226      \n",
      "35:          245.3488    150.5424    4.0526      0.0426      0.0208      \n",
      "36:          242.4559    147.8184    4.0442      0.0465      0.0243      \n",
      "37:          242.0292    147.4892    4.0395      0.0407      0.0191      \n",
      "38:          239.4832    145.0072    4.0363      0.0446      0.0156      \n",
      "39:          236.6383    142.3733    4.0259      0.0473      0.0243      \n",
      "40:          236.9036    142.6623    4.0248      0.0475      0.0174      \n",
      "41:          233.2777    139.285     4.0125      0.0505      0.0174      \n",
      "42:          234.736     140.748     4.0123      0.0484      0.0191      \n",
      "43:          228.3988    134.6923    3.9983      0.053       0.0139      \n",
      "44:          223.8098    130.2335    3.9919      0.05        0.0208      \n",
      "45:          222.8361    129.3812    3.9859      0.0552      0.0226      \n",
      "46:          218.9503    125.6732    3.9771      0.0521      0.0208      \n",
      "47:          216.6208    123.5659    3.9661      0.0525      0.0208      \n",
      "48:          208.0545    115.081     3.9621      0.0575      0.0191      \n",
      "49:          202.7118    109.6166    3.9683      0.0565      0.0243      \n",
      "50:          192.6803    99.7631     3.9595      0.0579      0.0226      \n",
      "51:          183.8892    91.361      3.9401      0.0664      0.0208      \n",
      "52:          171.0367    78.7456     3.9283      0.0675      0.0278      \n",
      "53:          155.5659    63.2955     3.9274      0.0617      0.0278      \n",
      "54:          151.3966    58.765      3.9455      0.059       0.0156      \n",
      "55:          140.8398    48.8097     3.9155      0.0673      0.0312      \n",
      "56:          138.9526    47.1174     3.9059      0.0673      0.0208      \n",
      "57:          135.912     44.2883     3.8954      0.0712      0.0243      \n",
      "58:          135.6237    44.3252     3.8792      0.0685      0.026       \n",
      "59:          133.8084    42.524      3.8786      0.0667      0.0278      \n",
      "60:          131.9814    41.1628     3.8554      0.0772      0.0243      \n",
      "61:          132.7151    42.0041     3.8501      0.0762      0.0208      \n",
      "62:          132.4156    41.962      3.8373      0.0816      0.0104      \n",
      "63:          131.0401    40.9256     3.8204      0.081       0.0226      \n",
      "64:          131.3411    40.7369     3.845       0.0837      0.0243      \n",
      "65:          132.5011    42.2037     3.8297      0.0802      0.0295      \n",
      "66:          129.3408    39.6653     3.7987      0.0928      0.0208      \n",
      "67:          130.4215    40.5225     3.8099      0.0837      0.0191      \n",
      "68:          130.3419    40.6404     3.8001      0.0849      0.0208      \n",
      "69:          128.6011    39.316      3.7794      0.0965      0.0208      \n",
      "70:          128.254     39.3559     3.7601      0.0963      0.033       \n",
      "71:          127.8468    39.0458     3.7553      0.0938      0.0226      \n",
      "72:          126.2653    37.9795     3.7296      0.1019      0.0243      \n",
      "73:          128.3575    39.7975     3.7433      0.0968      0.0295      \n",
      "74:          127.6606    39.2878     3.734       0.1028      0.0295      \n",
      "75:          127.3971    39.3441     3.7181      0.1123      0.0382      \n",
      "76:          124.7658    37.09       3.6993      0.1065      0.0226      \n",
      "77:          126.459     38.5165     3.7127      0.102       0.0191      \n",
      "78:          125.8736    38.4058     3.689       0.1113      0.0174      \n",
      "79:          131.5609    40.8949     3.849       0.0926      0.0243      \n",
      "80:          124.4368    37.332      3.6709      0.1134      0.0208      \n",
      "81:          123.7454    36.8217     3.6619      0.1115      0.0243      \n",
      "82:          125.6378    38.4982     3.6728      0.11        0.0243      \n",
      "83:          124.3144    37.7728     3.6429      0.1258      0.0208      \n",
      "84:          124.4695    37.5824     3.6602      0.1128      0.0208      \n",
      "85:          121.9752    36.3992     3.5947      0.1319      0.0278      \n",
      "86:          125.3744    38.6534     3.652       0.1127      0.033       \n",
      "87:          121.4083    36.5913     3.5568      0.1377      0.0191      \n",
      "88:          123.3937    37.7694     3.5972      0.1238      0.033       \n",
      "89:          120.9308    36.0102     3.562       0.1343      0.0278      \n",
      "90:          121.5222    36.2594     3.5792      0.1265      0.0295      \n",
      "91:          123.4307    37.6318     3.606       0.1206      0.026       \n",
      "92:          122.808     37.879      3.5625      0.1352      0.0278      \n",
      "93:          121.3799    37.4093     3.5146      0.146       0.0295      \n",
      "94:          121.227     37.4191     3.5065      0.1468      0.0278      \n",
      "95:          119.0821    35.8737     3.4765      0.1528      0.0365      \n",
      "96:          122.1328    37.9878     3.5233      0.1458      0.0226      \n",
      "97:          119.7363    36.7702     3.4644      0.1501      0.026       \n",
      "98:          121.1379    36.2249     3.5617      0.146       0.0295      \n",
      "99:          119.19      35.9935     3.4759      0.1522      0.0156      \n",
      "100:         121.4529    37.1455     3.5315      0.1476      0.0208      \n",
      "101:         116.9978    35.3743     3.3973      0.1696      0.0052      \n",
      "102:         117.1168    35.4262     3.4006      0.1753      0.0295      \n",
      "103:         120.6897    38.3732     3.4318      0.1624      0.0191      \n",
      "104:         122.6442    36.9664     3.5999      0.1495      0.0295      \n",
      "105:         117.6493    35.8275     3.4071      0.1696      0.0191      \n",
      "106:         117.7116    35.6959     3.4168      0.1688      0.0295      \n",
      "107:         115.0318    34.7662     3.3292      0.1823      0.033       \n",
      "108:         120.3705    36.8696     3.491       0.1611      0.0278      \n",
      "109:         114.2969    34.8651     3.2875      0.1998      0.0208      \n",
      "110:         115.5674    35.7109     3.3087      0.1869      0.0295      \n",
      "111:         115.0281    35.5385     3.2903      0.1998      0.0243      \n",
      "112:         114.7921    35.6174     3.2745      0.1971      0.026       \n",
      "113:         114.918     35.5759     3.2828      0.1954      0.033       \n",
      "114:         115.9525    36.4535     3.2906      0.2008      0.0174      \n",
      "115:         120.6851    38.1282     3.4434      0.168       0.0278      \n",
      "116:         112.6362    35.2503     3.1848      0.2211      0.0278      \n",
      "117:         114.2899    35.7221     3.2439      0.2062      0.0312      \n",
      "118:         113.2073    35.0634     3.2226      0.2133      0.0208      \n",
      "119:         112.1993    35.3039     3.1601      0.2297      0.0365      \n",
      "120:         112.3383    35.1586     3.1742      0.2215      0.0278      \n",
      "121:         114.3638    36.625      3.2021      0.2155      0.0243      \n",
      "122:         109.0162    34.2864     3.0516      0.2469      0.0347      \n",
      "123:         110.4449    34.9513     3.0897      0.2396      0.033       \n",
      "124:         111.8643    34.9857     3.1588      0.2157      0.0191      \n",
      "125:         120.6273    38.4092     3.4257      0.1962      0.0365      \n",
      "126:         110.3292    34.2973     3.1163      0.2272      0.0243      \n",
      "127:         109.1331    34.7113     3.0357      0.255       0.0208      \n",
      "128:         110.749     34.8249     3.1107      0.2353      0.0139      \n",
      "129:         113.7312    38.056      3.0982      0.2508      0.0312      \n",
      "130:         107.6347    33.9219     3.0         0.2583      0.0243      \n",
      "131:         108.7421    34.5892     3.0219      0.2477      0.0295      \n",
      "132:         104.8475    33.7182     2.8706      0.2784      0.0208      \n",
      "133:         129.1035    40.2381     3.7573      0.1458      0.033       \n",
      "134:         105.8712    33.6053     2.9272      0.2917      0.033       \n",
      "135:         109.217     34.5726     3.046       0.2589      0.0226      \n",
      "136:         106.8167    34.2871     2.9401      0.2676      0.033       \n",
      "137:         103.4189    33.9695     2.786       0.3086      0.0174      \n",
      "138:         128.7198    41.3694     3.6809      0.1674      0.033       \n",
      "139:         106.681     34.327      2.931       0.2838      0.033       \n",
      "140:         102.3957    33.1816     2.7738      0.3198      0.0347      \n",
      "141:         105.3206    33.7278     2.8927      0.2787      0.0347      \n",
      "142:         118.3977    37.7864     3.3435      0.2157      0.0312      \n",
      "143:         102.4524    32.9985     2.7854      0.3083      0.0243      \n",
      "144:         100.3422    33.5741     2.651       0.3534      0.033       \n",
      "145:         103.053     33.6448     2.7829      0.3056      0.0174      \n",
      "146:         102.6816    33.694      2.7617      0.3084      0.026       \n",
      "147:         100.5219    33.5678     2.6599      0.3245      0.0365      \n",
      "148:         100.4635    33.3978     2.6653      0.3287      0.0174      \n",
      "149:         99.512      33.2968     2.6226      0.3507      0.033       \n",
      "150:         105.0898    34.2011     2.8562      0.2944      0.0382      \n",
      "151:         97.3623     33.1411     2.5226      0.3648      0.0295      \n",
      "152:         101.8651    34.4815     2.6806      0.3497      0.0278      \n",
      "153:         105.6846    35.1483     2.838       0.2851      0.0278      \n",
      "154:         95.6538     33.0234     2.4426      0.4024      0.0365      \n",
      "155:         96.744      33.2448     2.4859      0.3673      0.0382      \n",
      "156:         99.9024     34.5929     2.5762      0.3625      0.0521      \n",
      "157:         97.3772     33.7226     2.4933      0.3576      0.0365      \n",
      "158:         100.5629    33.807      2.6481      0.3399      0.0399      \n",
      "159:         93.3337     32.7732     2.3382      0.4037      0.026       \n",
      "160:         97.4871     34.02       2.4833      0.37        0.0312      \n",
      "161:         97.1033     33.9829     2.4658      0.3796      0.0312      \n",
      "162:         95.7675     33.5674     2.4196      0.3945      0.0278      \n",
      "163:         98.1398     34.1727     2.5077      0.3819      0.0434      \n",
      "164:         89.8643     32.1982     2.1925      0.4537      0.033       \n",
      "165:         95.0727     33.105      2.4074      0.3889      0.0295      \n",
      "166:         92.8024     33.1        2.2939      0.4284      0.0347      \n",
      "167:         94.9359     33.6939     2.3707      0.4244      0.0278      \n",
      "168:         127.0364    41.468      3.5868      0.1883      0.033       \n",
      "169:         96.8939     35.1118     2.3972      0.4275      0.026       \n",
      "170:         92.4108     32.9605     2.2804      0.4286      0.0382      \n",
      "171:         87.9076     32.0973     2.0982      0.4813      0.0399      \n",
      "172:         89.2218     32.7768     2.1298      0.4622      0.0417      \n",
      "173:         84.5621     31.881      1.9414      0.5154      0.0226      \n",
      "174:         98.2211     33.8583     2.5252      0.3945      0.0243      \n",
      "175:         86.5273     32.4621     2.0101      0.5008      0.0451      \n",
      "176:         86.9552     32.4115     2.0339      0.4736      0.0243      \n",
      "177:         86.529      32.9358     1.9861      0.5075      0.0382      \n",
      "178:         88.7254     33.3502     2.075       0.4734      0.026       \n",
      "179:         82.7792     32.1783     1.8361      0.5297      0.0365      \n",
      "180:         87.5013     32.9621     2.0328      0.4742      0.0399      \n",
      "181:         80.8583     31.6758     1.7647      0.5548      0.0399      \n",
      "182:         79.6046     31.7196     1.6996      0.5768      0.033       \n",
      "183:         83.4821     33.3731     1.8106      0.5455      0.0382      \n",
      "184:         83.5936     32.4171     1.8637      0.5231      0.0399      \n",
      "185:         81.8295     32.4566     1.7733      0.5449      0.0382      \n",
      "186:         97.8329     36.5039     2.3709      0.3771      0.0382      \n",
      "187:         80.4005     32.4451     1.702       0.587       0.0451      \n",
      "188:         81.6658     32.841      1.7453      0.5621      0.033       \n",
      "189:         85.414      33.4505     1.902       0.5305      0.0469      \n",
      "190:         84.3908     33.032      1.8715      0.5091      0.0486      \n",
      "191:         74.445      31.6898     1.4411      0.6503      0.0556      \n",
      "192:         79.2789     31.8651     1.6738      0.57        0.0382      \n",
      "193:         78.0094     32.2241     1.5921      0.5995      0.0312      \n",
      "194:         98.0551     35.6382     2.4235      0.3731      0.0434      \n",
      "195:         75.1308     31.7222     1.4728      0.6512      0.0417      \n",
      "196:         73.4577     31.5408     1.398       0.6524      0.0503      \n",
      "197:         71.7681     31.7327     1.3037      0.6981      0.0347      \n",
      "198:         94.1958     35.0908     2.2569      0.4232      0.0417      \n",
      "199:         80.9212     33.0177     1.6966      0.5604      0.0382      \n",
      "200:         70.8883     31.2289     1.2842      0.6875      0.0399      \n",
      "201:         82.9361     32.8188     1.8068      0.5413      0.0417      \n",
      "202:         71.5213     31.3656     1.3085      0.6717      0.0382      \n",
      "203:         67.3402     31.2073     1.1072      0.7483      0.0417      \n",
      "204:         66.4655     30.9056     1.0784      0.7598      0.0365      \n",
      "205:         71.7205     31.7702     1.2977      0.6698      0.0573      \n",
      "206:         69.7582     31.7936     1.1982      0.7031      0.033       \n",
      "207:         75.8621     33.1922     1.4332      0.6275      0.0365      \n",
      "208:         70.4012     31.2681     1.2561      0.6767      0.0486      \n",
      "209:         98.0856     35.4531     2.4308      0.4066      0.0486      \n",
      "210:         95.4201     35.6561     2.2871      0.4155      0.0503      \n",
      "211:         66.7713     31.0563     1.0845      0.7695      0.0451      \n",
      "212:         65.7601     30.9825     1.0374      0.7639      0.0451      \n",
      "213:         65.8091     31.0157     1.038       0.7647      0.0469      \n",
      "214:         65.2045     30.7977     1.0185      0.755       0.0538      \n",
      "215:         62.538      30.8112     0.8843      0.8063      0.0625      \n",
      "216:         69.001      31.1662     1.1895      0.7105      0.0608      \n",
      "217:         61.3699     30.5492     0.8386      0.8158      0.0469      \n",
      "218:         64.6928     31.178      0.9731      0.7695      0.0365      \n",
      "219:         67.6723     31.2072     1.1205      0.6983      0.0347      \n",
      "220:         60.7215     30.4493     0.8106      0.832       0.0417      \n",
      "221:         69.6485     31.8312     1.1877      0.6863      0.0469      \n",
      "222:         61.47       30.5991     0.8402      0.8154      0.0503      \n",
      "223:         58.6042     30.7285     0.6903      0.8598      0.0469      \n",
      "224:         101.7384    36.2624     2.57        0.4008      0.0226      \n",
      "225:         276.227     62.5901     9.9774      0.0619      0.0243      \n",
      "226:         399.4561    93.0823     14.6128     0.0201      0.0139      \n",
      "227:         388.1255    61.2492     15.6376     0.0216      0.0139      \n",
      "228:         352.3285    59.8946     13.9156     0.027       0.0156      \n",
      "229:         220.6947    49.8555     7.8363      0.0662      0.0226      \n",
      "230:         94.9839     35.6725     2.2601      0.434       0.0382      \n",
      "231:         79.8313     32.7905     1.6465      0.5839      0.0417      \n",
      "232:         72.8651     32.1043     1.3323      0.6846      0.0417      \n",
      "233:         70.2421     31.4683     1.2328      0.7097      0.0469      \n",
      "234:         68.9332     31.4794     1.1666      0.728       0.0399      \n",
      "235:         68.8129     31.2688     1.171       0.7166      0.0399      \n",
      "236:         67.8019     31.3438     1.1165      0.7357      0.0521      \n",
      "237:         68.2464     31.3938     1.1361      0.7313      0.0451      \n",
      "238:         60.8239     30.3688     0.8161      0.8196      0.059       \n",
      "239:         60.0577     30.6595     0.7631      0.8434      0.0434      \n",
      "240:         63.2583     30.8277     0.9146      0.7894      0.0747      \n",
      "241:         57.4115     29.7911     0.6739      0.8702      0.059       \n",
      "242:         57.8714     30.0227     0.6852      0.8648      0.0573      \n",
      "243:         60.5277     30.4939     0.7944      0.8167      0.0521      \n",
      "244:         57.9167     30.2853     0.6741      0.858       0.0469      \n",
      "245:         63.4295     30.3617     0.9458      0.7814      0.0608      \n",
      "246:         58.8984     29.9082     0.7418      0.8356      0.0608      \n",
      "247:         54.1881     29.6214     0.5205      0.9053      0.0608      \n",
      "248:         56.6915     29.9354     0.6299      0.8692      0.0538      \n",
      "249:         53.2767     29.7668     0.4675      0.9252      0.0608      \n",
      "250:         55.3992     29.6029     0.5817      0.8767      0.0538      \n",
      "251:         53.4369     29.7116     0.4781      0.9153      0.0434      \n",
      "252:         53.4137     29.3979     0.4925      0.9047      0.0556      \n",
      "253:         55.7127     29.744      0.5901      0.8665      0.0451      \n",
      "254:         52.6299     29.3067     0.4577      0.9155      0.0417      \n",
      "255:         52.0217     29.3358     0.4258      0.9284      0.0503      \n",
      "256:         54.0569     29.7722     0.5056      0.8981      0.0469      \n",
      "257:         166.0201    46.1834     5.2829      0.2126      0.0278      \n",
      "258:         111.2571    38.0213     2.9526      0.3675      0.0573      \n",
      "259:         67.0081     30.5418     1.114       0.7236      0.0521      \n",
      "260:         58.1542     29.9405     0.7012      0.8644      0.0521      \n",
      "261:         61.5247     30.321      0.8506      0.8042      0.059       \n",
      "262:         53.968      29.4413     0.5166      0.9138      0.0434      \n",
      "263:         54.0606     29.4046     0.523       0.8997      0.0365      \n",
      "264:         53.8246     29.4485     0.5089      0.9043      0.0521      \n",
      "265:         56.2291     29.8312     0.6099      0.8636      0.0608      \n",
      "266:         50.7593     28.9363     0.3811      0.9429      0.0608      \n",
      "267:         50.0219     28.8815     0.3469      0.9497      0.0521      \n",
      "268:         54.3057     29.7554     0.5174      0.885       0.0608      \n",
      "269:         49.5044     28.8235     0.3238      0.9525      0.0451      \n",
      "270:         49.8629     28.9993     0.3329      0.9485      0.0573      \n",
      "271:         50.9633     29.8803     0.3439      0.9458      0.0625      \n",
      "272:         50.0727     29.7881     0.3039      0.9562      0.059       \n",
      "273:         48.8028     29.3443     0.2626      0.9674      0.0538      \n",
      "274:         47.8022     28.5774     0.2509      0.9695      0.0538      \n",
      "275:         61.0861     30.2804     0.8299      0.7757      0.0521      \n",
      "276:         48.6168     28.9633     0.2721      0.9647      0.0625      \n",
      "277:         48.2393     29.0662     0.2481      0.9684      0.0556      \n",
      "278:         47.5236     29.0626     0.2125      0.9813      0.0503      \n",
      "279:         50.9697     29.0991     0.383       0.9225      0.0486      \n",
      "280:         47.3598     28.8757     0.2136      0.9769      0.0573      \n",
      "281:         46.8329     28.2693     0.2176      0.9759      0.059       \n",
      "282:         46.3246     28.5046     0.1804      0.9834      0.0486      \n",
      "283:         47.925      29.1878     0.2263      0.9697      0.0556      \n",
      "284:         46.3522     28.489      0.1826      0.9797      0.0486      \n",
      "285:         156.4312    41.5338     5.0341      0.3127      0.0347      \n",
      "286:         118.1974    41.5918     3.1192      0.2895      0.0295      \n",
      "287:         72.8068     31.6364     1.3473      0.6811      0.0469      \n",
      "288:         55.0278     29.3833     0.5709      0.8939      0.0417      \n",
      "289:         50.8606     28.8359     0.3898      0.9412      0.0608      \n",
      "290:         48.3701     28.4772     0.2832      0.9699      0.0556      \n",
      "291:         48.7072     29.1936     0.2642      0.9695      0.0538      \n",
      "292:         51.3776     29.2057     0.3971      0.918       0.059       \n",
      "293:         46.5096     28.1369     0.2071      0.9828      0.0503      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-200e4904c112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/vae/notebooks/src/test_models/drduplex.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, data_loader, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         history = self.combined.fit(X,y,epochs=epochs,batch_size=batch_size,\n\u001b[1;32m    124\u001b[0m                                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                                     **kwargs)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyterlab-gpu/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod.train(1000,DL,config.batch_size,validation_split=0.10,verbose=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAADvCAYAAADM3MywAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXusZmd13p8XQ7g4ZuzxZXwZe8Y3bHzDNxwRHCCqooATJUVyUaBqpTREoiBRFSlK1Urp9I9IUSJVlVBEVKURkCZKArRSYuKgGDCYmiAugtjgwePreDzjuw0Bh4vN7h9z5uN5f+d8a59v5sx39pjnJ1ne+7z72/u97j17PXut1YZhUAghhBA2nxdtdgVCCCGEcJA8lEMIIYSJkIdyCCGEMBHyUA4hhBAmQh7KIYQQwkTIQzmEEEKYCHkohxBCCBMhD+UQQghhIuShHEIIIUyEw34ot9Z+s7V2e2vt1tbaeRtZqRDCcsl6DmEatMMJs9la2yrpZkmvl3SVpN8ahuFtG1y3EMISyHoOYTq8+DB/d52kW4dheE7SF1trF63nR621BNoOYZ0Mw9CWdKmF13PWcgjrZ5G1fLgP5a2Snrb9VWbw1touSf+Vf//oRz96mJecFpWF4Uc/+tHcY3/4wx92ZY8//vhs+9vf/nZX9s///M/dfms/HtdXvvKVc88jSccff/xs+9RTT+3KTjzxxDXPybqSsWNZvt6yF71ovorCMp5nvdesjltP+bK58cYbl3m5cj3PW8sf+tCH1jzZS1/60m7f5zznNHnJS16y5u8k6ad+6qe6fa4z5wc/+MHca37ve9/r9p977rnZ9ve///259ZGkZ555Zu41/Txcn6y7r52xOe51ev7557sy3x/rrxe/+Me3e56H7XzZy14223722We7shNOOGHNc0r1+L7iFa/o9nn/8H32gdeP7aruS+xb1vflL3/5mteQpO9+97uz7eOOO64rYx28vx588MGu7L3vfa8W4XA15aclnWj7z/OAYRh2DcPQ/L/DvFYI4ehSrues5RCWx+G+KX9B0u+01o6T9BpJezauSkeXw30jqt4K+S92/mv6iSeemG1Xb8P+L7O18Dfc/fv3l8ceOHBgtn333Xd3Zddcc81s+8wzz+zKDveNdozDfYseezPeqPP+hHNY63nefOBa8bcMvkXzzcrfcP3tQ1r9dufHsszfGp966qmu7Dvf+c6a9ZZWv0WzDv6mxWO9LZxf1ZsV7wm8n/h52U6Hb3r+5s66862VbfE6sD7+5vzTP/3TXZm/ebLuPl7S6nZv2bJltl21k/WpLCjsE85Nnycs8/OwjG/cDu+pi3JYD+VhGJ5qrX1I0m2SfijpN46oFiGETSPrOYTpcLhvyhqG4Y8k/dEG1iWEsElkPYcwDQ77oTwlqg8EKjMlzSlu7qG54lvf+la37x9y0OxMc3FlCnIz1mOPPdaVnXLKKXOP/ad/+qeujPX1OvHjlXvuuWe2TXMT9/nxiOMfk0mrTZPOIh9dLcJ6z3sk1zwct8GfBNxs6GuHplA3X9OkyvXg5sbqg0mpnps+53nN6mMp3hNINcfdnD/28VY1p2gare4f1e8qGYGyAT9k8vsAy3yMxj4Y83vE2Ed0fo/lNX0M2bdjH5BV13TYt9W9hXPK21aN0XpIRK8QQghhIuShHEIIIUyEPJRDCCGEiXBMasq02bu2VLkTEGrBrhc9+uijXRndKly/obZVaV0MKkCdxXEXKEJ3Ap7X9yt3rj17eu+X0047rdt39y5qyKz7ZZddNtumK8m864+xyDcCR3KdiirIwU+y3uz6q6+Hk046qTvOv39gf1Hjc72Q84t6r7vmVO421Lj5fYjrgwyUwXnsWiv1VD9PdQ+Q+rVd6adS3ye8v/k+686+9vryPLzXsM8cHxe6I1UBjzhG1X2JurHXl/0+5n5WXdP7mnPRx4XX4Jh5nTh+i5I35RBCCGEi5KEcQgghTIRjwnxNUwvNWm62oasQzSluFmE0mieffHK2Tfckmov9M/yxT+DdtMHzeBzZnTt3dmXVZ/eErhpeJ5qCKnMYTWCV2Yi/feSRR2bb27dv78rcpLRIHOpFzNdVTGO6erFPKjM0j61c536SIoXNi6hFM6XLRJUbotT3NU2EjO/u64Frw9c9XYVoWvYx4xynKdTrW5kwCd12vB84N2ky9/pWkcGqCGOE85bH+v2EY+Rt4XiOxaV2eF7vT96HqjXH8fX9RaIQVnGyea+rYmFX9+l11eOIfh1CCCGEDSMP5RBCCGEi5KEcQgghTITJaspuw6eNnrqx6w/MAEO3J9cjqO8+/fSPU8oyC5Nrv7wm9YWzzjqr2/fr0K3Iz1NlweE+dRS223Uf6s2uz1BXp67i7i1VRh+pb8vXv/71rszrQH2GLjQnn3zybJtjz3a6qxo1KtfiWFe6kHl/UtPjmPkc4jh4v1cuFtKxrz/P0385DlXIRv8OQerHifOWmqlnX2Nf+rwYy57kvx071rVDzmMf+8r1RurXOuc45xv310t1r2FZlU2JZX6eKjQlf8vx45qsNFyfa9SteR/3OvD+VoUe5b3Pf8t1Xs2hI3WTzJtyCCGEMBHyUA4hhBAmQh7KIYQQwkSYjKZcpWWjjkht00NBuq/xWvuuNdEvuArNV/k2UhOlj7NrJ2yL60lj/oquedCPj3q0t7sKe1j5VrLu1G6oqxw4cGC2XWkw1J0eeOCBbt91KPZ7lXKObam0X84LPw91KI6Da4f81sCvyfGkNuf7x6K+7O3zeVyFQaR+Sh3P+5q6YuUnz/Va+R5T114k1V7lp+xa55gfvI991QdSvUarVJf8nevI/NaG/edtqe5LvEblG13Fl2D9FqGKRcF1xXb6fYHt9HtflfJRqkOYLkrelEMIIYSJkIdyCCGEMBE21XztJh2aKd28wqwulanWTdlSHSKRpkc3z9KUQbOzmz2YQYomkrPPPlvz8D6gqYWZW7wf2F80pVWZsyo3BZrZvN3sA553njlT6k3mVRYXqR+jKkSoVJuVvC1sZ/U7HstxqDIAVWH92LdVSMljAZ+P3p90WfR5QZMlXaJ8XdFlhuetTP6V+w9/565X1TqS+rnB8/p9iXOIJmmvH+9Dlfm/ciuqXLSkvi2c0/v27ev2/Vysn5uLeQ1KWj6eNDOzT/yewX6v7hmVyyfnENc96z/vWPb7tm3bun1f26eeeurcc66HvCmHEEIIEyEP5RBCCGEi5KEcQgghTISla8rzdGTqlR7ykloS3VtcR6a+y3CKrpXcd999XZlrEbwGtQjXKqh3PProo5qHh5CU+j6g1kW3Hf8t3ZyoV5522mmzbfbt1q1b55Z5v0t1+kPq91W6N+/3sZB13paxdJGV+0MVtq/SjTl+PNb7j2NffSdBvO7UxY4F5qVu5PcEvk9NmXPc+48aJPva518VopbX5Dz2eUI9sNIyOY9dj6Y2zf0qvSDb4sdynfvcrEJ5Sv18pJ7L+6Tfc6vwurwm75O8Hzuc8962qr8qzZ3nYd15rJdzvVbujZy3Xj/Ot0XJm3IIIYQwEfJQDiGEECZCHsohhBDCRFi6pjwvJWMVgo2+ZNRgXBfwdG7S6nByroHce++9XdlVV10126YWQp9E12RcY5Sk3bt3d/uu09I/cPv27bPtPXv2dGV79+7t9l33oebC/nMf0kqvHOtb74dK5+F1Kp9E6mLUs/y3VfhEqdeXqP95uExqX/xOYZ7P7Vr183ZXvrPsL46Dn+dYD7P5+OOPz7bpG+prkN8scH36GPI8XJPuP1vpihxPznHXElmfKlQl8e8z6NtbrZ2xbw+qtnBez6uP1N8bTz/99K6MdfDrcBwWCSPp9xeep/pehOPp9zeWcd/Hl/e3KuRqdWyVkpK/rWIVrIe8KYcQQggTIQ/lEEIIYSKMmq9bay+RdKukSyW9cxiGj7bWTpH0p5JOkHTLMAy71ntBNwn4duUWQNcbmmy8vAq5JvVmcboFuAmTn8BXYS1p3jz33HO7fS+nWfeee+6ZbdOkRNPo/v37Z9tnnnlmV0ZXjoceemi2zTClvr9jx46ujK5WW7ZsmW2PhQ50kw773c1PLKvCHtLkxWPdnFiZn2gy5/h627zNa12zyhTk9eWcpnnd21mF+9tINno9H8LbRvOmrx3KLDzW+4/9zr72+VaNw5jbThUekxKN15dzqqIy1bIPuO/9wPpUv2O7XTpjfWi297XNNehjyPpU7o5j/VW1bb2Zsngs59CYXDevPjyuCts7JkeMsZ435eck3Sjpf9jfflvSnwzDcL2k17bWLjmiWoQQlkXWcwgTZvShPBzkAP58vaSbVrZvkvSGja5YCGHjyXoOYdocrqZ8/DAMh+ywz0jaygNaa7taa4P/d9i1DCEcTcr1nLUcwvI4XJeoZ1trLxuG4XuStkhaFUttRZfa5X9rrQ3zQvNVujHLqEu5mwW1QuqDrkFSc3GXC2oG1Kortx13xZF6LYVpHF23uP/++7uyiy++uNv31JK+La12tbr88svnnvfAgR+/KLmmLa125bjgggtm2xwHakQ+nqyP611jYVN9PBmyrgrNV7k7jLlxeAjTKkSoVKdc9LZwHpxyyindvut2mxxms1zP89ayj6NrkvxuwvuPujr72jW/ytVFqnVjv86YW0wVBpTujn7Nyo2I9yiuFd/nWmZ9q7nh840uULwX+hhxLXNN+rcl1fch/K6k0p/Zjmo8qzDHnENVOlfWj3jbOPZVCF9e069TaePr4XDflG+TdMPK9ltW9kMIxyZZzyFMhHU90ltrfyXpWknfaa1dJ+n3JX24tfY+SZ8ahuHrR7GOIYQNJOs5hOmyrofyMAxvW+PPbzmcC7rZxs0VNAG72w7NFTQNuemApsZt27Z1+1/5yldm2zRNuSvTvn37urLK3eDBBx/syl7/+td3+x6pi1mivA6sq5uZpd4sSHPKAw88MPe3PI+bkWiGYUQ0N/fT/FS5t9BsVEXO4b6b4WjaY7vnRYiTavNTFbGNZmf2kWfgopnej/XjpNrtaRH3miNlo9azr183jdIM6GubZlP2bZUpiNG0/NjKbY3uPlWErzFzZ5UByM/L+xnr7qZl3t+47+uhMsVz3tLs7PvsA7pCen/SJO31Y9/SdOvt5Fjznurn5Xn8t6w754lDOY73kwqvD9cn58lGrt8EDwkhhBAmQh7KIYQQwkTIQzmEEEKYCEvPEuX6RBWurQoJR3u+6wTURqj5uZsRzzPPxUNarQl5nai5fPOb3+z2vZ2eTUfqNSLWh8eec845s+0nn3yyK3vssce6fde0GGbT++uiiy7qyliHhx9+eLZ9/vnnd2U7d+7s9l1zZv+5tlS5l0m99sUQptSlLrvsstk2dTyH3w+wT7w/qelRR6zq5+FPqZlR864y/BwLuNbp64H9Vemwlesh7wmcU34s3X8q1yVS6diVmx3LvD6c49RBK6rQlZUbUbWOWF+2k8f6eqm+46h0Yakez0p/rmDf8t7sdeI1KncqXt/LeE3q934f5zpflLwphxBCCBMhD+UQQghhIuShHEIIIUyEpWvKriG5BlKFbGQZ9UD3ReOx9Dd2rYRaV+VLS19f12CoKVe+cHfdddfc81DT8PSLUh+ik1oONSLXOqkX+XVe9apXdWXUZ774xS/Oth999NGujGEjXWehNl35IPKaPkZsV+WTyO8JHGqX1H18DjFcIX1rr7zyytk2U2i6flmFHJRq7etYwLVGn2NVSFPqk2SRVH9+7CIpFisfeo4Z910brnRizreq3aw7tWE/F3X1Si+v+o/3N7bT+4TrvEqjyGt6fVnXKn0q+9bvESyrfIZ5b+HarkLdLrI+K519UfKmHEIIIUyEPJRDCCGEibB0m9k8025llqFJhGYQNzvwWJppqhBxXuYhN6XVWVT8t+6WI602dbhpiCZgN2kyYxM/u/d2MkxkFS6T5ifvvzvvvLMrO/XUU7t9N+/QDE5T/Omnnz7b3r59+9z6sa6kcjejGdBNYDRNuTvXWFg87xP2AcfXTXucF173KluSVGebOhbYu3fvbNvnsWf5kvq20SWFa9nXFU2P7CM/F+eUrx3KXRwXn2N0naProde3mlOcX7wnzJPxpNWhIffv3z/bpgRSuSGeccYZ3T7Xh0OTsLeT4+BlvJ/zWA8rzLXL+5u3jWW+T/M5w9n6ePL+TxdGPxeP9fsd59ciIV8XJW/KIYQQwkTIQzmEEEKYCHkohxBCCBNh6Zqy6xFuz6de6boUdUWGlPTwkzyWGkIVAq1K4UbdwrXE3bt3d2Vsi5+XbjvulkW3K+o8X/va12bb1IeoQ5111lmz7fPOO68r+/KXvzzbfuSRR7oy6tqVywD7xOvPMfLwptQG2U7XiakHUq/x+cR+dx2Pv9uxY0e37xoRj6XmRx3ZqULH0gXE273eEINTxfVMzk3XT6swkSynBk8t0fuXc8rXA+dF5WZHjZuuTR62l23xMaQrZtVuXrNKQ8k+8T7wNb8WrpfzflF9i8NQxX7Pog5LN1PX/cfGwb9J4Xm9T8Zc5aq0mJxD6w3nzLpS8/bxrFzG1kPelEMIIYSJkIdyCCGEMBHyUA4hhBAmwtI1ZdcaXUupQq5Ry6TOyFSJzpYtW7p911KqEGwMcUlcb6AfMPUH15HpA+s6j2sqUq8hS9Idd9wx277uuuu6MrbT2/bAAw/MrQ/9navQntTFqjRo1OT9GwFqZjyv9wOPdb9HlleaPMeI/eVa3ViKRa9v5XvJdh1JOr8p4lq7a8rsrypFJfuo8mHn9xiVH6mPJ8eI+9V3E7ymz3mOn/sT81sWrjOH9wve36pvI3x/zP/f+4TX4L3H70v8NsL1Xn47Uo0ntWm228eBx/pYU2/mvaZan7zn+3jy25Gq39knPhfGxmGMvCmHEEIIEyEP5RBCCGEiLN18PS8kJkPzVa4RDOHobjx0L6CZwd1ZaH5ykw3NFQxh5/Xjedz9R6ozSnnYTZpm3/72t889D1016ILhpnj2rZtsaGajq9C2bdvW/J202kzj/UC3BR9Dmps4vm5u53gyK5Ofi+4YXj+6b1UZmypztdSb3Vh3nzecF5WbB8fzWMDrX2XGqTLocH16X7NPKHH59emG4nOV85b4HGN9uHZc9qhcvzj/WYcq6xDn23pDcrK/qjClrB/vS36uylzMsKRcg35/YR9QQvJxqDL4jblUVib9KnvdIq5obIv3Z7JEhRBCCC8Q8lAOIYQQJkIeyiGEEMJEWLqm7PqEp/2iy4DrBtT/qCm4u8tYuELXnnhNr8+FF17YlVFD2LNnz9xreNpEqdeezj///Ln1oc7EUHiux1M/4r5rMtSLvH4so+uQn3dMK3Hdlrq/a/JjWuG9994722YfVCnd6L7iGtUzzzzTlVVtod5Whc2rUrpRm+Z5qpSGxwLenio1px/HbwQq9xEeW30zwL7233Ksef/w81An5pzyNchrun5afTsirZ7XDr8tefzxx2fbVSpa6qVjqRId9omvSZb5+uCc5jcq1X2c+G8rzZ33i6pPOIeqtL9cg77P+lT1O9LvQ/KmHEIIIUyEPJRDCCGEiTBqvm6tvU7Sf5f0A0nfkfSvV373p5JOkHTLMAy71ntBNx+42Ygmm4cffnjN30h1tpEx0+iTTz459zxVxBtG+vEIODTh3Hfffd2+u/HQtcrL3P1IWm0id5MwI97QnHLLLbfMtj3SkLTarcKhqcrPS/MOXb98DB988MGuzE1eHiVMWj1mntWK7eSx3vc0O/v84vhVLluvetWrujL+1t1kGNHI59SYG4zXnabGo8FGr+V5LnpcV97X7BMe6/1Ac6zLS1JvWmbfVpG3uF4rM3jlblNllKJcwkh+bs6m+ZXr0+8L7AM3g3MOVTIMr8n+87axD7ydvL9W67WKpsXrcM25+1Rlapf6tlCO4Jzyc1UunpRAuO/trEzb62E9v35Q0r8YhuHZ1tq7JL1H0omS/mQYho+01j7eWrtkGIZvHFFNQghHm6zlECbOqPl6GIb9wzAc+sLiB5Kek3S9pJtW/naTpDccneqFEDaKrOUQps+6NeXW2smS3i3pf0k6fhiGQzaWZyRtXeP4Xa21wf/bkBqHEI6IrOUQpsu6jN+ttVdI+oik9w7D8ERr7dnW2suGYfiepC2SVqVAWdGmduE8g+tx7uJAraQKe8iQkg4/yafe4PtV5g9qygwJ5+4/1KhcD5eku+66a7bNbCyPPPLIbPt1r3tdV0ZtybNEsV1/8zd/0+17qEpqSw7L2Ceuq1x55ZVd2QUXXNDtu/ZFDc31GmpCpMrww76u3JVcF6PWRU3I9XBqynTF8b6n64vPY2pUbEsV4u9osZFr2eena2rVdwnU2/iNgM9HutBUGiTHCHUtz+P1HTvW59siWauqMKCEv/U5dsYZZ8z9XeWOJPWaLseB7fbfVpmzeP+gbuzaNd3AeF/3dcXzeP14zSqkKa9ZhWrlWvYxW0THrr7ZWQ+jb8qttRdL+gtJ7x+G4faVP98m6YaV7bes7IcQJkzWcgjTZz1vym/XQZ3pla21/yDp45J+X9KHW2vvk/SpYRi+fhTrGELYGLKWQ5g4ow/lYRj+VAddJshbNr46IYSjRdZyCNNn6WE23Ybvdnr6j7keSF8z6jN+LH0HiesNr371q7uyKhQkNSD3dyZsi/vsUju/6qqr1jxOWq17uj7z6U9/uiujb7RT+S/yGtRKfuVXfmW2/Uu/9EtdWZW+rAqfOObzt0gITNel+K2B68jUJzlG55xzzmx7zJfW9a6rr766K/PUoA899FBXRp9mn//0BT0W8HlVpXF0vY3zgtqm90P1fQP3GULSyyqNVurnAudXFRaUvshValVqkn5exieghuvfrzCEr3+7wbXLkLn+PQ/nv89bqddFeR7vP7aL68w1XY412+l1YpmvuepbIJ6nml+kSpnJsmoej30zM0YieoUQQggTIQ/lEEIIYSIs3XztZhs3D9DsUYWsI+4KQFM3M0G5aYMmXw//SPcC1s/N0DRJV2FAt27t3UDd1YpuHQzJ6S5R3/hGH3SJ5hS/ZuU2RH7xF3+x23eT9Vgmo8qE6ftjbk2VeZ19631EdzM3edEMSenCQ3uyPlXWF5rS/JqVuZXXGcvANUXcxOjzjSZDN42yDyoXFZpYadKcZz7neWmursKfchyqMaPbjt+n+Duah/23vL9x/u3YsWO2Tdc+X/fsA7bF7zVja7max96fblpfC28L75MMt1uFzPU68N7M/vPfsk94T/V2sr/8PFWIXKnvk0Xut2uRN+UQQghhIuShHEIIIUyEPJRDCCGEibB0Tdlt766zULP1/Up3kqSdO3fOtg8cONCVUUNwTZLndX1h7969c+st9dow9cpzzz232/dwlAyT56kb6WZ15513dvuuI49pkK7xUZ9xfYTaKnXZ6jxkvboxdWHi1xlLuej6ErVfnyeXX355V8YxctcNavtVX1ft5O+oKx6LblCO65K+lugS4iFr2V90ZfK1xHXOff8t+9LrwDSFrEPlwkLtlS5Jjl+H33gwNa2vQU/jKK3Wjf28vNd4nzA0MLVXhyFCOef5bY6zSGpCnxe8Bu+pfizHc963SNJqbd/vGZULpdS7flXfAjF0Ju9L/ryKS1QIIYTwAiEP5RBCCGEi5KEcQgghTIRN9VOu0jO6pkENodKEqJVQw3Xt8LLLLuvKzj///DXrxnpLdTq6yreR53HNm32we/fusg4Vfi5qLu6LzHSRf//3f9/t+ziwXdRrvJ2Vrx7PQ33G+5O6E9viOhW1uGuvvXa2TX9K6m0+x8bmWxVSz49lO6lP+nguotNNBfcjrkJV+ncT9D2u/EjZt0zDV/ndVvOf36/4WqcWzGM9JCbL/JsQzkW20+cY687vYLwfqu8xqpSZUu8nXIUJlvo+oZ7q12EcCKa49fsH+4T3au9Prp1qzVVpT8dCclZhXav7Lee46/5VXIP1kDflEEIIYSLkoRxCCCFMhKXbzNyEUbmPeGYSmg9pIvFMKcy4wrCWHtqtcrehmYimDN+nuYn1dRMJTVVe9slPflIVF1100WybGaVo0nHXJvbBpZdeOrfubOdHP/rR2TbNT+w/b0uV6eaSSy7pyliHKsMPQ/WdddZZs+3XvOY1c89Dt5jKVDUW2rMypXl9K1cN/vZYN197/Stz4piJlSbh6ljvz8rcOSaX+HjzWM4FN01WmYz4u6rdPA9d5+6///7ZNteym5bZ75QK/Lec07xnsQ6Oh7WkC2WVTYljS7O414F19zK6a1VudZwz7CM/L+/N1TyuGHMdHSNvyiGEEMJEyEM5hBBCmAh5KIcQQggTYelC1tVXX73m3yv7PXWBRfSZKuRZ5bZTaYVSrz1RO6Sm4PoSdZVPfOITs+0vfelLc+sj9VoOtV9qMOecc85s2zVkSfrUpz4122YoT+o1XvcxlwE/dvv27V3ZO97xjrnXoL71zW9+c+41L7744m7f20ZNyPc5nrym74+lXqtcv7y+nIsM6/r000/Prc+xgK8Jd1din/hxY9+H+JhRl+U3DVV6QZ+bHHvu+3Wqb0cINVE/lt8+0J3L7xFMPcjfOtR6fd5w/nOduR5OLZjj4OFEqdn6HGfoTIav9THi2LPd/O7D8b71741YH1KlhZX6PuEa9HnBvqRLpR/LPlmUvCmHEEIIEyEP5RBCCGEiLN187SYLN7fQ1OdlNF9X5myavLhfmToqM1tlqh37dN7P9eUvf7kr+9znPjfb3rFjR1lXjzhGNyKavDxjzM0339yV7dmzZ7a9SNQp1odmQHdJ+vVf//WuzE1TvMYHP/jBbv++++6bbTMim5u2pV4O+IVf+IWurIrWw3nhZq2xDFx+LkYc8z5h31ZRxI7U5LUZuGnSTX+VqxzNh+wjP2eVEUyqM1P5mmMZ17KPIU3kvA+45EApyk2+vEfR1O1ziOehWdfnY+Vuw3sA+/bxxx+fbdMkXfUR57jD/qoyP3FeUBKsMtJV0kDl2krZgDKfX7PK/MTxY9/6eB6uK9Uh8qYcQgghTIQ8lEMIIYSJkIdyCCGEMBGWrim7jd81hSo8W+ViQcY0K7f3V6HmxsLQ+XV4TdZv3759s+2PfexjXZlrLszYdOGFF3b7rre0KtL3AAAfl0lEQVS5LixJX/jCF7p9148efvhhzaNyDZL6dlMrqTLq3HTTTV2Zu2h5f0irdXbXWh955JGuzDMOSX3IziqEKevKMfN2j32H4H1CPdC1c/6OWXG8nYtkAJsKvpa9LXRt8TnOvqW2uch88/Glhuv9ybXLeeK6IjVR1s+/5eCxrq8yexLr7q5NnEPUTL0f2Bbfp7uUf1ci1fePk08+udv3kJzUuP3YMVc+dyXimqu+DarKqP3SncuPpVbOcamyYfl16IbFdvsYVa5d6yFvyiGEEMJEyEM5hBBCmAij5uvW2jZJ/1fSDyUdJ+ldku6V9EFJZ0q6U9J7hmGo/UhCCJtK1nII02c9mvITkq4fhuFHrbU3SfpPkj4v6UvDMPxBa+0PJb1Z0t+u54Ku56w3xRu1iEo3HjvWdSBqQl6fsfRbVZpH6hiekpHHum7x6U9/uiu74447un0PYUdtyX0kJenAgQNr1pX1q/w7pTrsIc/rOtVdd93VlXlKTepF1LP8Op5qU5Le+c53dvuu43E+Vd8PLKLh8rxVSE4fT/pEsr+8T6qUhRvIhq5l10l9TNlu36/SmvKcY/1XfZPi16nKWPexMJvzQotKvaY7FvKyumexvr4euF6ffPLJuXVlLANfK/w2o/rGgmvH68d7gvtxS70Wyz6p2l3FFRi7D/l9ndfkbw835WgVipdzelFGzdfDMDxv/3I+UdLXJP2cpENf8twk6Q1HVIsQwlEnazmE6bMuTbm1dklr7XZJ75f0GUlbJR36J9EzK/v8za7W2uD/bVSlQwiHR9ZyCNNmXS5RwzB8Q9LPttZeI+l/SnpAB/+l/YikLZKeWuM3uyTt8r+11oZ5plOabNyNgmYFmp0rU2SVxafKFkOTCM9TfaLPY9/61rfOPdbDK7pbiSTt37+/23dXImYccnO11JucKrMM20lzj2eT4Xmq8Kd0C3B3DIZLvPLKK7v9K664Yra9c+fOrozuD5UZsAqFyv3KTF+FWOU4uFvFWChDr/tpp52mZbCRa9nnsptG2U7vB5r2OId8DNm3lasax9NNybwGQ5r6WuE1ue9maEoOfg9j5ji6OXENOI8++mi372uQ69yvw7XLjGreD3SXoil+vSEvx8IaVxmvmEnOr0nponJZ5LPD28mx5/3Dx7AK+8k5zXnh9266Vi3K6Jtya82fIs9IelbSZyXdsPK3GyTddkS1CCEcdbKWQ5g+63lTvrq19nuSfiSpSXqfpN2SPtha+6ykuyTdXPw+hDANspZDmDijD+VhGD4v6Y1rFL1t46sTQjhaZC2HMH2WHmbTNZDqM/fKRYSasmsBY65Mrg1UqQjHNMh57iDSam3H9Ydf+7Vf68ruvffe2fZHPvKRroyayz333DPbprvDIunCXO+96qqrurLrr7++2/d0kmNayamnnjrbpguIa0vsLw/ByX1qN5VLGce++n5gkVCtlWZV6Zycw5wX3pYjDc23GcwLocjx9XZyHCpXE+qy/FbDdTzOC9ckq5CNUt8OzlvWwfVe6uP+XQBdg4hfp/qeRurnGDVRX1fUhYlr+2Pfkvh1+K1LtXbYt67fc47zflK5N3rdmS6yCoPLObOIG6y3k9+VcE75GI2FHh0jEb1CCCGEiZCHcgghhDAR8lAOIYQQJsLSNWXX2ar0h27rp263CNQbKs3Zj6VmUFGlneQ+z3veeefNtt0fUVqdttDLf+ZnfqYr+8pXvtLt33333bPt888/vytzv2nq1meccUa372nbqJF6ejep14joa+laE7Wvs846q9t37YkaFfH+5LGVHyvHodKfqUtV87EKQci559rhIvNtiri2T621So1Y+cey/+i76sdyjOiH61R+rtRWH3vssbm/rUItUhdmWEtfS2yXf5tBqMu61snzcBxci+U1eM/y9UANt4pHwGO9nH3Csfc+qkJVjoWx9HnB8azaSS24ilvBOvhvqfsvSt6UQwghhImQh3IIIYQwEZZuM3OTT+XG42Vj5mFnLEuU7y9y3ipzC6myRrHNbqJ++OGHuzIPFSj15h2Gr6N57JJLLplt/+qv/mpX5mNAk5KbvaXe3HjBBRfMPY/Uu3nQBOx9wvCTDHtYuW5UJurKNFW5NZHKVU7q+4RhU31e0OWDbXFzI81sxwLeL1W2He8jSiCVnEQTYWUu5vj6Nat1TVgfhsOsXJlcsmEfsC2VVFa5DtE9yecis63RPOx1P+mkk7qyqt28po/7WChUn9c0r1d9VJmHK5c7nndMQnKqMJtcn9z3eV3N0/WQN+UQQghhIuShHEIIIUyEPJRDCCGEibB0TXmevlPpu1VKvuqc0mr7fuWyUoVcI4toYQ51xr179862+Sk9XaQefPDB2TY1IYbHdF22Sm3J+lAj9XLqgU891Wf589CflRZMbYkas4/RWHhM36e25HWowqRKvUbE81A/8v6sQmnyGjzW68R+PxbwuVGlMqUm6dBFyufGk08+2ZVxnlRhev28HHvOeR9PHsu143ODZa4F83sQ6sRe3ypkoyRt27ZtbpnXgek/uc78PKRKt8l2ehnnNHVsrwP7gC6VHtKU86IKp1t9SzLmPlWNp6/l6h4g1e5Ti5I35RBCCGEi5KEcQgghTISlm6/dTFJF9HKzQpUFRKrdk6qIXpVpg7+rXFbGooZ5JihGCHKz8/79+8vzeOQrRsG69NJLu3030dHs56YXRt564oknun13s6BJiRHHfBzoKuHmdrpusJ1evyoKFq9ZzQOWVdJF5c4l9fOG53ETPs24nG8+RkcStW6zmBcJi+ZqN3Fy/JjtrHKZrDL10ITpfV259Ej9vKZ7Hue8jxPH090UGdmK2ae8v3gNrlc/trov0X2LdXCqLHyE9fHfsj5sSyVb0Zzt5+X91vt6zMVtnqveWvWtTM2LuGH53KzkmvWQN+UQQghhIuShHEIIIUyEPJRDCCGEibCpYTadSvOrwlZKvb2ftv9KqyZ+XuoWY25Z1bGuyfzDP/xDV/ba1752tn3xxRd3Zeecc06375qRZ2+SpMcff7zb37lz52ybfeLaF9vBjFLu4kAXFY6l79Ndyt01Dhw40JXRVcN1R2qQ1KUc9rvrW2OuVZULyCJzyLUw/q5yzztSHWqz8b6uMkFRy2SfVGuQx1buLF7Gvq3cADm2PNbhunIXn8qNSKrDY/JbBP8eg33iZe5SxPpI/Vrn+uR9oApD6/VjXStXJvYtj/W2Ufv1+8AideV5Ktc04uuX85bj63MzmnIIIYTwAiEP5RBCCGEi5KEcQgghTISla8rz/Epp+69CEFIfdHs+NQIeW2mSfp4xX2jXMcZ8TF3HoDbhfpEMUUcfYteMqBexj7x+VThMalTUXFxH3rdvX1fG+lZt8fFkiFD6e3p/Up+pxoF94JpQ5WtMKv9JqdeTqItVaTE5p7xPqlCoU6VKbed4u9lOjpkfW6X0HMPHntdgCEyfQxwz3pd8LVUpKqvvG6R+TtG/uAoBW81bllW6Nr/jYJ9UfszeTl6jSsfLOcJjq5gDVeyC6v7L+30VopP97vcMflvA8aziaixK3pRDCCGEiZCHcgghhDARNjXM5nqzO1XZf3hOmqsrd5bKDFKZMqQ+JOaOHTu6Mpov3DxGs7ObhFnGsJteJ5pluO8hMOk+5WE/Ga6zyrhCkzRDcrqJh/XxcWFoRbpyeH+NuSN5fRfJ3FK5K3EOETdvV24elQsU63ekJq/NwMfNx55t8T6i2Y9j7+Wcb+7KJ9XuZ25+5XjSRO3XpBm3ytjEeeztpgTCPnGTNfugMrHSBFyZklmHKqwx+7py63n66afn1r0Ks0kzPe9vF1544Wy7yppGFyia2v2a7BOOmcOx9nsYr8l54rAPFiVvyiGEEMJEyEM5hBBCmAjrfii31q5vrQ2ttVNW/ru5tfa51tquo1i/EMIGk7UcwnRZRFP+j5K+tLL925L+ZBiGj7TWPt5au2QYhm+s5yRu73cbPu3wrsHwU//KJWpMf3ao8VUpv6g37N27d7a9ffv28rzeFobOvPvuu2fbDHFZ6cZjYSNde6Iriad08/CX0ur+c82IehavyVSOjus+vEYVBpHp56o0nqyPn6cKzcrzVmkApb4t1O2qcJOV1rpkNmQtz/sGowq/yr6klul9xmMrt8nqOxPC83jdOZ5Muehwbvq3G5xfdEFyrZN9wHuEuyVybvo+71FVmNKxkJdV6EqH+nzlUka3oi1btnT7vq5Yd3ePq77ZYTnLODd93rD/vvWtb2ke1LHXmxJ4PazrTbm19suSPifpkEp+vaSbVrZvkvSGI6pFCGEpZC2HMG1GH8qttRdJerekD9ifjx+G4dA/e56RtHWN3+1aMZHN/tuQGocQDous5RCmz3relN8h6a+HYXAb47OttUO21C2SnuKPhmHYNQxD8/82oL4hhMMnazmEibMe4eBySde01v6lpCsk/bmk2yTdIOn/SHqLpP98OBd32z/1U9c8qH9wfxEfzyqsmp+HmkGVEpJ+wJXfIfXn3bt3z7ap61x77bXdfuVHXaXAo2brWhh14ioc5VhKMm83z+Pp6ag78bw+DmwXNT8vr/w7x1LyuV8k+6TSiFh31weZTpNzqEo9eJTY0LXsbWVITMd9Q8f8RivtkL/1ceH9o+rPKj4CYVpF1xm5zn086WfLfa8v67pnz565v+VcdN9f+nG7PzHrR82dc961dK4r7wOuT65tD6nLunPOVH7B1ZhVzwfeU6kbe9+yrIpdwHZW11iU0YfyMAy/fWi7tXarDv5ru0n6cGvtfZI+NQzD14+oFiGEo07WcgjTZ6GIXsMwvMl237KxVQkhLIus5RCmydLDbM5znaAJosrYVH2uX7kMkMpdauyzdjdrMeQaXSWc+++/v9u/7rrrZtunn356V1ZloaEbBXGzKs1sfh72O832vk/3EI5LZU6sxppt8XKah3nNymWryhLFsfe6j4XJq8yAlbsUzXV+nSorz1SpXJ0cN/VVZm6pnzdVKFSp73uOme+Phcyt3C+Jl1cZ6MbuQz7evJ/RNFplpKvmUBWqspINpH7dsZ2+X91Dpb6vq3CYUt+2aqzHqOpXmah5v/Wx5u8qKe9IpahE9AohhBAmQh7KIYQQwkTIQzmEEEKYCEvXlB2391duTYu4MFATqjQYHuvXoc7jKRalXrd47LHHurJzzz232//Hf/zHNa8vSZdeeulsuwr/t9a+Q43ItRzqM5VbRxWGjmHx6ApWuSB5u6mdV2HyCDUi13aoY1facOUKxn6uzlvpUNTB6LKyCS5RG4qPm9e/Cm3oLjJS7dpH3a5ynWNZldKQ9wTf57zgdwE+pjzW58WYy5HPKc6Lqi3EtWC6+XEcvE5jbok+j9l/fh7O/6ee6t3c/bcM98v7r7eT69zPw2tW7kmE9zcfM/aX9wn7gOepQr4uSt6UQwghhImQh3IIIYQwETbVJarKLOPmAJoraH5y01DleiBJX/3qV2fb11xzTVfm5hT+jpF9TjnllNn2Lbfc0pXdfvvt3b6be1796ld3ZW56ocm3yhJFczXr65ll9u/f35Vt3frj8MZjppbKnEiTnI8LzXfetrHx9DFkuyo3LLpsLZIhrJpDrF9lwnRzIs3nHE/vzyONArQZzJNTKnMnXW+qTG2cQ5UpmXOqGvvKxYfwPG6C5fh6GU3OXK9eX7+XSKtlIZ83nCc+/2l+raQ8rmWuMx8X9q3PebaTpuSqftyvInpVWdx436xc5cay6zneX5zTlAqcmK9DCCGEFwh5KIcQQggTIQ/lEEIIYSIsXVN2bcDt+5W2RB2xyu5UhVGT+pCY1Hlcx6AeU+kqPJYuDldfffVsm/qRH8u6u/bL+lITqsLkUYvzMKBj7hdeJ5ZVOkvlhvXAAw90ZWeeeebca47pZH4d1q/KIFW5XHB+Ve4irI/PW+p01KH8vMdimE3Oq0NU+jjXUdUndMGrtF/2XxXyknh96SJYuRVV9yFqmVwPDsP0ch77vYb95e3m9w1VWEuOA+tXjaG3jdfkvmvMY+GSvZxlXp+xbzWq+1Dldlq5JXKd89lRuYMuSt6UQwghhImQh3IIIYQwEfJQDiGEECbC0jXlebpGFfpuzLfMNQTqMQzt5npqlcKNUJvYu3fvbJs68fbt2+fuUz9ybZMasuuwUq95VKnDpF4DoX7q/cf+qdLI0X+ySvPIcHuuA1ED4jV9XKjlVL7RY/qRUx1b+SVLfTur9IIsq3TGYz3MZpUCb706rNSvjzHtcL1pWSu/aTLm71yF0qx8rDmnvO/G/Pa9nPesap0vkqaQ95PqWxIfhypUMevEY6vvMXhP8POynWyL/5YafBXWlVShRnlNLz/SmAN5Uw4hhBAmQh7KIYQQwkTYVJeoKpRbZa6gKcHNDFUYOkl65StfOdt++umnuzJ3zaHZg+ZY/+3ZZ5/dlZ1xxhndvreNYehOOOGEuXWtQuHRvEOXKDdzVSZqmqAPHDjQ7VeZlqq+JW7y4lizDj7eY64a3haatn2ecA7R9aVyiapMmpyL3ha2i8dWmbyOBTyUq49vNRcrs6Q0381KWt1HlcmwCmFKM3h1Hu77sVzL3u4qA5LUz41F1gPxdvK4Kvwk5z/vEZWM4NdhXxJvW+W2yXMtkimrukdUpm2p72v2F+/5DtviUHZclLwphxBCCBMhD+UQQghhIuShHEIIIUyEpWvKTuWyUqXNog7l5dRy+FvXJvbt29eVXXnllbPtJ554oivbvXt3t+/68znnnNOVUZvw+lbuP/xdpb9Rc6GO4fvsZ+8Dumg99NBD3b5rJ3TZcj1c6rUn6lteX+pXbIufl9cgPt7Ullzz4zygTla5UVTuENT/vC1j6fE20o1iM3ANvwo76/OW6TWrcIqc0wy76eNQfTPA8eO+z3F+l0DN1OvAMfM6VPcoXpPtYgjHRx99dLbNuelzfEw/9WMZCpiarbeF9yXvW85p6uzen4uklqxcl8bczarzsG99XNi3vj/mjlelGl6UvCmHEEIIEyEP5RBCCGEi5KEcQgghTIRN1ZQr5qV4lFbrgW7fZyhID6spSaeeeups+4477ujK7r///tk2NWRqJTt27JhtU8ukLuWaDLUl15Oo81Cv8XZSC6bG4boP9RDXXFjXiy66qNv3tlEPpI7n5TzW23Leeed1ZawDtaZ59WEdqrCCVXhOHjuW5tF/Sx3K280yzlufF8eipjwvxCPXq8/5sZSGfizXLvXAKjSq6/mc/9T8vE5cR6yv69xVSlmWUbN1fdX9vaXV/ee+26xfFaOB1/Tfsk/4/UOlBVffyFQ+/VwPrG+VhtLPw/VYadNj33X4PbcKmTt2nuobqEXJm3IIIYQwEdb1UG6tfbe1duvKf29urb28tfaXrbXbWmsfaK3l4R7CMUDWcgjTZr3m6/uHYXjToZ3W2nskfWkYhj9orf2hpDdL+tsjqQjNHtUn5gzFV5ljae5xFxuGSrv11ltn2zQPv/Wtb+323bQxFpaxMme4GaQywfGapDLpVNl22Je8pocTpVmN5ig3l9Hc7+2kCwjxcaFJnyFMHfazm9Yqk6q0WMhLHyeasdzEyr7kNTfJZL1ha3lelib2tfcnzabsP187YxmI5mWck/q5OJb1axEXlsp06/WlGxHxOU4XQba7msfrzVjG87JPWN9qblZZtio3sbH57uuDdfc+GnM3q0JnVlTZucbu8fMyph0O6/1X8dmttc+21v6stXaypJ+TdNNK2U2S3nBEtQghLIus5RAmzHrflM8fhuGJ1tq/k/S7krZKOvQK9czKfghh+mQthzBh1vWmPAzDofBWfyHpKh1cxIc+jdwiaVU6jdbartba4P9tRIVDCIdP1nII02b0Tbm1dryk7w3D8LykN0raI+nzkm6QtHvl/5/g74Zh2CVpF8617sXsNnza86v0fdRVqk/0Tz755K7ssccem23//M//fFd20kkndfvucjTm5uF12L9/f1fmuizPQ23J9Uq6O1AD92uecsopXZlrukxfWYWfrEJnsr7U21z3YXpI9te5554726ZbDPUj1yipdfm8WSSdWuXuIPU6FY+tUjdS36pS8h0NNnotz9MIORf9O49K918579wyhnl198dK8+M85XcU1bzlGqxcv7w/qnXE83KecD1Uc6rqr8pli/XjfbIKUevjWWncrBPnP+vn5dU9n78bS2PrML1s9U2P9xG/hWAdqm+MFmU95uuLJf1xa+3bkr4v6Z2SnpD0wdbaZyXdJenmI6pFCGEZZC2HMHFGH8rDMHxZB81c5G0bX50QwtEiazmE6TPZiF4VNA+4SYlmGJpMPPvTaaed1pVdccUVs+3t27d3ZTyvmz1oCqJZ3M1ljHTl5myayqooQGNuHN5HNMu42Y9uTeT000+fbT/1VC837ty5s9t3U5ZntpF60yPNh6yDmz9psqzGgf3n56W5iWY3nyc0f9HMXJmv3dS32ebqzYJ96/t0/6lMmpz/nMd+rkoyYr9zzKo1wPnn65d1d9PoWMQsX59j2Z1cKuPcrKKlVa5LY/cPP1dlTq/Geuw61Xrg2FcusqxfZXami2VVVzfhc+5VcsmRmq8TKCCEEEKYCHkohxBCCBMhD+UQQghhIhyTmjKpssVUoQ23bdvWlZ111lmzbWojdKlxHYOf2VM3cx2DGgd/O+8arFP12b/Uuz1RQ6uyMFHz9jq4Hi/1Wpe0OkPXvPMwKw51O78O9fmq7qTKzsXzeP2oFVauTVV4whe6hux96HOTul2lbVYZzKqwmjy20hX5DQO1V1+vdH2kvuv1ZUjfyk2ymm9VxjKp17y5PqvfVa58Y65plauhw3ZSC66++aiyO1UuW5wXXIM+LmMhVuddg+cdC5FbfcOzKHlTDiGEECZCHsohhBDCRMhDOYQQQpgILwhN2aGOR/3B9UtqQq5xUJ+h7unlVao61oHajaeSHNN5qpSBbIuH5KQ+Qx9sh22hb7JDnd1/S53H60DNnbqi+zjzWIbdrLRg70/2bTVm9FutQuodaZq2Y5l56Tg5ZlV4R85bh2u5GsPKd5VjxPnmVGF5pV4z5Xm8bWwnz+P7YykXqzlODddhWyqts0q5WH0bMXbvq76xqPx5qz4Z+1bDy3kP5X6lMVfztjqW9+ZFyZtyCCGEMBHyUA4hhBAmwgvOfE2TSJWFpjKPVRlMpD4EG89D86ebPipzGN2c3ATNYxm2j9f0fboVeVt4nsp8x76k6cxdT1jmfUCXGWaqchlhLFyhjxNNoV539iWPrUyEY64mP6ns27dvtn3mmWfOtmlmrsLgcj14346ZRn2e8LxeRtc9SjKVGZxj7fNvEXebyuRamba5zzXo85r9XrWF7kh+PyNVVibWleu1MuvyvFX2qapvK9M761PJHJVcWIX3lfr7bSX5rYe8KYcQQggTIQ/lEEIIYSLkoRxCCCFMhLbMUICttRd23MEQNpBhGOr8eptIa214oYcRDWEjaK0ttJaX+qHXoYqtLOjJ3HBSn5rUZ5wp1uloM5aTN4SwOC+4r69DCEef/AN7/UytTqlPzWbXJ5pyCCGEMBHyUA4hhBAmwmY9lP/bJl13HqlPTeozzhTrFEI4xtiUh/IwDLs247rzSH1qUp9xplinJTG1f4xMrT7S9OqU+tRsan2W6hIVQgghhPlEUw4hhBAmwlIfyq2132yt3d5au7W1dt4yr211eElr7f+11p5prd248rdTWms3t9Y+11rbteT6vK619vnW2mdaax9vrZ24yfXZtjJGn1m5/mWttZe31v6ytXZba+0DrbWl/2OutXZ9a21Y6ZtN6x+rz3dX5vGtrbU3T6GPlk3W85r1yXpeX70ms54nt5aHYVjKf5K2SvqCDvpGv1bSXy3r2qhHk3SGpF2Sblz52x9I+lcr2x+XdMkS63OmpFesbL9L0n/Z5PocJ+lFK9tvkvS/Jb1H0m+t/O0PJd2wCeP2MUlflHTKZvaP1edO7G96Hy25/VnPa9cn63l99ZrMep7aWl7mvwCuk3TrMAzPDcPwRUkXLfHaM4aDHMCfr5d008r2TZLesMT67B+G4VDOxh9Iem6T6/P8MAyHcpadKOlrkn5us+ojSa21X5b0OUmH8tRtWv8YZ7fWPtta+7PW2sna5D7aBLKe165P1vMIE1zPk1rLy3wob5XkiXOnZN47fhiGQwkxn9HBui6Vlcnwbkn/a7Pr01q7pLV2u6T3S/qM+rFban1WTEfvlvQB+/Omj5ek84dheIOkT0r6XW1iH20SWc8FWc9z6zLF9TyptbzMhfS0Dv5L7RDPzztwE3i2tXYoG/YWSUeWpXpBWmuvkPQRSe8dhuGJza7PMAzfGIbhZyX9sg4uZB+7ZdfnHZL+ehiG79nfNrV/JGllnCTpLyRdpc3to80g63kOWc8lk1vPU1vLy3wof0HSG1trx7XWrpa0Z4nXHuM2STesbL9lZX8ptNZerIOT4f3DMNw+gfq81HafkfSspM9afW5YZn0kXS7pxtba30m6QtKfaxP7R5Jaa8e31o5b2X2jDs7lzeyjzSDreQ2ynkeZ1Hqe4lpedurGd0n6t5J+KOk3hmG4Z2kX7+vxV5KulfQdSX+ngx8afFjSCZI+NQzD7yyxLv9GB//1+tWVP31c0gc3sT6vk/R7kn6kgx/RvE/S7pU6nS7pLkn/3nSqpdFau1XSjSv12pT+WanHNZL+WNK3JX1f0jslPaEJ9NEyyXpesy5Zz+uv263a5PU8xbWc4CEhhBDCRJjSxxkhhBDCTzR5KIcQQggTIQ/lEEIIYSLkoRxCCCFMhDyUQwghhImQh3IIIYQwEfJQDiGEECZCHsohhBDCRPj/WrCzrPXUvmoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_dec(mod,DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier_acc</th>\n",
       "      <th>Classifier_loss</th>\n",
       "      <th>Generator_loss</th>\n",
       "      <th>Generator_mean_squared_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_Classifier_acc</th>\n",
       "      <th>val_Classifier_loss</th>\n",
       "      <th>val_Generator_loss</th>\n",
       "      <th>val_Generator_mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019097</td>\n",
       "      <td>4.168705</td>\n",
       "      <td>263.987283</td>\n",
       "      <td>0.084180</td>\n",
       "      <td>361.170590</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>4.186162</td>\n",
       "      <td>254.255446</td>\n",
       "      <td>0.081076</td>\n",
       "      <td>351.787255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021798</td>\n",
       "      <td>4.168634</td>\n",
       "      <td>248.409453</td>\n",
       "      <td>0.079212</td>\n",
       "      <td>345.590274</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>4.185663</td>\n",
       "      <td>234.719179</td>\n",
       "      <td>0.074847</td>\n",
       "      <td>332.240065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018326</td>\n",
       "      <td>4.166175</td>\n",
       "      <td>227.537044</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>324.667689</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>4.182758</td>\n",
       "      <td>239.722748</td>\n",
       "      <td>0.076442</td>\n",
       "      <td>337.184316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016975</td>\n",
       "      <td>4.165539</td>\n",
       "      <td>225.054486</td>\n",
       "      <td>0.071765</td>\n",
       "      <td>322.171194</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>4.188661</td>\n",
       "      <td>227.660536</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>325.238983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021412</td>\n",
       "      <td>4.161943</td>\n",
       "      <td>220.238498</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>317.282119</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>4.187420</td>\n",
       "      <td>225.185696</td>\n",
       "      <td>0.071807</td>\n",
       "      <td>322.738149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier_acc  Classifier_loss  Generator_loss  \\\n",
       "0        0.019097         4.168705      263.987283   \n",
       "1        0.021798         4.168634      248.409453   \n",
       "2        0.018326         4.166175      227.537044   \n",
       "3        0.016975         4.165539      225.054486   \n",
       "4        0.021412         4.161943      220.238498   \n",
       "\n",
       "   Generator_mean_squared_error        loss  val_Classifier_acc  \\\n",
       "0                      0.084180  361.170590            0.019097   \n",
       "1                      0.079212  345.590274            0.010417   \n",
       "2                      0.072556  324.667689            0.013889   \n",
       "3                      0.071765  322.171194            0.006944   \n",
       "4                      0.070229  317.282119            0.019097   \n",
       "\n",
       "   val_Classifier_loss  val_Generator_loss  val_Generator_mean_squared_error  \\\n",
       "0             4.186162          254.255446                          0.081076   \n",
       "1             4.185663          234.719179                          0.074847   \n",
       "2             4.182758          239.722748                          0.076442   \n",
       "3             4.188661          227.660536                          0.072596   \n",
       "4             4.187420          225.185696                          0.071807   \n",
       "\n",
       "     val_loss  \n",
       "0  351.787255  \n",
       "1  332.240065  \n",
       "2  337.184316  \n",
       "3  325.238983  \n",
       "4  322.738149  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame.from_records(mod.combined.history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f94f0c6dc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('paper')\n",
    "metrics = ['loss','Generator_loss','Classifier_acc']\n",
    "fig,axs = plt.subplots(nrows=len(metrics),sharex=True,figsize=(10,10))\n",
    "for metric_name,ax in zip(metrics,axs):\n",
    "    sns.scatterplot(data=hist_df[['val_'+metric_name]],ax=ax)\n",
    "#     ax.set_xscale('log')\n",
    "axs[2].hlines(y=(1.0/DL.num_classes),xmin=0,xmax=hist_df.index.values.max(),linestyles='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_df['generalization_error'] = hist_df.val_loss - hist_df.loss\n",
    "# hist_df['G_generalization_error'] = hist_df.val_G_loss - hist_df.G_loss\n",
    "# hist_df['class_generalization_error'] = hist_df.val_class_loss - hist_df.class_loss\n",
    "# sns.lineplot(data=hist_df[['class_generalization_error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def clean_config(config,keys=['dev_mode','log_dir','log_level','proj_root']):\n",
    "    c = vars(config)\n",
    "    for k in keys:\n",
    "        if k in c.keys():\n",
    "            del c[k]\n",
    "    \n",
    "    c['uploaded_by']='elijahc'\n",
    "    c['last_updated']= str(dt.datetime.now())\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'bg_noise': 0.0,\n",
       " 'dataset': 'fashion_mnist',\n",
       " 'dec_blocks': [4, 2, 1],\n",
       " 'enc_arch': 'feedforward',\n",
       " 'enc_layers': [3000, 2000, 500],\n",
       " 'epochs': 1200,\n",
       " 'label_corruption': 0.0,\n",
       " 'last_updated': '2019-09-05 13:58:11.015741',\n",
       " 'model_dir': '/home/elijahc/projects/vae/models/2019-08-13/xent_20_recon_1/stim_var_0',\n",
       " 'model_name': '0905_135744_fashion_mnist',\n",
       " 'monitor': None,\n",
       " 'optimizer': 'nadam',\n",
       " 'project': 'vae',\n",
       " 'recon': 1,\n",
       " 'rot_max': 0,\n",
       " 'run_dir': '/home/elijahc/projects/vae/logs/0905_135744_fashion_mnist',\n",
       " 'seed': 7,\n",
       " 'uploaded_by': 'elijahc',\n",
       " 'xcov': 0,\n",
       " 'xent': 20,\n",
       " 'y_dim': 20,\n",
       " 'z_dim': 50}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_meta = clean_config(config)\n",
    "run_meta['project']='vae'\n",
    "# run_meta['ecc_max']=0.8\n",
    "run_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3ecb8a02f4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "run_conf = clean_config(config)\n",
    "\n",
    "with open(os.path.join(run_conf['model_dir'],'config.json'), 'w') as fp:\n",
    "    json.dump(run_conf, fp)\n",
    "\n",
    "hist_df.to_parquet(os.path.join(run_conf['model_dir'],'train_history.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = trainer.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.get_layer(name='dense_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_encoder = Model(trainer.input,trainer.z_lat)\n",
    "classifier = Model(trainer.input,trainer.y_class)\n",
    "y_encoder = Model(trainer.input, trainer.y_lat)\n",
    "\n",
    "l1_encoder = Model(trainer.input,trainer.model.get_layer(name='dense_1').output)\n",
    "l2_encoder = Model(trainer.input,trainer.model.get_layer(name='dense_2').output)\n",
    "l3_encoder = Model(trainer.input,trainer.model.get_layer(name='dense_3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_grad(model, inputs, outputs):\n",
    "    \"\"\" Gets gradient of model for given inputs and outputs for all weights\"\"\"\n",
    "    grads = model.optimizer.get_gradients(model.total_loss, model.trainable_weights)\n",
    "    symb_inputs = (model._feed_inputs + model._feed_targets + model._feed_sample_weights)\n",
    "    f = K.function(symb_inputs, grads)\n",
    "    x, y, sample_weight = model._standardize_user_data(inputs, outputs)\n",
    "    output_grad = f(x + y + sample_weight)\n",
    "    return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "# res = classifier.evaluate(DL_dicarlo.sx_test,DL.y_test_oh,batch_size=config.batch_size)\n",
    "# ts_error = 1-res[1]\n",
    "# print(res[1])\n",
    "# df = pd.DataFrame.from_records({'test_acc':[res[1]],\n",
    "#                                 'label_corruption':[config.label_corruption],\n",
    "#                                 'recon':[config.recon],\n",
    "#                                 'xent':[config.xent],\n",
    "#                                 'ecc_max':[config.ecc_max],\n",
    "#                                 'xcov': [config.xcov]})\n",
    "# df.to_json(os.path.join(config.model_dir,'performance.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DL_dicarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_enc = l1_encoder.predict(DL_dicarlo.x_train,batch_size=config.batch_size)\n",
    "l2_enc = l2_encoder.predict(DL_dicarlo.x_train,batch_size=config.batch_size)\n",
    "l3_enc = l3_encoder.predict(DL_dicarlo.x_train,batch_size=config.batch_size)\n",
    "\n",
    "\n",
    "z_enc = z_encoder.predict(DL.x_train,batch_size=config.batch_size)\n",
    "# y_lat = y_lat_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_enc = y_encoder.predict(DL.x_train,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc_tr = z_encoder.predict(DL.x_train,batch_size=config.batch_size)\n",
    "# y_lat = y_lat_encoder.predict(DL.sx_test,batch_size=config.batch_size)\n",
    "y_enc_tr = y_encoder.predict(DL.x_train,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import hashlib\n",
    "def raw_to_xr(encodings,l_2_depth,stimulus_set):\n",
    "    obj_names = [\n",
    "        \"T-shirt\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Dress Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ]\n",
    "    all_das = []\n",
    "    for layer,activations in encodings.items():\n",
    "        neuroid_n = activations.shape[1]\n",
    "        n_idx = pd.MultiIndex.from_arrays([\n",
    "            pd.Series(['{}_{}'.format(layer,i) for i in np.arange(neuroid_n)],name='neuroid_id'),\n",
    "            pd.Series([l_2_depth[layer]]*neuroid_n,name='layer'),\n",
    "            pd.Series([layer]*neuroid_n,name='region')\n",
    "        ])\n",
    "        p_idx = pd.MultiIndex.from_arrays([\n",
    "            stimulus_set.image_id,\n",
    "            stimulus_set.dx,\n",
    "            stimulus_set.dy,\n",
    "            stimulus_set.rxy,\n",
    "            stimulus_set.numeric_label.astype('int8'),\n",
    "            pd.Series([obj_names[i] for i in stimulus_set.numeric_label],name='object_name'),\n",
    "            pd.Series(stimulus_set.dx.values/28, name='tx'),\n",
    "            pd.Series(stimulus_set.dy.values/28, name='ty'),\n",
    "            pd.Series([1.0]*len(stimulus_set),name='s'),\n",
    "        ])\n",
    "        da = xarray.DataArray(activations.astype('float32'),\n",
    "                         coords={'presentation':p_idx,'neuroid':n_idx},\n",
    "                         dims=['presentation','neuroid'])\n",
    "        all_das.append(da)\n",
    "        \n",
    "    return xarray.concat(all_das,dim='neuroid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {\n",
    "    'pixel':DL.sx_test,\n",
    "    'dense_1':l1_enc,\n",
    "    'dense_2':l2_enc,\n",
    "    'dense_3':l3_enc,\n",
    "    'y_lat':y_enc,\n",
    "    'z_lat':z_enc\n",
    "}\n",
    "depths = {\n",
    "    'pixel':0,\n",
    "    'dense_1':1,\n",
    "    'dense_2':2,\n",
    "    'dense_3':3,\n",
    "    'y_lat':4,\n",
    "    'z_lat':4\n",
    "}\n",
    "slug = [(dx,dy,float(lab),float(random.randrange(20))) for dx,dy,rxy,lab in zip(DL.dx[1],DL.dy[1],DL.dtheta[1],DL.y_test)]\n",
    "image_id = [hashlib.md5(json.dumps(list(p),sort_keys=True).encode('utf-8')).digest().hex() for p in slug]\n",
    "stim_set = pd.DataFrame({'dx':DL.dx[1]-14,'dy':DL.dy[1]-14,'numeric_label':DL.y_test,'rxy':DL.dtheta[1],'image_id':image_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = raw_to_xr(encodings,depths,stim_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def save_assembly(da,run_dir,fname,**kwargs):\n",
    "    da = da.reset_index(da.coords.dims)\n",
    "    da.attrs = OrderedDict()\n",
    "    with open(os.path.join(run_dir,fname), 'wb') as fp:\n",
    "        da.to_netcdf(fp,**kwargs)\n",
    "        \n",
    "    \n",
    "save_assembly(out,run_dir=config.model_dir,fname='dataset.nc',\n",
    "    format='NETCDF3_64BIT',\n",
    "#         engine=\n",
    "#         encoding=enc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(config.model_dir,'z_enc'),z_enc)\n",
    "np.save(os.path.join(config.model_dir,'l1_enc'),l1_enc)\n",
    "np.save(os.path.join(config.model_dir,'l2_enc'),l2_enc)\n",
    "np.save(os.path.join(config.model_dir,'l3_enc'),l3_enc)\n",
    "np.save(os.path.join(config.model_dir,'y_enc'),y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lat_vec = np.concatenate([y_enc,z_enc],axis=1)\n",
    "_lat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc_mu = np.mean(z_enc,axis=0)\n",
    "z_enc_cov = np.cov(z_enc,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(z_enc_mu,z_enc_cov,size=50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen = generator.predict(_lat_vec,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL2 = Shifted_Data_Loader(dataset=config.dataset,flatten=True,\n",
    "                          rotation=None,\n",
    "                          translation=translation_amt,\n",
    "                          bg_noise=bg_noise,\n",
    "                          bg_only=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_samples(DL.x_train,DL.x_train,z_enc_tr,y_enc_tr,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_dec_samples(DL.x_test,DL.x_test,z_enc,y_enc,generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_enc2 = z_encoder.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "y_lat2 = y_encoder.predict(DL2.sx_test,batch_size=config.batch_size)\n",
    "_lat_vec2 = np.concatenate([y_lat2,z_enc2],axis=1)\n",
    "regen2 = generator.predict(_lat_vec2,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import remove_axes,remove_labels\n",
    "from src.utils import gen_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 5\n",
    "rand_im = np.random.randint(0,10000,size=examples)\n",
    "fix,axs = plt.subplots(examples,11,figsize=(8,4))\n",
    "_lat_s = []\n",
    "regen_s = []\n",
    "out = gen_trajectory(z_enc[rand_im],z_enc2[rand_im],delta=.25)\n",
    "out_y = gen_trajectory(y_enc[rand_im],y_lat2[rand_im],delta=.25)\n",
    "\n",
    "for z,y in zip(out,out_y):\n",
    "    _lat = np.concatenate([y,z],axis=1)\n",
    "    _lat_s.append(_lat)\n",
    "    regen_s.append(generator.predict(_lat,batch_size=config.batch_size))\n",
    "\n",
    "i=0\n",
    "for axr,idx in zip(axs,rand_im):\n",
    "    axr[0].imshow(DL.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    axr[1].imshow(DL.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[2].imshow(regen[idx].reshape(56,56),cmap='gray')\n",
    "    for j,a in enumerate(axr[3:-3]):\n",
    "        a.imshow(regen_s[j][i,:].reshape(56,56),cmap='gray')\n",
    "#         a.imshow(s.reshape(56,56),cmap='gray')\n",
    "    axr[-3].imshow(regen2[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-2].imshow(DL2.sx_test[idx].reshape(56,56),cmap='gray')\n",
    "    axr[-1].imshow(DL2.x_test[idx].reshape(28,28),cmap='gray')\n",
    "    for a in axr:\n",
    "        remove_axes(a)\n",
    "        remove_labels(a)\n",
    "    i+=1\n",
    "# plt.imshow(regen[rand_im].reshape(56,56),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix.savefig('../../updates/2019-02-05/assets/img/translocate_{}.png'.format(translation_amt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdjsakl;fdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = DL.dx[1]-14\n",
    "dys = DL.dy[1]-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feat_range = (0,30)\n",
    "z_enc_scaled = [MinMaxScaler(feat_range).fit_transform(z_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(10)]\n",
    "z_enc_scaled = np.squeeze(np.array(z_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc_scaled = [MinMaxScaler(feat_range).fit_transform(y_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(10)]\n",
    "y_enc_scaled = np.squeeze(np.array(y_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_enc_scaled = [MinMaxScaler(feat_range).fit_transform(l2_enc[:,i].reshape(-1,1)).tolist() for i in np.arange(2000)]\n",
    "l2_enc_scaled = np.squeeze(np.array(l2_enc_scaled,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_enc_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import dit\n",
    "from dit import Distribution\n",
    "\n",
    "def mutual_information(X,Y):\n",
    "    XY_c = Counter(zip(X,Y))\n",
    "    XY_pmf = {k:v/float(sum(XY_c.values())) for k,v in XY_c.items()}\n",
    "    XY_jdist = Distribution(XY_pmf)\n",
    "        \n",
    "    return dit.shannon.mutual_information(XY_jdist,[0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dx_I = [mutual_information(z_enc_scaled[i],dxs.astype(int)+14) for i in np.arange(5)]\n",
    "# l2_dx_I = [mutual_information(l2_enc_scaled[i],dxs.astype(int)+14) for i in np.arange(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dy_I = [mutual_information(z_enc_scaled[i],dys.astype(int)+14) for i in np.arange(5)]\n",
    "# l2_dy_I = [mutual_information(l2_enc_scaled[i],dys.astype(int)+14) for i in np.arange(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_class_I = [mutual_information(z_enc_scaled[i],DL.y_test) for i in np.arange(5)]\n",
    "# l2_class_I = [mutual_information(l2_enc_scaled[i],DL.y_test) for i in np.arange(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_I_df = pd.DataFrame.from_records({'class':z_class_I,'dy':z_dy_I,'dx':z_dx_I})\n",
    "z_I_df['class'] = z_I_df['class'].values.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_I_df = pd.DataFrame.from_records({\n",
    "    'class':l2_class_I,\n",
    "    'dy':l2_dy_I,\n",
    "    'dx':l2_dx_I})\n",
    "l2_I_df['class'] = l2_I_df['class'].values.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_I_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_I_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l2_I_df.dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z_I_df.dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.translation_amt = translation_amt\n",
    "config.translation_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../data/xcov_importance/dist_{}/'.format(translation_amt)\n",
    "\n",
    "z_I_df.to_pickle('../data/xcov_importance/dist_{}/z_mutual_info.pk'.format(translation_amt))\n",
    "np.save('../data/xcov_importance/dist_{}/dxs'.format(translation_amt), DL.dx[1]-14)\n",
    "np.save('../data/xcov_importance/dist_{}/dys'.format(translation_amt), DL.dy[1]-14)\n",
    "np.save('../data/xcov_importance/dist_{}/z_enc'.format(translation_amt), z_enc)\n",
    "\n",
    "hist_df.to_pickle(os.path.join(dir_path,'training_hist.df'))\n",
    "\n",
    "with open(os.path.join(dir_path,'config.json'), 'w') as fp:\n",
    "        json.dump(vars(config), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_weight(wts,thresh=0.01):\n",
    "    idxs = np.abs(wts)>thresh\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_max = np.argmax(z_I_df.dx.values)\n",
    "dy_max = np.argmax(z_I_df.dy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.05\n",
    "dx_filt = filter_by_weight(z_w_k[:,dx_max],thresh=t)\n",
    "dy_filt = filter_by_weight(z_w_k[:,dy_max],thresh=t)\n",
    "union = np.union1d(np.where(dx_filt==True),np.where(dy_filt==True))\n",
    "intersect = np.intersect1d(np.where(dx_filt==True),np.where(dy_filt==True))\n",
    "# filt = np.array([False]*2000)\n",
    "# filt[union] = True\n",
    "\n",
    "sns.set_context('talk')\n",
    "fig,axs = plt.subplots(1,2,figsize=(6*2,5))\n",
    "\n",
    "filt = dy_filt\n",
    "print('num: ',len(union))\n",
    "print('intersect_frac: ',float(len(intersect))/len(union))\n",
    "print('mean dx_I: ',l2_I_df.dx[filt].mean())\n",
    "print('mean dy_I: ',l2_I_df.dy[filt].mean())\n",
    "points = axs[0].scatter(x=l2_I_df['dx'],y=l2_I_df['dy'],\n",
    "                        c=l2_I_df['class'],cmap='viridis',vmin=0,vmax=0.4,s=z_I_df['class']*100\n",
    "                       )\n",
    "plt.colorbar(points)\n",
    "points = axs[1].scatter(x=z_I_df['dx'],y=z_I_df['dy'],c=z_I_df['class'],cmap='viridis',s=z_I_df['class']*100,vmin=0,vmax=0.4)\n",
    "# plt.colorbar(points)\n",
    "axs[0].set_ylim(0,0.9)\n",
    "axs[0].set_xlim(0,0.9)\n",
    "axs[1].set_ylim(0,0.9)\n",
    "axs[1].set_xlim(0,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(z_dx_I,z_dy_I)\n",
    "# ax.set_ylim(0,0.8)\n",
    "# ax.set_xlim(0,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(25),sorted(z_class_I,reverse=True))\n",
    "# plt.scatter(np.arange(25),z_dx_I)\n",
    "# plt.scatter(np.arange(25),z_dy_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import var_expl,norm_var_expl\n",
    "from collections import Counter\n",
    "\n",
    "dtheta = DL.dtheta[1]\n",
    "fve_dx = norm_var_expl(features=z_enc,cond=dxs,bins=21)\n",
    "fve_dy = norm_var_expl(features=z_enc,cond=dys,bins=21)\n",
    "fve_class = norm_var_expl(features=z_enc, cond=DL.y_test, bins=21)\n",
    "# fve_dt = norm_var_expl(features=z_enc,cond=dtheta,bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fve_dx_norm = (dxs.var()-fve_dx)/dxs.var()\n",
    "# fve_dy_norm = (dys.var()-fve_dy)/dys.var()\n",
    "# fve_dth_norm = (dtheta.var()-fve_dt)/dtheta.var()\n",
    "fve_dx_norm = fve_dx\n",
    "fve_dy_norm = fve_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dx_norm.shape\n",
    "# np.save(os.path.join(config.model_dir,'fve_dx_norm'),fve_dx_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "plt.scatter(fve_dx_norm.mean(axis=0),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('fve_dx')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dx.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "xdim = np.argmax(fve_dx_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_dy_norm.mean(axis=0)\n",
    "# np.save(os.path.join(config.model_dir,'fve_dy_norm'),fve_dy_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_dy_norm.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_dy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(config.model_dir,'fve_dy.png'))\n",
    "# plt.ylim(-0.125,0.25)\n",
    "ydim = np.argmax(fve_dy_norm.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(config.z_dim),fve_class.mean(axis=0))\n",
    "plt.xlabel('Z_n')\n",
    "plt.ylabel('fve_class')\n",
    "# plt.ylim(0.0,0.5)\n",
    "np.argmax(fve_class.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import Z_color_scatter\n",
    "Z_color_scatter(z_enc,[xdim,ydim],dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[xdim,ydim],dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_color_scatter(z_enc,[7,18],dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
