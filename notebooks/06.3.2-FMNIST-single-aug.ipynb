{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neptune\n",
    "import imageio\n",
    "import scipy as scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.data_loader import Shifted_Data_Loader\n",
    "from src.data_generator import ShiftedDataBatcher\n",
    "\n",
    "from src.plot import orig_vs_transformed as plot_ovt\n",
    "from src.data_loader import _shift_image\n",
    "from src.test_models.drduplex import DRDuplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_date = '2019-09-27'\n",
    "proj_root = '/home/elijahc/projects/vae'\n",
    "models_root = os.path.join(proj_root,'models',exp_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPS = {\n",
    "    'dataset':'fashion_mnist',\n",
    "    'encoder_arch': 'dense',\n",
    "    'generator_arch': 'resnet',\n",
    "    'augmentation': 'single',\n",
    "}\n",
    "PARAMS = {}\n",
    "\n",
    "train_conf = {\n",
    "    'n_epochs': 54000,\n",
    "    'batch_sz':512,\n",
    "}\n",
    "\n",
    "data_conf = {\n",
    "    'bg': None,\n",
    "    'im_translation':0.75,\n",
    "    'im_rotation':None,\n",
    "#     'bg_contrast': 0.3,\n",
    "}\n",
    "\n",
    "model_conf = {\n",
    "    'xent_weight': 15,\n",
    "    'recon_weight': 1,\n",
    "}\n",
    "\n",
    "for conf in [train_conf,data_conf,model_conf]:\n",
    "    PARAMS.update(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_factor=1\n",
    "DL = Shifted_Data_Loader(dataset=PROPS['dataset'],flatten=False,num_train=60000*oversample_factor,\n",
    "                         translation=PARAMS['im_translation'],\n",
    "                         rotation=PARAMS['im_rotation'],\n",
    "#                          scale_mean0 = True,\n",
    "#                          contrast_level=PARAMS['bg_contrast'],\n",
    "                         bg=PARAMS['bg'],\n",
    "                         blend=None,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = ShiftedDataBatcher(dataset=PROPS['dataset'],\n",
    "                         translation=PARAMS['im_translation'],\n",
    "                         rotation=PARAMS['im_rotation'],\n",
    "#                          contrast_level=PARAMS['bg_contrast'],\n",
    "                         bg=PARAMS['bg'],\n",
    "                         blend=None,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,idx = plot_ovt(DL,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mean0(X):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1),copy=False)\n",
    "    n,x,y,c = X.shape\n",
    "    scaler.fit_transform(X.reshape(n,x*y*c))\n",
    "    X = X.reshape(n,x,y,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in [DL.sx_train,DL.sx_test,DL.fg_train,DL.fg_test]:\n",
    "    print(X.min(),X.max())\n",
    "    scale_mean0(X)\n",
    "    print(X.min(),X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.init('elijahc/DuplexAE')\n",
    "src_files = ['./src/data_loader.py','./src/test_models/drduplex.py']\n",
    "exp = neptune.create_experiment(name='fg_w_recon',properties=PROPS,params=PARAMS,upload_source_files=src_files)\n",
    "exp_dir = os.path.join('models',exp_date,exp.id) \n",
    "\n",
    "os.mkdir(os.path.join(proj_root,exp_dir))\n",
    "os.mkdir(os.path.join(proj_root,exp_dir,'recons'))\n",
    "os.mkdir(os.path.join(proj_root,exp_dir,'test_ims'))\n",
    "\n",
    "exp.set_property('dir',exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xent = PARAMS['xent_weight']\n",
    "w_recon = PARAMS['recon_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = DRDuplex(img_shape=(56,56,1),\n",
    "               num_classes=DL.num_classes,\n",
    "               recon=w_recon,\n",
    "               xent=w_xent,n_residual_blocks=4,\n",
    "#                kernel_regularization=1e-5,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.combined.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pct = 0.05\n",
    "val_idxs = np.random.choice(np.arange(10000),int(val_pct*60000),replace=False)\n",
    "validation_set = (DL.sx_test[val_idxs],\n",
    "                  {'Classifier':DL.y_test_oh[val_idxs],\n",
    "                   'Generator':DL.sx_test[val_idxs]}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "epoch_sz = int(DL.num_train/512)\n",
    "pan_ims = []\n",
    "pan_y = []\n",
    "\n",
    "# hist_labels = mod.combined.metrics_names\n",
    "hist_labels = ['loss','G_loss','C_loss','G_mse','acc']\n",
    "\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "\n",
    "# val_X,val_X_fg,val_y = DB.gen_batch(DB.x_te,DB.y_test_oh,batch_size=1000,bg='natural')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pan = 3\n",
    "not_unique = True\n",
    "while not_unique:\n",
    "    pan_idx = np.random.choice(np.arange(len(DL.sx_test)),size=num_pan,replace=False)\n",
    "    if len(np.unique(DL.y_test[pan_idx])) == num_pan:\n",
    "        not_unique = False\n",
    "    \n",
    "px_ = DL.x_test[pan_idx]\n",
    "print(px_.shape)\n",
    "# tX, tX_fg,ty = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_span = DB.gen_pan_deltas(step=2)\n",
    "pX = np.stack([np.expand_dims(_shift_image(X=px_,dx=dx,dy=dy),-1) for dx,dy in x_span])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "n,r,x,y,c = pX.shape\n",
    "\n",
    "pX = scaler.fit_transform(pX.reshape(n,x*y*c*r)).reshape(n,r,x,y,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,num_pan)\n",
    "for i,ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(pX[27,i].reshape(56,56),cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# nj = 25\n",
    "# fig,axs = plt.subplots(1,nj,figsize=(2*nj,2))\n",
    "\n",
    "# for i in np.arange(nj):\n",
    "#     axs[i].imshow(pX[i+15].reshape(56,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_pan(pan_ims):\n",
    "    min_max = lambda xp: np.clip((xp+1)/2,0,1)\n",
    "    for idx,inp,G in pan_ims:\n",
    "        idx = str(idx).zfill(3)\n",
    "        \n",
    "#         inp_fn = 'input_{}.png'.format(idx)\n",
    "#         inp_fp = os.path.join(proj_root,exp_dir,'test_ims',inp_fn)\n",
    "        \n",
    "        G_fn = 'G_{}.png'.format(idx)\n",
    "        G_fp = os.path.join(proj_root,exp_dir,'recons',G_fn)\n",
    "    \n",
    "        fig,axs = plt.subplots(2,num_pan)\n",
    "        for k in np.arange(num_pan):\n",
    "            axs[0,k].imshow(inp[k],cmap='gray')\n",
    "            axs[1,k].imshow(G[k],cmap='gray')\n",
    "\n",
    "        for ax in axs.ravel():\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.tight_layout()     \n",
    "        \n",
    "        fig.savefig(G_fp)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_dir = os.path.join(proj_root,exp_dir,'recons')\n",
    "input_dir = os.path.join(proj_root,exp_dir,'test_ims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(recon_dir,input_dir,fps=8,loop=0):\n",
    "    G_ims = []\n",
    "    for G in sorted(os.listdir(recon_dir)):\n",
    "        if G.endswith('.png'):\n",
    "            G_fp = os.path.join(recon_dir, G)\n",
    "            G_ims.append(imageio.imread(G_fp))\n",
    "        \n",
    "#     imageio.mimsave(os.path.join(proj_root,exp_dir,'inputs_video.gif'), input_ims,fps=fps,loop=loop)\n",
    "    imageio.mimsave(os.path.join(proj_root,exp_dir,'G_video.gif'), G_ims, fps=fps,loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(mod,mod_dir,spec_fn='model.json'):\n",
    "    model_json = mod.to_json()\n",
    "    with open(os.path.join(mod_dir,spec_fn), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "def save_weights(mod,mod_dir,weights_fn='weights.h5'):\n",
    "        mod.save_weights(os.path.join(mod_dir,weights_fn))\n",
    "\n",
    "def save_model_and_weights(mod,mod_dir,spec_fn='model.json',weights_fn='weights.h5'):\n",
    "    save_model(mod,mod_dir,spec_fn)\n",
    "    save_weights(mod,mod_dir,weights_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class ReconCallback(Callback):\n",
    "    def __init__(self,pX,pan_ims,pan_y):\n",
    "        self.pX = pX\n",
    "        self.pan_ims = pan_ims\n",
    "        self.pan_y = pan_y\n",
    "        self.recon_dir = recon_dir\n",
    "        self.input_dir = input_dir\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        pidx = int(epoch%len(self.pX))\n",
    "        im = pX[pidx]\n",
    "        p_recon,p_class = self.model.predict_on_batch(im)\n",
    "        \n",
    "        pan_im = (int(epoch), np.squeeze(im), np.squeeze(p_recon))\n",
    "        self.pan_ims.append(pan_im)\n",
    "        self.pan_y.append(p_class)\n",
    "        \n",
    "        \n",
    "        if len(self.pan_ims)>int(len(pX)/3):\n",
    "            print('writing_image_buffer...')\n",
    "            flush_pan(self.pan_ims)\n",
    "            self.pan_ims = []\n",
    "                \n",
    "            print('recompiling video...')\n",
    "            make_gif(self.recon_dir,self.input_dir)\n",
    "            \n",
    "class NeptuneMonitor(Callback):        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "#         innovative_metric = logs['acc'] - 2 * logs['loss']\n",
    "        neptune.send_metric('loss', logs['loss'])\n",
    "        neptune.send_metric('val_loss', logs['val_loss'])\n",
    "        neptune.send_metric('C_loss', logs['Classifier_loss'])\n",
    "        neptune.send_metric('val_C_loss', logs['val_Classifier_loss'])\n",
    "        neptune.send_metric('G_loss', logs['Generator_loss'])\n",
    "        neptune.send_metric('acc', logs['Classifier_acc'])\n",
    "        neptune.send_metric('val_acc', logs['val_Classifier_acc'])\n",
    "        neptune.send_metric('batch',int(epoch*117))\n",
    "        \n",
    "            \n",
    "class ModelCheckpointer(Callback):\n",
    "    def __init__(self, save_dir, monitor='val_loss'):\n",
    "        self.metric = monitor\n",
    "        self.save_dir = save_dir\n",
    "        self.best_val = np.inf\n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        print('monitoring {} to checkpoint model'.format(self.metric))\n",
    "        print('saving model spec and initial weights...')\n",
    "        save_model(self.model,self.save_dir)\n",
    "        save_weights(self.model,self.save_dir,'weights.h5')\n",
    "        \n",
    "    def on_train_end(self,logs={}):\n",
    "        save_weights(self.model,self.save_dir,'final_weights.h5')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch > 5 and logs[self.metric] < self.best_val:\n",
    "            self.best_val = logs[self.metric]\n",
    "            save_weights(self.model,self.save_dir,'weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_monitor = NeptuneMonitor()\n",
    "checkpointer = ModelCheckpointer(save_dir=os.path.join(proj_root,exp_dir),\n",
    "                                 monitor='val_Classifier_loss',\n",
    "                                )\n",
    "reconcb = ReconCallback(pX, pan_ims, pan_y)\n",
    "cbs = [neptune_monitor,checkpointer,reconcb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.combined.fit(DL.sx_train,y={'Classifier':DL.y_train_oh,'Generator':DL.sx_train},\n",
    "                 batch_size=PARAMS['batch_sz'],validation_data=validation_set,callbacks=cbs,epochs=int(54000/117),\n",
    "                 verbose=0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flush_pan(reconcb.pan_ims)\n",
    "make_gif(recon_dir,input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dir = os.path.join(proj_root,exp_dir)\n",
    "mod_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weights(mod.combined,mod_dir,'final_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = mod.combined.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_tr = pd.DataFrame.from_records(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_labels = ['loss','G_loss','C_loss','G_mse','acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {k:v for k,v in zip(mod.combined.metrics_names,hist_labels)}\n",
    "hist_tr = hist_tr.rename(columns=col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_dir)\n",
    "hist_tr.to_csv(os.path.join(mod_dir,'training_hist.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teX,_,_ = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mod.combined.predict_on_batch(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon,y = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = np.random.choice(np.arange(1024),size=5,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,axes = plt.subplots(2,5,figsize=(2*5,2*2))\n",
    "\n",
    "for i,idx in enumerate(choices):\n",
    "    axs = axes[:,i]\n",
    "    axs[0].imshow(teX[idx].reshape(56,56),cmap='gray')\n",
    "    axs[1].imshow(x_recon[idx].reshape(56,56),cmap='gray')\n",
    "    \n",
    "for ax in axes.ravel():\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix.savefig(os.path.join(mod_dir,'inp_output_pairs.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.send_artifact(os.path.join(mod_dir,'inp_output_pairs.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = DL.sx_train\n",
    "x_tro = DL.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.squeeze(x_tr[5])\n",
    "plt.imshow(x_tro[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_warp = np.zeros((28,28))\n",
    "xt_warp = scipy.ndimage.zoom(x_tro[5],(1.1,0.9))\n",
    "plt.imshow(xt_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL.meta_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-GPU (Python3.5.2)",
   "language": "python",
   "name": "py3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "neptune": {
   "notebookId": "c2652b93-8ee0-4f8b-8e17-4bde282b576b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
